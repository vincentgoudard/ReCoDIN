
@article{wanderley_gestural_2004,
	title = {Gestural {Control} of {Sound} {Synthesis}},
	volume = {92},
	issn = {0018-9219},
	url = {http://ieeexplore.ieee.org/document/1278687/},
	doi = {10.1109/JPROC.2004.825882},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {Proceedings of the IEEE},
	author = {Wanderley, M.M. and Depalle, P.},
	month = apr,
	year = {2004},
	pages = {632--644},
	file = {2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_IEEE/2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:application/pdf}
}

@phdthesis{bin_show_2018,
	address = {London},
	title = {The {Show} {Must} {Go} {Wrong}: {Towards} an understanding of audience perception of error in digital musical instrument performance},
	abstract = {This thesis is about DMI (digital musical instrument) performance, its audiences, and their perception of error. The goal of this research is to improve current understanding of how audiences perceive DMI performance, where performers and their audiences often have no shared, external frame of reference with which to judge the musical output. Further complicating this audience-performer relationship are human-computer interaction (HCI) issues arising from the use of a computer as a musical instrument. In current DMI literature, there is little direct inquiry of audience perception on these issues. Error is an aspect of this kind of audience perception. Error, a condition reached by stepping out of bounds, appears at first to be a simple binary quantity, but the location and nature of those boundaries change with context. With deviation the locus of style and artistic progress, understanding how audiences perceive error has the potential to lend important insight to the cultural mechanics of DMI performance. In this thesis I describe the process of investigating audience perception and unpacking these issues through three studies. Each study examines the relative effects of various factors on audience perception — instrument familiarity and musical style, gesture size, and visible risk — using a novel methodology combining real-time data collected by mobile phone, and post- hoc data in the form of written surveys. The results have implications for DMI and HCI researchers as well as DMI performers and composers, and contribute insights on these confounding factors from the audience’s perspective as well as important insights on audience perception of error in this context. Further, through this thesis I contribute a practical method and tool that can be used to continue this audience-focused work in the future.},
	language = {en},
	school = {Queen Mary University of London},
	author = {Bin, S M Astrid},
	month = may,
	year = {2018},
	file = {2018.PhD.Bin.ShowMustGoWrong.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2018.PhD.Bin.ShowMustGoWrong.pdf:application/pdf}
}

@article{gadd_metamuse:_2002,
	title = {{MetaMuse}: {Metaphors} for {Expressive} {Instruments}},
	abstract = {We explore the role that metaphor plays in developing expressive devices by examining the MetaMuse system. MetaMuse is a prop-based system that uses the metaphor of rainfall to make the process of granular synthesis understandable. We discuss MetaMuse within a framework we call “transparency” that can be used as a predictor of the expressivity of musical devices. Metaphor depends on a literature, or cultural basis, which forms the basis for making transparent device mappings. In this context we evaluate the effect of metaphor in the MetaMuse system.},
	language = {en},
	author = {Gadd, Ashley and Fels, Sidney},
	year = {2002},
	pages = {6},
	file = {nime2002_065.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_065.Fels.MetaphorsForExpressiveInstruments.pdf:application/pdf}
}

@article{fyans_where_nodate,
	title = {Where {Did} {It} {All} {Go} {Wrong}? {A} {Model} of {Error} from the {Spectator}'s {Perspective}},
	abstract = {The development of new interfaces for musical expression has created a need to study how spectators comprehend new performance technologies and practices. As part of a larger project examining how interactions with technology can be communicated with the spectator, we relate our model of spectator understanding of error to the NIME discourse surrounding transparency, mapping, skill and success.},
	language = {en},
	author = {Fyans, A Cavan and Gurevich, Michael and Stapleton, Paul},
	pages = {2},
	file = {nime2009_171.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_171.pdf:application/pdf}
}

@article{wessel_problems_nodate,
	title = {Problems and {Prospects} for {Intimate} {Musical} {Control} of {Computers}},
	abstract = {In this paper we describe our efforts towards the development of live performance computer-based musical instrumentation. Our design criteria include initial ease of use coupled with a long term potential for virtuosity, minimal and low variance latency, and clear and simple strategies for programming the relationship between gesture and musical result. We present custom controllers and unique adaptations of standard gestural interfaces, a programmable connectivity processor, a communications protocol called Open Sound Control (OSC), and a variety of metaphors for musical control. We further describe applications of our technology to a variety of real musical performances and directions for future research.},
	language = {en},
	author = {Wessel, David and Wright, Matthew},
	pages = {4},
	file = {WRIGHT WESSEL - Problems and Prospects for Intimate Musical Control of Computers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_INSTRU/WRIGHT WESSEL - Problems and Prospects for Intimate Musical Control of Computers.pdf:application/pdf}
}

@article{fels_mapping_2002,
	title = {Mapping transparency through metaphor: towards more expressive musical instruments},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Mapping transparency through metaphor},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002042/type/journal_article},
	doi = {10.1017/S1355771802002042},
	abstract = {We define a two-axis transparency framework that can be used as a predictor of the expressivity of a musical device. One axis is the player's transparency scale, while the other is the audience's transparency scale. Through consideration of both traditional instrumentation and new technology-driven interfaces, we explore the role that metaphor plays in developing expressive devices. Metaphor depends on a literature, which forms the basis for making transparent device mappings. We examine four examples of systems that use metaphor: Iamascope, Sound Sculpting, MetaMuse, and Glove-TalkII; and discuss implications on transparency and expressivity. We believe this theory provides a framework for design and evaluation of new human-machine and humanhuman interactions, including musical instruments.},
	language = {en},
	number = {2},
	urldate = {2019-05-24},
	journal = {Organised Sound},
	author = {Fels, Sidney and Gadd, Ashley and Mulder, Axel},
	month = aug,
	year = {2002},
	pages = {109--126},
	file = {2002.OS.Fels.Mapping Transparency through Metaphor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2002/2002.OS.Fels.Mapping Transparency through Metaphor.pdf:application/pdf}
}

@book{seve2013a,
  title={L'instrument de musique: une {\'e}tude philosophique},
  author={S{\`e}ve, Bernard},
  year={2013}
}
