\chapter{Interview : Jose-Miguel Fernandez}
\label{appendix:fernandez}

\section*{Biographie}

\noindent José Miguel Fernandez a étudié la musique et la composition à l’université du Chili et au Laboratoire de recherche et de production musicale (LIPM) de Buenos Aires, Argentine. Il suit ensuite les cours de composition au Conservatoire National Supérieur de Musique et de Danse de Lyon et participe au Cursus de composition de l’IRCAM. Il compose des œuvres de musique instrumentale, électroacoustiques et mixtes. Ses œuvres sont créées en Amériques, Europe, Asie et Océanie, et il réalise des concerts de musique mixte et électroacoustique dans plusieurs festivals. Il a été sélectionné au concours international de musiques électroacoustiques de Bourges (2000) et il est lauréat des concours internationaux de composition Grame-EOC de Lyon (2008) et Giga Hertz Award du ZKM en Allemagne (2010). En 2014 il a été sélectionnée par l'IRCAM pour suivre le programme de résidence en recherche artistique sur l'interaction en musiques mixtes. Il est actuellement doctorant du Doctorat de musique : recherche en composition, organisé en collaboration par Sorbonne Université, l’UPMC et l'IRCAM. Son projet de recherche se concentre principalement sur l’écriture de l’électronique et la recherche de nouveaux outils pour la création en musiques mixtes et électroacoustiques. Parallèlement à son activité de compositeur, il travaille sur divers projets pédagogiques et de création en lien avec l’informatique musicale.

\section*{Transcript}

\noindent Jose-Miguel Fernandez, interview du 13/06/2018, à l'IRCAM, Paris.

VG — Comme je te disais j'ai une liste de questions assez ouvertes, sur les raisons qui t'ont amené à faire ce que tu fais et là ou tu vas avec les instruments numériques, et les choses qui m'intéressent spécifiquement ce sont les caractéristiques du numérique dans ces instruments qui dès qu'on utilise les instruments sont présentes de toute façon... 

JMF — oui, parce que moi je n'ai pas d'interface physique sauf mes capteurs, mais sinon je fais tout dans l'ordinateur... après bon je fais de la musique mixte donc il y a les instruments vrais qui vont être traités ou de la musique acousmatique pure où il n'y a pas de ...mais je n'ai pas d'interfaces tactiles ou des choses comme ça même si j'en ai fait, j'ai bidouillé pas mal avec arduino, tout ça, mais maintenant je suis plus orienté vers le développement, tous ces trucs là, plus informatique, Antescofo, comme je t'ai montré... 

VG — oui, après tout cela s'inscrit dans un écosystème d'outils que tu utilises... l'idée à la base était motivée par le fait que chacun a sa manière très spécifique de faire de la musique avec des instruments numériques, tout le monde peut programmer à sa sauce donc il y a toujours une part de personnalisation, et pas un truc que tu achètes tout fait... même quand tu achètes Ableton Live, tu vas quand même prendre tes propres chemins... ce qui m'intéressait là-dedans, c'est qu'à chaque fois il y a un côté très singulier dans la manière dont chacun s'approprie ces outils 
 
JMF — ok 

VG — ma première question c'est qu'est ce qui t'a amené à utiliser des instruments de musique numériques plutôt qu'une guitare, un piano, un instrument qui a déjà une tradition, prêt à l'emploi d'une certaine manière... qu'est ce qui t'a motivé à utiliser de tels instruments ? 

JMF — je viens du Chili et je pense que tout vient de la composition, d'essayer de trouver de nouvelles sonorités, toujours, et surtout des interactions avec des instruments et d'autres types de choses, les gestes, l'utilisation de Kinect (l'interface de Microsoft, NdE) mais au tout début, j'étais au Chili et je savais qu'ici en Europe et aux Etats Unis, on utilisait un logiciel qui s'appelle Max, car j'avais écouté quelques compositions faites ici à l'IRCAM et ailleurs, qui utilisaient ça, donc moi j'étais en quatrième année à l'université, on avait un cours d'électroacoustique et j'avais demandé à mon prof est-ce que tu connais ce logiciel qui s'appelle Max ? Et il me dit oui oui, regarde et il ouvre un tiroir et il y avait Max 2.5, donc avec le gros manuel qu'il y avait à l'époque...  

VG — en papier 

JMF — oui, en papier c'était relié avec une spirale... et donc je l'ai pris, et il m'a dit oui il est ici parce qu'on a gagné un projet donc on a acheté un classic 2, un Mac Classic II et Max parce que voilà il l'avait étudié en Allemagne, il venait d'arriver, donc il disait oui je sais que ce logiciel, tout le monde dit que c'est un peu l'avenir... déjà à l'époque, c'était en 1994 ... et donc il m'a dit mais moi j'ai aucune idée de comment ça marche donc, tiens, débrouilles toi... donc il m'a donné le truc et moi j'ai commencé à regarder, donc j'ai vu le premier tutorial où il y avait « plus » et après « multiplier », deux boites, donc je me dis bon mais ça... ça ne sert pas à faire de la musique ce truc... et bon après je me suis rendu compte qu'il y avait un métro (objet Max métro, servant de métronome, NdE) donc ah ok, on peut faire les rythmes, et après il y a un random (objet Max, NdE) les trucs de bases quoi... donc je peux faire random, et et après je peux contrôler des trucs externes, des synthétiseurs, des samplers... parce qu'à l'époque c'était que MIDI, c'était la version Opcode MIDI... et donc il y avait des samplers et donc je commençais à enregistrer plein de trucs et après les piloter avec Max et après les synthés, tout ça ... et petit à petit je commençais à rentrer dans le monde de la fabrication, et en temps réel, parce qu'on peut dire que j'ai vraiment commencé avec Max, j'avais fait un peu de Csound aussi... et en même temps... et après je suis allé en Argentine où il y avait le LIPM (Laboratorio de Investigación y Producción Musical, à Buenos Aires, NdE), c'était un laboratoire d'électroacoustique, le meilleur à l'époque c'était en 1996 ... et c'était le meilleur d'Amérique du Sud, il y avait toutes les semaines des gens, John Chowning, Chadabe, l'IRCAM, Boulez venaient tout le temps... j'étais pendant six mois et j'ai vu passer toute l'informatique musicale, il y avait Max Mathews, tous les gens très très importants, donc ça bougeait beaucoup, ils avaient beaucoup d'argent à l'époque et il faisaient des concerts toutes les semaines, tous les mercredis, même deux parfois... et donc là j'ai continué à faire de la programmation dans Max ... et voilà je pense qu'à partir de là, je me suis mis complètement dans l'informatique et quand je retournais au Chili, je travaillais avec le gars que je te disais, il avait plein d'ordinateurs, j'ai travaillé avec Nato qui était la première librairie pour faire de la vidéo dans Max et le premier système ambisonique aussi, on avait mis une sphère de haut-parleurs, et ... bon après un certain moment, je suis dit bon là il y a une personne qui peut m'apprendre plus de choses et ici voilà... parce que l'autre personne était plutôt dans la musique électronique pour danser plutôt...et moi je voulais continuer la musique plutôt de recherche et d'exploration ... expérimentale d'une certaine façon... et bon je me suis dit ici il n'y a plus rien à faire, il faut que je parte un peu plus loin... donc je suis allé à Lyon, au CNSM, j'ai fait la postulation et j'ai été accepté, et là voilà j'ai continué encore à développer Max et tout ça .... et bon l'idée c'était toujours de faire des choses les plus interactives possibles entre les musiciens donc j'ai beaucoup travaillé avec des percussionnistes, même aujourd'hui je continue à le faire, et donc mettre toujours des capteurs, des piezos, des choses pour avoir le plus d'information possible dans l'ordinateur pour la synchronisation, pour les traitements et tout ça et ça m'a amené à commencer à développer de plus en plus de différents types de patchs, soit pour la synthèse, soit pour les traitements... et là c'est arrivé que je suis venu à Paris, faire le cursus de composition de l'IRCAM et là, après le cursus, comme ça arrive à beaucoup de compositeurs, bon je ne suis pas si jeune que ça, mais qu'on a rien... d'un jour à l'autre, j'avais une super bourse pour toute cette année, et d'un jour au lendemain je n'avais rien donc j'ai demandé ici, bon est ce qu'il y a un peu de boulot, et il y a Eric Daubresse qui m'a dit oui, il y a un peu de travail, donc j'ai commencé à travailler avec Emmanuel Nunes, qui avait une notion de l'électronique très fine, et tout de suite j'ai été amené à faire des patchs assez complexes, pour pouvoir ... donc lui son paradigme, c'était que chaque note allait avoir un ou plusieurs traitements et chaque note allait se spatialiser dans un ensemble de haut-parleurs, un peu une sphère aussi de haut-parleurs, un enveloppement de haut-parleurs, et donc la première pièce que j'ai faite avec lui, c'était pour ensemble et électronique donc il y avait des couches de superpositions d'instruments qui partaient dans tous les haut-parleurs, donc c'était à l'époque j'utilisais encore des boites de messages, mais il y en avait partout et donc c'était assez, disons grand comme travail, et donc à partir de ça après j'ai continué à travailler à l'IRCAM pendant une dizaine d'années en tant que RIM (réalisateur en informatique musicale, NdE), intermittent du spectacle bien sûr... mais mon idée c'était toujours de voir quelle électronique avoir dans le monde de la musique contemporaine, plus ou moins l'équivalent que la musique instrumentale, c'est-à-dire que la musique instrumentale a un long parcours historique et aussi des techniques, et des virtuosités... on voit même des concerts pour piano de la musique romantique, il y a un rythmique, harmonique et oui, au niveau de la virtuosité, donc normalement c'est ce qu'on a l'habitude, parce que bon c'est quand même assez jeune je pense l'informatique musicale temps réel, et souvent c'est comme si l'électronique reste toujours un accompagnement ou qui est toujours plus simple, on fait des nappes, ou.... Et donc mon idée c'était pourquoi ne pas arriver au même, même si bon, c'est une idée, c'est peut-être encore une utopie, mais pourquoi ne pas arriver au même niveau de sophistication du monde instrumental dans le monde électronique ... et donc à partir de là, j'ai commencé à faire justement des patchs de plus en plus complexes, mais à un certain moment, plutôt récemment, je me suis rendu compte que j'avais besoin quand même d'un autre paradigme, de trouver une autre façon de faire, qui est d'utiliser par exemple Max dans ce cas, parce que je voulais des choses dynamiquement, très rapidement et avoir une grande superposition, de faire une espèce d'orchestration de l'électronique, au même titre que l'instrumental, et ... aussi avec les travaux que j'avais fait avec Emmanuel Nunes, donc lui m'a d'une certaine façon marqué par cette idée de virtuosité électronique, et d'arriver à un système le plus dynamique possible... et donc j'ai commencé à travailler là avec Antescofo, qui est le suivi de partition, donc là on pouvait avoir vraiment un suivi de partition très très précis et même à un niveau rythmique, même si c'est très rapide l'ordinateur va arriver à suivre, bien sûr si c'est des notes, si c'est des modes de jeu un peu particulier, il faut passer à d'autres systèmes mais au moins le suivi de notes marche très bien et aussi on avait le suivi de tempo donc avec toutes ces données on pouvait déjà faire des choses très très sophistiquées mais il restait quand même la contrainte qu'on a, voilà, sur l'ordinateur, souvent, ou sinon sur des ordinateurs en réseau, mais que la CPU monte assez rapidement, dès qu'on commence à utiliser par exemple des phase-vocoder, SuperVP on appelle ça (un objet Max implémentant un algorithme de vocodeur de phase en temps réel, développé à l'IRCAM, NdE) pour faire du time-stretch en temps-réel par exemple ou un traitement FFT, etc. donc on s'aperçoit que dès que tu commence à faire des choses un peu plus dynamiques et rapidement la CPU part et même Max commence à avoir des problèmes au niveau du timing, de la précision du temps... et donc petit à petit j'ai commencé à migrer vers SuperCollider que j'ai au début utilisé comme un synthétiseur, parce que j'étais assez choqué la première fois que j'ai chargé SuperCollider, bon j'ai commencé avec la version 2, mais qu'il y a une seule ligne de code et que ça envoyait tout de suite un son hyper-complexe et donc je me suis dit bon, là il y a quelque chose à explorer, parce qu'avec une seule ligne de code très réduite, on arrive à faire des sons assez complexes avec des rythmes et surtout la qualité du son, ça m'a beaucoup choqué parce qu'on avait plutôt l'habitude de Max/MSP, à l'époque ça venait de sortir aussi, c'était en 1998, quelque chose comme ça, 1999, je ne me souviens plus... et donc le son de SuperCollider quand même il y avait une richesse qui était assez particulière, qu'on n'avait pas dans Max/MSP à l'époque, peut-être que maintenant c'est différent, peut-être que maintenant, c'est aussi un paramètre un peu abstrait, mais c'est un paramètre qui est quand même perceptible et que pas mal de gens ont quand même... c'était même une discussion dans les forums de logiciels spécialisé, quel est le logiciel qui sonne le mieux et donc toujours il y avait une tendance vers SuperCollider quand on faisait la relation entre des environnements temps-réel ... et donc comme je t'ai dit, j'ai commencé à utiliser SuperCollider que pour faire des sons, parce que ça m'intéressait la partie synthétique et tous les UGens, qui sont comme les objets dans Max, les objets qui génèrent du traitement du signal, du son, des enveloppes et tout ça, et donc il y avait et il y a toujours une grande richesse de différents types de modules pour faire différents types de choses, stochastiques, randomiques et déterministes, etc. et à un certain moment, j'ai commencé à me dire ah mais pourquoi je fais pas les sons, au lieu de les faire en... parce que je les faisais dans SC et je les enregistrais pour les utiliser comme des bandes pour déclencher après, je me suis dit pourquoi ne pas les faire en temps réel et c'est là que je me suis aperçu qu'il n'y avait pas que la synthèse mais qu'il y avait tout un mécanisme de gestion du temps réel dans SC qui était complètement dynamique et vraiment, James McCartney, la personne qui l'avait créé avait pensé du début à toute cette organisation... donc le logiciel est pensé du début, bon comme Max aussi bien sûr pour faire du temps réel, mais ici pour faire du temps réel dynamiquement... c'est-à-dire qu'on va pouvoir créer des instances de synthèse, les détruire, les faire évoluer dans le temps, créer plusieurs superpositions et avec une consommation de CPU assez réduite... et donc ça, ça m'attirait beaucoup l'attention ... et bon après je fais le mix, j'ai commencé à faire ça il y a deux ou trois ans... entre les logiciels, parce qu'Antescofo bien sûr a évolué, la première pièce où je l'ai utilisé ça devait être en 2010 ou 2011 et aujourd'hui ce n'est plus qu'un suivi de partition mais aussi un langage de programmation en entier, donc un langage où on va pouvoir gérer sur tout le temps, il y a différentes façon de gérer le temps... comme je t'ai montré il y a le temps absolu, le temps relatif, il y a différents types de courbes, des multi-courbes, multi-dimensionnelles,etc. Donc le fait que c'est un langage de programmation va me permettre de créer des processus temporels ou rythmiques ou musicaux, pour créer des accords ou n'importe quoi mais aussi pour créer de la synthèse et c'est là où je me suis dit bon, ce que je vais faire c'est marier le monde du suivi de partition avec ce langage de programmation c'est un espèce de méta-séquenceur, parce qu'on peut l'utiliser comme séquenceur aussi, on n'est pas obligé de l'utiliser qu'avec le suivi de partition mais tu peux créer tes séquences, des séquences où tu vas générer aussi en même temps des processus, donc qu'est ce que c'est un processus, ça va être par exemple déclencher une séquence qui va être crée avec un algorithme déterminé ou séquence avec des notes que tu vas mettre dans un réservoir... et bon ça c'est vraiment la base, mais ça va être aussi changer la structure d'une séquence où d'une synthèse avec des inputs, donc c'est là où j'ai commencé à utiliser aussi des capteurs, donc je rentre par OSC (Open Sound Control, NdE) direct les capteurs dans Antescofo et lui il va créer les synthèses et tout ça... donc l'idée d'unir les deux mondes, c'est que les deux sont des systèmes dynamiques dans le sens où dans Antescofo je peux créer un petit processus, et ce processus je vais pouvoir l'appeler, mon processus bien sûr va s'appeler « toto » (rires) et je peux l'instancier toutes les fois que je veux... par exemple toto va faire Do, Mi, Sol ... mais je peux le lancer cinquante fois, il va faire cinquante fois Do Mi Sol et même il va y avoir du chevauchement, ce qui veut dire que la polyphonie est déjà intégrée d'office parce que je peux l'instancier autant de fois que je veux... je peux changer ses paramètres, que ça ne soit pas Do Mi Sol, mais Do Ré Mi Fa Sol La Si Do, et donc je peux aussi en temps réel changer la morphologie d'une certaine façon ... la ligne mélodique, si on fait une mélodie, je peux la moduler aussi en temps réel et je peux connecter cette modulation avec le monde extérieur, apr exemple les capteurs ou le clavier ou n'importe quoi, par exemple l'analyse du son, j'ai beaucoup travailler avec l'analyse en temps réel des flux audios avec des descripteurs ou des trucs beaucoup plus simple, comme enveloppe follower, etc. donc tu vas pouvoir moduler toutes ces structures qui sont polyphoniques et ce qui m'intéresse c'est que dans SC c'est plus ou moins l'équivalent parce que je vais pouvoir aussi créer des synthèses, tout ce que je veux, dynamiquement, sans avoir besoin de faire un patch par exemple... Bien sûr avant j'ai programmé tout pour que je puisse faire les interconnexions tout ça, il y a beaucoup de programmation avant, mais au moment de la performance on va pouvoir déclencher autant de choses qu'on veut, à la vitesse qu'on veut, bien sûr il y a des limites, mais ça donne un environnement très flexible et je m'approche de mon idée que je te disais au début que je peux pouvoir manipuler l'électronique de manière aussi souple qu'avec les instruments... bien sûr ça ne va pas être quelqu'un qui va le jouer, sauf si on utilise le suivi de partition, à ce moment là je peux utiliser les caractéristiques de l'instrumentiste comme les gestes, le son etc. pour piloter et créer dynamiquement des synthèses, des spatialisations et tout ça mais je veux aussi pouvoir créer des processus qui vont pouvoir créer plusieurs couches de synthèse, donc c'est ce que je suis en train de faire dans lequel il y a le système ambisonique et je veux, voilà, créer des masses sonores qui vont d'un endroit à l'autre, après peut-être aussi avoir une écoute, que je puisse me balader dans la pièce elle-même, la pièce électronique je veux dire, mais qui est un espace virtuel et créer des masses qui vont évoluer, un peu à la Xénakis d'une certaine façon, utiliser des masses sonores et créer par des synthèses granulaires ou différents types de synthèses que je peux envelopper, envoyer dans différentes parties de l'espace en 3D et voilà... mon idée c'est justement de pouvoir donner à l'électronique une vie que normalement on n'a pas l'habitude de le faire, on ne peut pas le faire par exemple avec ProTools, si je me mets à couper des petits échantillons et à faire des processus, peut-être que je vais passer un an à faire une pièce de cinq minutes... donc c'est vraiment pas pratique de faire comme ça et c'est pas adapté parce que je vais avoir des superpositions de, je sais pas, 200 trucs en même temps... et par exemple gérer dans proTools 200 tracks c'est un peu compliqué et après si tu veux faire du grouping, bien sûr on peut mais c'est pas le but et ce n'est pas des instruments qui sont adaptés pour faire ce genre de choses et c'est pour ça que j'ai eu cette tendance d'aller vers cette richesse de l'électronique qu'on puisse voir comme un espèce d'orchestre électronique mais aussi comme une possibilité d'intégrer des choses de modèles extérieurs comme des modèles mathématiques ou stochastiques ou des... je sais pas , des orbites, pour l'instant je suis en train de faire un catalogue des librairies dans lesquelles je suis en train d'injecter ou programmer différents modules pour différents types de mouvements dans l'espace ... des mouvements rythmiques etc. et après biensûr des enchainements de synthèse et voilà... c'est ça l'idée, c'est de faire une électronique qui soit très très souple et virtuose... ou pas... parce qu'on peut faire des nappes très lentes mais lesquelles il y a beaucoup de superpositions, c'est pas que des choses très articulées rythmiques mais les deux parce que bon la musique que je fais, il y a souvent des parties qui sont un peu plus statiques, mais après ça rentre dans un chaos où ça aprt dans tous les sens, où peut-être ça peut revenir, donc ça passe d'un monde à l'autre... donc l'idée c'est pour aller dans cette densité, de pouvoir utiliser qui soient un peu plus performants que ceux qu'on a l'habitude d'utiliser... et voilà c'est plutôt où je vais... 

VG — oui... en faisant un grand saut jusqu'au début de ce que tu disais, tu as commencé par la composition instrumentale classique, hors électronique ? 

JMF — oui, disons ma première pièce c'était classique, un sextuor à cordes, mais je pense que ma deuxième composition déjà c'était une pièce mixte... et après j'ai fait une pièce électronique pure, acousmatique et après une pièce instrumentale et je pense que depuis que je suis rentré au CNSM de Lyon, j'ai fait peut-être une seule pièce acoustique seule, un quatuor de saxophone, le reste c'est que des pièces mixtes ou électroniques, donc oui, on peut dire que j'ai tout de suite commencé à faire de la musique mixte avec des ordinateurs, c'était presque en même temps... 

VG — dans ce que j'entends de ce que tu me racontes, tu étais dans un cursus de composition où du coup tu as appris à composer avec les instruments acoustiques et avec la notation classique, j'imagine, déjà étendue par les symboles de la musique contemporaine, et du coup l'électronique, c'était du coup un moyen d'avoir des outils plus souples, plus dynamiques, pour l'écriture ? Il y avait vraiment cette idée de l'écriture musicale ? Je te pose cette question car parmi les gens que j'ai interviewés, certains sont arrivés dans la musique électronique uniquement pour des raisons de son, par exemple... c'était la possibilité de faire des sons qu'on ne pouvait pas faire sans l'électronique, il y avait une souplesse au niveau du son ... quelque part les deux se rejoignent.... La souplesse d'écriture des processus participe de la richesse des sons qu'on peut produire, sûrement, mais je pensais à cela par rapport à cet exemple que tu donnais de ProTools où c'est très difficile de faire 200 pistes parce que tu veux déclencher 200 notes en même temps, ces systèmes électroniques, tu dis que tu souhaites un système plus ouvert, plus dynamique, plus vivant... et du coup c'est des outils pour lesquels il devient très difficile de noter cela avec une notation classique, voire impossible ... on serait autant embêté avec une partition papier pour dessiner 200 notes qu'on le serait avec ProTools...  

JMF — oui bien sûr 

VG — donc ce n'est pas tant le fait que ProTools ne soit pas pratique, c'est que ... 

JMF — oui, c'est pas adapté à la notation bien sûr... après pour revenir aussi à ce que tu dis, pour moi, le plus important c'est le son, aussi ... le résultat sonore c'est ce qui est le plus important, après il y a des moyens pour y arriver... donc l'écriture instrumentale tu peux faire quelque chose plus ou moins complexe, mais moi ce qui m'intéresse c'est le son, ce n'est pas l'écriture pour l'écriture elle-même... par exemple je peux créer des systèmes qui vont me donner des résultats d'écriture, bien sûr je peux utiliser de la CAO, de la composition assistée par ordinateur, qui va me générer automatiquement des choses mais c'est pas ça vraiment qui m'intéresse... je l'ai utilisé, et je vais continuer à l'utiliser, c'est comme avoir une espèce de réservoir de sons... toute l'écriture pour moi, c'est quelque chose qui va vers le résultat final qui est le son... par exemple, moi, ça ne m'intéresse pas de créer des relations hyper complexes au niveau rythmique, mélodique, etc. sans avoir un retour sonore... je pense que la musique algorithmique pure, pour moi, n'a pas trop d'intérêt parce que on se concentre beaucoup trop sur quelque chose de théorique et on laisse de côté justement le son... et le son c'est ça qu'on va finalement entendre... c'est ça qui est la musique, ce n'est pas la théorie qui est derrière... bien sûr après on peut créer des super théories qui vont créer aussi des sons très intéressants et qui peuvent donner aussi des compositions magnifiques, mais après voilà ça dépende du compositeur de comment il arrive à avancer... surtout aujourd'hui où on a tellement de possibilités... mais voilà c'est comme à partir, je sais pas, des années 60, il y a dans la musique contemporaine, pas dans les autres musiques où il n'y a pas eu cette division entre la partie théorique et le son, mais dans la musique contemporaine au moins européenne et occidentale, on peut dire qu'à partir des années 1950, il y a eu un retour vers le son et je suppose qu'on est encore là-dedans parce que finalement on s'est rendu compte que si on veut pas ennuyer un public au bout de cinq minutes d'entendre quelque chose qui finalement change, par exemple c'est ce qu'on appelle la musique structuraliste de années 1950, où tous les paramètres étaient calculées par des combinaisons calculatoires, et au bout de cinq minutes on perd l'attention (la tension?) parce que ça donne toujours la même chose... bon après il y a des gens qui apprécient beaucoup ça, mais en général on a plus je pense la sensation, ou je ne sais pas comment dire, l'intuition de rentrer dans une musique qui peut te prendre et te ramener et te faire voyager, ballader par différents endroits, sonores bien sûr, dans un espace sonore et... voilà c'est ça qui m'intéresse... donc pour moi tous ces outils, qu'ils soient plus ou moins sophistiqués, c'est pour arriver au résultat final qui va être le son et cet agencement de sons qui est finalement la composition, c'est-à-dire comment je vais pouvoir prendre quelqu'un, ou même moi-même, parce que peut-être que je vais montrer la musique que j'ai écrit à quelqu'un qui va dire c'est n'importe quoi, c'est pas de la musique ... mais au moins pour moi, et j'espère pour quelqu'un d'autre, va pouvoir rentrer dans cet état quand la musique te prend et va te faire comme une montagne russe, et qui soit quelque chose qui ait une émotion .... le plus important c'est la musicalité et c'est le truc un peu magique, car elle a la capacité de te prendre et te faire rentrer dans des espaces mentaux, psychologiques, ou je ne sais pas quoi qu'on ne vit pas dans la réalité normale... quand tu es en train d'écouter attentivement la musique, comme dans une salle de concert, ou quand tu mets un casque, avoir une concentration et te laisser porter par la musique ... pas la musique d'ascenseur ... mais voilà c'est le paradigme du concert qui, bon est aujourd'hui un peu fragilisé car que les gens peuvent sortir de tout ça... mais la musique acousmatique, comme on dit le cinéma pour l'écoute, je suis assez d'accord avec ça, voilà c'est comme quand on va au cinéma, un film dans lequel tu rentres... et le son va réagir dans ta psyché, tes émotions, et toute ta perception...  

VG — c'est la part de sensualité, de souvenirs, d'évocations...  

JMF — oui, d'une certaine façon très hédoniste comme pensée... 

VG — ... qui ne sont pas dans les mathématiques 

JMF — oui, pour moi, tout ça c'est des outils... donc les mathématiques, je peux utiliser différents types d'algorithmes chaotiques, stochastiques, etc. mais ça va être seulement des éléments, comme le bruit ou les sinusoïdes, c'est seulement des outils qu'on a la chance aujourd'hui d'avoir toute cette palette qui est des fois mêmetrop énorme, tu peux te perdre parce que tu ne sais pas par où commencer, tellement il y a de possibilités, parce qu'il y a les instruments, il y a les traitements des instruments, tu as le son de synthèse et maintenant en plus tu peux avoir des choses qui peuvent se produire automatiquement de façon très rapide en temps réel, mais... voilà, ces outils si on arrive à se les approprier, et leur donner une directionnalité, une forme musicale ça peut donner je pense des choses très très riches... voilà c'est ça mon idéal ... après si j'arrive à le faire ou pas, bon c'est une autre histoire... 

VG — et tu parlais du fait que tu avais commencé avec Max, puis après SC, as tu l'impression qu'il y a différents instruments numériques — je ne sais pas si tu les appelles instruments d'ailleurs, que tu as développés et utilisés et qui sont identifiés comme entité... est-ce que tu pourrais les compter par exemple ? Est-ce que tu pourrais dire que jusqu'à aujourd'hui tu as fait, une dizaine, une cinquantaine, 200 instruments électroniques ... ou bien est-ce que c'est quelque chose qui était toujours en évolution ? Est-ce qu'il y a des étapes où tu fais un instrument et il a une fin ? 

JMF — non je pense que je n'ai jamais fini un instrument, c'était toujours un \textit{work-in-progress} et je me souviens que... bon je pense que s'il y a quelque chose avec les gens qui font du Max et du SC, la première chose qu'ils essaient de faire — bon, pas tous—, c'est de se créer un environnement ... par exemple, je me souviens dans Max, mon premier environnement, dès qu'est sorti Javascript, ça a été de créer un système de scripting, parce que j'avais l'idée de créer automatiquement les modules et donc j'avais ce que j'appelais un méta-patch, et je l'ai —peut-être pas ici, mais quelque part dans un disque dur, c'est un patch qui disait combien d'entrées tu veux et combien de sorties, est ce que tu veux un spatialisateur, est ce que tu veux un \textit{frequency shifter}, donc j'ai commencé à donner des listes de traitement et après je cliquais un bouton qui s'appelait « build », et il créait tout le patch automatiquement avec les vumètres, les sliders, la matrice audio, la matrice de contrôle avec tous les trucs dessinés, les inputs, les outputs, et donc d'une certaine façon ça c'était un premier instrument, parce que pour moi l'environnement c'est l'instrument et après tu vas seulement lui créer des plugins de cet environnement... et donc c'est un paradigme assez connu, tous les logiciels marchent comme ça, comme Live ou même ProTools, ou Studio Vision pro, ou Cubase déjà avait la notion de plugins et je pense même les mixeurs, on peut dire d'une certaine façon que c'est des plugins qui sont fixes parce que tu as l'équalisateur, le compresseur, etc. mais voilà on peut dire que cet instrument a déjà les plugins incorporés, et mon idée c'était d'avoir un instrument modulaire mais comme je t'ai dit, il n'y a pas que moi, je pense qu'il y a plusieurs gens qui font de l'informatique musicale dans Max, qui se sont créé, j'en ai vu passer surement toi aussi, plusieurs environnement de ce genre, dans lequel tu peux soit créer comme je t'ai dit, une représentation et après le truc va se créer automatiquement, soit que tu vas les faire plus ou moins dynamiquement... donc ça c'était mon premier instrument... et après quand je suis rentré ici à l'IRCAM, ce que je faisais c'est que j'avais un patch qui avait plein de traitements, donc après je le montrais au compositeur et après je faisais par exemple une réduction ... ou bien je créais en même temps des plugins parce qu'il voulait faire un truc déterminé, une abstraction Max ou un patch Max, que je vais rajouter au patch principal pour générer des processus.... Si je veux faire un truc qui fait des rythmes automatiquement, je vais intégrer cette machine dans l'environnement général de Max... et après j'ai beaucoup travaillé avec les capteurs, comment rentrer des données du monde extérieur pour aussi moduler toutes ces machines en tep réel etc. et mon deuxième instrument c'est cet environnement dans SC qui est plus ou moins la même chose, parce que d'un côté j'ai tous mes modules, c'est des plugins, et je pense qu'il n'y a rien de nouveau par rapport à ça... c'est le même concept qu'on a eu de toujours, mais c'est la possibilité que je vais pouvoir construire des environnements tout de suite et dynamiquement et même tout ce que je faisais avant dans le scripting Max, ça prenait des fois quelques minutes, où tu avais le truc qui tournait, la pizza (le sablier sur OSX, NdE), parce qu'il était en train de créer tous les patchs et bpatcher pour la visualisation etc. tandis que là, ça se fait instantanément.... Je n'ai pas calculé combien de temps ça prend... Peut-être que si je fais des graphes audio très complexes ça prend quelques milli-secondes mais c'est instantané, on ne le voit pas... et donc c'est la même chose mais augmenté parce que je le fais en temps réel, automatiquement, je fais une description des processus ou des chaînes de traitement, dans une ligne de code et donc c'est ça pour moi maintenant l'avantage de ce deuxième instrument, je peux dire, que j'ai fabriqué c'est le dynamisme...  

VG — d'avoir l'instrument le plus réactif possible... 

JMF — oui... et que je peux changer comme je veux, le plus souple possible ... j'y ai passé un peu de temps mais je suis assez content du résultat au aussi du fait qu'il y a aussi le langage Antescofo qui va me permettre de piloter cet environnement... donc dans le futur on pourrait imaginer qu'on pourrait faire tout avec Antescofo, donc ils ont déjà fait le test d'intégrer FAUST (Functional Audio Stream, développé par le Grame, NdE), il y a Pierre qui n'est pas là aujourd'hui mais ils ont créé des SynthDef —des définitions de synthèse— dans Antescofo mais qui appelle le compilateur FAUST, donc tu peux créer \textit{just in time} (cf. JIT compiler, NdE) comme ils appellent ça, des modules FAUST... c'est encore trop expérimental et primitif mais peut-être dans le futur on peut avoir un système qui soit plus unifié, c'est le sujet de ma thèse, de faire des partitions centralisées, ça s'appelle mon sujet de thèse...  

VG — Partitions centralisées ? 

JMF — oui, c'est-à-dire d'avoir toute la description de ce qui va se passer dans un seul environnement, ici en l'occurence c'est une partition électronique, c'est-à-dire où je vais avoir tous les processus temporels et les processus de synthèse audio, je vais tout écrire dans un seul environnement... et éventuellement on pourrait aussi aller plus profondément et faire du DSP, du traitement du signal directement aussi ... mais bon, ça dépend de niveaux de complexité... 

VG — du coup Antescofo devient un peu le container de tes partitions... 

JMF — voilà... Antesofo devient un peu le séquenceur, parce que bon la musique se déroule dans le temps, donc je vais lui dire que maintenant je vais commencer tel truc, après je vais avoir un deuxième événement, un troisième etc. mais pour chaque événement, je veux pouvoir faire quelque chose de déterministe, dire déclenche moi une séquence qui va faire 1,2,3,4 mais le 2ème événement je peux lui dire, fais moi un événement qui va dépendre de la vitesse avec laquelle tu as bougé la main, et le 3ème, je vais utiliser des algortihmes mathématiques, et un quatrième où je vais faire interagir différents processus, peut-être déterministes qui vont déclencher des trucs aléatoires ou à l'inverse, des trucs aléatoires qui vont déclencher des trucs déterministes, des séquences ou peu importe, et donc ça devient un espèce de méta-séquenceur, parce que je epxu en même temps créer des processus qui vont s'autogénérer et qui vont aussi être influencés par le monde externe... donc comment agencer tout ça, ça va me permettre d'expérimenter, voir, aller vers la musique... peut-être que je vais avoir une idée et après la faire jouer en temps réel, la faire jouer, je peux la faire jouer en temps réel, et si ça ne me plait pas, je dis non ça, ça ne marche pas, je la jette et .... mais bon ça c'est aussi l'expérience, qu'après tu sais plus ou moins où tu vas, quand tu as une idée, c'est tout l'apprentissage qui est un peu interne et subjectif aussi... 

VG — tu parlais dans Antescofo, du fait qu'on reste sur une notion du temps linéaire, par rapport à cette souplesse d'écriture, est-ce que ce n'est pas quelque chose qui te contraint d'avoir un développement linéaire, plutôt que d'avoir différents fragments qui pourraient être reconnus... 

JMF — disons que tu peux faire les deux... ce n'est pas complètement linéaire et disons tu peux faire des sauts, tu peux appeler différents trucs... et aussi, un autre avantage, c'est que tu peux avoir plusieurs temps en parallèle, donc tu peux faire de la polyrythmie sans aucun problème, disons quelque chose qui va aller dans un rythme, un autre qui va être très rapide, donc tu peux avoir quelque chose qui va se manger, je sais pas, qui va polluer l'autre, le transformer... tu vois tu peux faire ce genre de choses... mais bon moi, ce qui m'intéresse c'est quand même la linéarité, donc je suis peut-être dans ce cas assez classique, on peut le dire, parce que je veux rester dans le mode de la composition où je commence là et je finis là, et milieu j'ai tout un parcours... la montagne russe dont je te parlais, le voyage... j'aime construire ce voyage, même si dedans il y a plusieurs dont je n'ai pas le contrôle, volontairement je dis que je ne veux pas avoir absolu que tous les grains que je veux déployer dans l'espace, parce que c'est l'effet global qui m'intéresse... mais il y a quand même la notion de linarité dans la composition elle-même, après bien sûr on peut faire des trucs plus ou moins complexe... je peux dire que ce qui est arrivé là, après il va arriver là d'une façon transformée ou renversée... mais ça c'est des choses qu'on fait dans la composition depuis la nuit des temps... donc ça reste quand même dans cette idée de composition... parce que ce qui m'intéresse ce n'est pas qu'on ne sache pas, ou que je ne sache pas où je vais aller... bien sûr, après le champ est libre pour ceux qui veulent, Antescofo va te permettre même de faire des états d'improvisation et tu peux faire plein plein de choses... tu vas par exemple pouvoir reconnaître des patterns, par exemple si tu fais Do, Sol, Mi, à chaque fois que tu vas jouer dans ton instrument Do, Sol, Mi, l'ordinateur peut être réactif et jouer quelque chose par exemple... ou à chaque fois que, bon, ça on ne l'a pas encore expérimenté mais, par exemple, s'il reconnaît un geste que je fais avec les capteurs, à chaque fois que je fais un rond avec un geste, l'ordinateur va dire ah maintenant je vais faire telle chose... ou tu peux lui donner un réservoir de trucs à faire, à chaque fois que je fais un kick de main droite vers la droite par exemple... donc tu peux créer des états d'improvisation assez poussé aussi, parce que voilà tu peux avoir plein de réservoirs de trucs qui vont se passer en fonction de comment tu vas jouer ou simplement laisser libre et faire qu'à chaque fois que je regarde la caméra, il va faire un truc tu vois... mais musicalement, ça ne m'intéresse pas beaucoup, mais j'ai quand même expérimenté des choses comme ça, mais je pense que le problème c'est qu'on perd un peu le contrôle... j'ai beaucoup fait d'improvisation et c'est super, mais surtout je trouve pour les gens qui le font... mais des fois pas trop pour les gens qui l'écoute... donc ce qui m'intéresse aussi c'est qu'il y a le public qui écoute, et j'aimerais créer quand même quelque chose qui peut ramener à rentrer dans ce truc qui te prend... c'est ça qui m'intéresse... que la musique te prenne et te... 

VG — qu'est ce qui te fait dire que l'improvisation n'est pas forcément intéressante pour le public ? 

JMF — parce que j'ai joué longtemps dans un groupe d'improvisation et c'était super on était hyper contents mais on le montrait au gens et ils disaient ah oui mais votre truc c'est nul ... ou des fois oui c'est super... mais bon oui, c'est très ... mais bon tu vas me dire toute la musique est comme ça... mais j'ai assisté à beaucoup de concerts de musique improvisée et ça m'est arrivé que, bon pareil je peux avoir écouté un concert et peut-être que je n'aime pas du tout... mais des fois je pense qu'on perd un peu cette espèce de continuité ou je ne sais pas comment dire... mais bon c'est une appréciation personnelle... mais je pense que c'est aussi mon parcours qui m'a amené à faire ça, parce que j'ai aussi expérimenté, mais bon je jouais la clarinette surtout, je ne faisais pas de l'électronique... par exemple... je n'ai jamais eu l'occasion, peut-être que ce serait intéressant... tu dois connaître ça mieux que moi, de jouer, faire une impro électroacoustique ... 

VG — en même temps ta remarque je la comprends... bon c'est difficile de parler de manière générale alors qu'il y a plein de musiques improvisées, mais il y a en tout cas des écueils récurrents dans ces musiques là, surtout en ensemble... par exemple, la raison pour laquelle on a inventé John (John the Semi-Conductor, cf. chapitre Notations, NdE), c'est que parmi les écueils de la musique improvisée, il y a la question des grandes formes qui souvent prennent la forme d'un grand mouvement en cloche, parce que c'est très difficile d'avoir des moments de rupture synchrone avec tout le monde...  

JMF — Oui, par exemple souvent il y a des problèmes de grande forme parce qu'il y a une tendance toujours et donc l'avantage pour moi de la musique écrite entre guillemets, parce que bon on ne peut peut-être plus parler de... je ne sais pas bien ce qu'est l'écriture ou pas maintenant, j'ai une confusion en ce moment... peut-être que je saurai plus dans quelque années... ou pas... peu importe... mais en tout cas l'avantage, c'est que tu sais que là, paf, je veux une coupure nette et que tout le bordel qu'on a fait va se synchroniser et se couper là, à ce moment déterminé et que je vais recommencer un truc, qu'il soit hyper complexe ou pas, et j'ai un contrôle sur le temps que j'aime beaucoup... et c'est ça le truc du compositeur ... j'ai fait aussi des compositions à plusieurs... donc j'ai fait l'année dernière avec un autre compositeur, mais bon c'était séquentiel, disons que chacun a fait une séquence... donc ce n'est pas comme si on avait composé à deux en même temps, mais quand même il reste qu'on a dit tous les deux « ah ici il va y avoir une partie qui va être plus bruiteuse et après une partie plus statique... et après une partie très articulée et après une partie très forte avec un beau crescendo » ... donc tu vois on a créé d'une certaine façon une espèce de forme et après chacun a rempli... après bien sûr au milieu tu peux changer, tu peux dire ah oui, mais ça non, ça peut-être on va les inverser parce que ça va mieux... 

VG — ... un squelette pour la grande forme... 

JMF — oui, un squelette... peut-être que c'est ça ce que tu es en train de faire avec John, un squelette ... mais aussi l'avantage de l'écriture c'est que tu peux faire le squelette mais aussi aller vers la micro-structure, tu peux même composer la micro-structure et je trouve que c'est quand même pas mal, parce que tu créé une sorte d'architecture... là je rejoins encore Xénakis que j'aime beaucoup ... lui étant architecte en même temps, il parlait aussi de cette création de formes, d'architecture de la micro-forme à la structure générale, au bâtiment ou à la pièce ... ça je trouve que c'est l'avantage de l'écriture, et c'est la chose qui m'intéresse en ce moment... c'est pour ça qu'avec Antescofo, tu peux écrire très précisément tous les événements électroniques, avec SC les jouer, et créer les rendus audio, etc.  

VG — tu utilisais l'expression « cinéma pour l'écoute », tu parlais de montagnes russes, tu as utilisé différentes métaphores et tu parlais aussi du fait que tu utilisais des capteurs... une des choses singulières dans les instruments électroniques et numériques en particuliers c'est que lorsque tu branches des choses ensemble, que cela soit des processus, des capteurs, etc. tu peux les brancher de différentes manières, et donc à la différence des instruments acoustiques où tu retrouves le même comportement quand tu jours plusieurs fois les mêmes touches, là chaque touche peut déclencher quelque chose de différent à chaque fois et donc toute l'interaction est scénarisée... Quand tu travailles avec des interfaces, quelle genre de métaphore tu vas utiliser ? Est-ce que par exemple tu as donné des noms à des mappings qui revenaient de manière récurrente ? Comment fais-tu ton chemin là-dedans ? 

JMF — Je pense, encore une fois, que c'est de la structuration, de l'écriture... les capteurs que j'utilise sont déterministes, ce sont des MO (Modular Musical Objects, développés par l'équipe ISMM à l'IRCAM) 9 axes, donc je vais avoir toujours la même donnée, bon, plus ou moins la même, comme je les mets dans un gants, l'idée c'est que ce soit fixe et le plus déterministe possible ... si je fais ce mouvement de la main, je veux savoir que la position de la main est comme ça, et donc du moment où j'ai les capteurs déterministes, ce serait différents avec des capteurs un peu plus ... par exemple des capteurs physiologiques... 

VG — mais même avec des capteurs déterministes, tu peux mapper cette position x à plein de choses différentes qui vont changer à chaque pièces, ou même durant la pièce... 

JMF — oui, c'est là où il y a une espèce d'écriture aussi... parce que je fais d'abord les tests, l'expérimentation et tout ça et travailler avec des musiciens ... et je me dis ah, à ce moment là, je vais utiliser tel type de mapping ... 

VG — c'est-à-dire qu'un geste est associé à un moment dans l'écriture... 

JMF — ... voilà, j'ai même des partitions où j'écris le mouvement des gestes, bouger la main comme ça, etc. Il y a même dans l'écriture des gestes où des fois je mets des traits pour qu'ils jouent des gestes très brusques de percussions ou de karaté, ou j'ai un symbole de repos... 

VG — c'est-à-dire qu'un geste va jouer tel son à un moment de la pièce, mais à un autre moment de la pièce, le même geste pourra déclencher autre chose ? 

JMF — oui, c'est ça... il y a une écriture du mapping, aussi... 

VG — d'accord... donc les métaphores que tu utilises ont une inscription temporelle locale à chaque fois, dans le déroulement de la pièce ? 

JMF — c'est ça oui... mon truc en ce moment, c'est ça, et donc même les mappings, et même les transformations de mapping, parce que je peux dire qu'un mapping va se transformer dans le temps en un autre type de mapping, et tout ça, même des choses très complexes qui peuvent arriver, comme l'utilisation de machine learning, tout va être quand même déterminé à un certain moment de la partition... même si je peux dire que si je fais ça (faisant un geste de la main, NdE) à un certain moment, je peux avoir par exemple un réservoir de sons ou de synthèses, mais à chaque fois que je fais ça, ça va être différent mais dans une certaine ambiance on va dire... donc par exemple je vais utiliser des petits sons aïgus, et passer à des sons graves très aggressifs... 

VG — et généralement, c'est toi qui joue les capteurs ou bien c'est quelqu'un d'autre ? 

JMF — c'est quelqu'un d'autre... je suis encore dans ce paradigme instrumentiste/compositeur, que je donne ma partition et quelqu'un la joue... parce que des fois je me dis je vais faire une pièce où je bouge seulement les mains, mais après il faut le faire... et on sait que les instrumentistes ont un \textit{background} des gestes, des mouvements, beaucoup plus précis que moi... bon j'ai joué du piano et de la clarinette pendant des années, mais je ne joue plus et je n'ai pas la même réactivité et des fois peut-être la même musicalité... même si des fois, il y a des instrumentistes qui sont un peu coincés, parce que quand tu leur mets des capteurs, il faut aussi un entrainement pour eux, pour maîtriser et savoir jouer avec un instrument électronique... et donc ça, c'est un désavantage on peut dire, par rapport à quelqu'un qui les a fabriqués, qui sait jouer son propre .... mais peut-être que cette personne là va jouer toujours de la même façon, parce qu'il a ses conditionnement, etc. et c'est intéressant quand tu construis un instrument de le faire jouer à quelqu'un d'autre, à différentes personnes, et même pour toi si tu es instrumentiste, ça va te donner aussi d'autres idées, sortir un peu... c'est un truc naturel de l'être humain qu'on reste toujours dans un petit espace parce qu'on se sent protégé, on sait qu'on maîtrise ça, mais il y a peut-être d'autres mondes à explorer qui pourraient être très intéressants et c'est pas aussi compliqué non plus de rentrer dedans, c'est juste que voilà, il fallait donner le truc à quelqu'un d'autre... peut-être un musicien africain ou indien, ils vont changer complètement ta perception du truc et ça va te donner un autre retour qui va, voilà peut-être te faire partir dans de nouvelles voix... et ça c'est très important je pense, on peut faire un parallèle entre la musique et la vie, on est toujours comme ça (faisant des signes de changements de directions, NdE), après on a des bas et des hauts, et des fois on se sent super bien, des fois on se sent très mal... donc la vie c'est tout lié pour moi de toute façon... donc le fait de regarder d'autres cultures ou d'autres gens dans ce cas là qui jouent, peut t'apporter beaucoup personnellement et musicalement...  

VG — je parlais des métaphores que tu peux utiliser pour la composition, mais quand tu confies ton instrument à quelqu'un d'autre, même si tu peux lui laisser découvrir l'instrument par lui-même, tu es amené à lui transmettre des instructions, et ce ne sont pas des instruments qui ont une histoire, donc c'est à toi de dire ça fonctionne comme ça et peut-être utiliser des métaphores ? 

JMF — oui... il y a justement la tradition orale, qui est quelque chose de très ancien, mais qui est toujours très très moderne aussi... parce que voilà on construit un instrument ou un logiciel, mais il faut quand même les apprendre, faire des tutoriels dans YouTube pour que les gens apprennent à l'utiliser... donc même si on utilise des technologies très sophistiquées, mais il y a toujours ce rapport qui était là avant l'écriture ... ou dans d'autres traditions... parce qu'il y a des traditions où il n'y a pas d'écriture du tout, d'autres où il y a plus ou moins, et l'occidentale où tout est hyper précis... mais même dans l'hyper-précision il y a toujours le prof qui va enseigner la technique, jouer le piano avec un certain toucher, qui a ce rapport de tradition orale, et qui est fondamental... 

VG — je pensais notamment au fait que tu as un certain vocabulaire qui existe pour la musique comme \textit{staccato, pizzicato, sul ponticello}, etc... qui sont utilisés pour les instruments qu'il est possible de réutiliser dans d'autres contexte... on discutait une fois de la manière dont on peut enseigner les instruments électroniques sachant qu'il n'y a pas vraiment de standard, de forme réifiée et pérenne d'instrument électronique, comme il existe pour les instruments acoustiques... les interfaces sont à chaque fois variées, certains jouent avec des claviers, d'autres avec des pads, d'autres avec des capteurs et arduino... et comment faire pour ne pas repartir de zéro à chaque fois qu'on en discute ensemble... et il y a peut-être un vocabulaire qui se développe pour la musique électronique, par exemple si tu joues de la synthèse FM, si tu la joue avec des capteurs arduino ou avec un clavier, cela ne va pas être la même ergonomie du tout, mais quelque part il y a un objet similaire que tu retrouves, avec certains timbres comme des cloches, des cuivres, etc. le « son » de la FM...  

JMF — oui c'est par rapport au résultat sonore dans ce cas... 

VG — il y a un objet abstrait qui existe qu'on peut transposer sur différentes interfaces, et dans lequel on peut retrouver des chemins... et c'était aussi par rapport à ça que je te posais cette question des métaphores, de la manière dont tu développes un langage pour parler avec les instrumentistes avec qui tu travailles pour pouvoir échanger, dans la mesure où, cet espace de timbres de la FM par exemple, n'est pas enseigné en formation musicale... 

JMF — oui c'est sûr qu'il n'y a pas vraiment de relation entre les instruments traditionnels et les instruments numériques ... ce qui rend aussi peut-être des fois une vie assez courte parce qu'il n'y a pas beaucoup d'instruments qui restent dans le temps, comme ça évolue toujours... le violon est arrivé à son maximum de perfection avec je sais pas, Stadivarius, et le piano avec, je sais pas, Pleyel ... et après il est resté dans cet état là... et personne s'est demandé, oui, maintenant on peut faire les pianos électroniques et tout ça mais ça reste quand même le violon... dans les musiques avec instruments numériques, il y a souvent une vie courte, parce que la personne qui les fait, c'est souvent une personne et une fois qu'il l'a fait, il dit ok je vais faire un autre, je passe à autre chose et celui là il reste là, comme une pièce de musée, presque, même si ça a été fait l'année dernière, et après on passe à un autre, et on passe à un autre, et on passe à un autre... c'est comme les logiciels... 

VG — Oui, il y a beaucoup d'instruments qui sont fait par pièce, en fait, qui ne sont peut-être pas tant des instruments que des agencements d'instruments, parce que comme tu le disais tout à l'heure quand tu parlais de ton « instrument », tu parlais de ton environnement, quoi... qui j'imagine ne change pas à chaque pièce...  

JMF — non ce qui change c'est le contenu disons de comment je vais le gérer... 

VG — tu changes les plugins, tu changes les capteurs... 

JMF — ... mais la structure va être la même oui... c'est une base assez souple mais j'utilise constamment deux logiciels, Antescofo et SC dans un cadre quand même déterminé... même si on peut faire tout et n'importe quoi avec, mais je suis dedans... et par exemple dans les instruments que toi, tu connais bien, il y a vraiment très peu d'instruments qui perdurent dans le temps, et paradoxalement c'est peut-être les premiers, le Théremin, bon les Ondes Martenot peut-être un peu moins, je ne sais pas s'il y a encore le cours au CNSM de Paris, mais c'est plutôt ces instruments plus anciens dont je vois qu'ils perdurent dans le temps... bon et après bien sûr il y a les synthés classiques comme le Moog et les autres qu'utilisent les rockers, mais... 

VG — j'ai l'impression qu'il y a des « organes » d'instruments qui restent, par exemple le clavier ... 

JMF — Voilà ...  

VG — et dans les choses qui survivent, ce n'est peut-être pas tant les organismes complets que les organes eux-mêmes, c'est-à-dire que le clavier c'est un des organes du piano, du clavecin, de l'orgue... et il reste le clavier, on le retrouve sur le Seaboard (de Roli, NdE), et d'autres instruments nouveaux... 

JMF — oui, on a continué à ... oui... 

VG — et il y a à la fois des objets physiques comme le clavier, mais il y a aussi des objets abstraits comme les notions de théorie musicale, comme les gammes, qui sont abstraites mais qui s'inscrivent dans le corps des instruments, et qu'on va retrouver dans les algorithmes de traitements tels que les arpéggiateurs, les grilles de quantisation... c'est un élément abstrait de l'écriture mais qui se traduit physiquement dans des outils de lutherie numérique, qui prennent corps dans les instruments numériques... et du coup ma question, comme tous ces instruments sont très disparates, qu'il y a plein d'éléments de partout et qu'on va utiliser Antescofo, Max, SC, sur un environnement et qu'il est très difficile de tout connaître, il y a ces communautés qui s'organisent sur internet en forums de discussions et si on ne sait pas se servir de quelque chose, on peut poser une question et avoir la réponse sur un forum... Nick Collins disait quand je l'ai interviewé que faire des instruments s'apparentait aujourd'hui à faire de la cuisine, qu'il n'y avait pas besoin d'être un grand chef, car tout le monde sait cuisiner, en récupérant les ingrédients ici et là... 

JMF — de la bidouille... 

VG — oui, il y a un côté bidouille... et il y a beaucoup d'échanges, si on regarde la page Facebook de Max, il y a plusieurs milliers d'utilisateurs dessus, la page d'Ableton Live, n'en parlons pas... donc il y a vraiment un fonctionnement collaboratif, avec des gens qui font des tutoriels et tout ça... ce qui contraste un peu par rapport à une vision un peu plus solitaire du luthier qui fabrique son instrument seul dans son atelier, enfin c'est l'époque qui est comme ça, plus connectée, et la question que je voulais te poser c'est comment toi tu as vécu ça, car quand tu as commencé dans les années 1990, internet n'était pas encore là et tu parlais du manuel papier de Max 2.5, c'était peut-être un travail un peu plus solitaire de lire ça ... 

JMF — oui... mais je pense que j'ai toujours été assez solitaire, bon sauf quand j'étais un Maxeur à fond, parce que là je suivais la mailing-list Max, j'étais beta-testeur, mais ça a duré une période et ça fait des années que je ... bon de temps en temps je vais aller regarder quand il y a un truc qui m'échappe dans Max mais c'est très rare d'aller dans les forums... maintenant je suis le forum de SC, et je ne le vois peut-être pas tout le temps, parce que bon Max, je suivais vraiment tous les différents \textit{thread} etc. bon il n'y avait peut-être pas autant d'utilisateurs, et peut-être que maintenant c'est impossible de suivre tout sinon tu y passes toute ta journée comme sur FaceBook, mais à l'époque voilà, il n'y en avait pas autant... mais maintenant je suis un peu SC, mais par exemple Antescofo, c'est quelque chose qui n'a pas encore une grande communauté, du moins sur le langage de programmation, donc déjà Antescofo, il y a des gens qui le connaissent mais pour qui c'est un suiveur de partition, tout le monde ne sait pas qu'Antescofo, sauf peut-être les gens du forums IRCAM, possède un langage de programmation qui te permet de faire plein de trucs et donc en ce moment là, on est vraiment une communauté très très réduite... SC, c'est différent, il y a une communauté active avec plusieurs emails par jour, ce n'est pas le débit de Max, et ne parlons pas de Live, mais dans ce chemin d'Antescofo je pense qu'on reste d'une certaine façon ésotérique, une secte d'une certaine façon, pas dans le sens péjoratif du terme, mais dans le sens qu'on est un peu fermé, parce qu'on n'a pas encore eu l'occasion de montrer tout ce qu'on fait parce que c'est relativement nouveau... et aussi il y a le code, qui est une syntaxe que tout le monde n'aime pas, parce qu'il y a des lignes où tu te dis ouh la la, ça peut me rappeler mes cours de mathématique ou de physique quand j'étais à l'école... et si je n'aimais pas ça, peut-être... ou je ne sais pas, il peut y avoir plein de raisons, ça c'est un truc que je viens d'inventer bien sûr... on peut avoir des fois peur du code, plus que d'un langage comme max où c'est visuel et peut-être tu dis dit ah oui, je sais ce que je suis en train de connecter, je sais que c'est la sortie là qui va rentrer là, et qui va sortir par là... donc c'est beaucoup plus direct comme approche 

VG — Antescofo, il y a peut-être aussi un côté confidentiel dans le fait que... le code est public? 

JMF — oui, c'est public, tu peux le télécharger sur l'IRCAM  

VG — ah je ne savais pas ça 

JMF — mais tu n'es pas le premier à me le dire  

VG — parce qu'il y a une startup qui a été créé et je suis sur la mailing list donc je pensais que quand il sortirai le logiciel je serais au courant, mais je n'ai pas vu passer le code... 

JMF — oui, ils ont sorti un logiciel qui s'appelle Metronome... non, Metronaut... et maintenant la distribution IRCAM est gratuite, je ne suis jamais allé la télécharger sur le forum IRCAM, mais théoriquement tu peux t'inscrire sur le forum et la télécharger... et il y a des tutoriels ... mais voilà ça reste encore un peu une niche parce que d'un côté c'est très nouveau, et d'un autre il y a l'aspect code qui peut être un peu aussi, euh... c'est pour ça que SC il y a beaucoup moins d'utilisateurs, parce qu'apprendre c'est un peu plus compliqué... Max a ce côté un peu comme un jouet où tu t'amuses comme un Mécano, c'est beaucoup plus amical et c'est même ludique, je pourrais dire ... tandis que quand tu dois écrire des lignes de code et penser « ah, ça ça doit rentrer là » c'est un peu plus un truc d'information, de geek... 

VG — oui, tu oublies le point virgule... 

JMF — oui, voilà, tu oublies le point virgule ou quelque chose comme ça et ça ne marche plus, donc oui tu perds des heures sur ça... bon après sur Max tu peux perdre des heures sur autre chose, mais je pense qu'il y a cette contrainte là, qui est un peu illusoire à mon avis, parce que bon moi, comme je t'ai dit j'étais complètement addict à Max, et finalement il n'y a pas trop de différence dans la programmation graphique et la programmation textuelle, c'est finalement la même chose mais voilà l'un à l'air plus pour jouer et l'autre plus un truc de geek, et tu peux créer des préjugés très facilement, parce que peut-être on a un peu de paresse aussi, parce que peut-être il faut réfléchir un peu plus, bon avec Max aussi il faut réfléchir parce que c'est quand même de la programmation... bon mais c'est ça que je veux dire, qu'à la fin les deux sont des langages de programmation, l'un est visuel, graphique ou block-diagram, et l'autre c'est textuel et en série, mais c'est quand même un raisonnement logique, si tu veux que ça, ça rentrer là et que ça fasse un multiplier et diviser par machin-truc, c'est la même chose, sauf que l'un tu écris une ligne et l'autre tu connectes des boites...  

VG — sur Max, c'est comme on dit le « low entry fee »  

JMF — comment tu dis ? 

VG — c'est le concept du « low entry fee » et « high ceiling » qui avait été formulé dans un article par David Wessel (cf. \cite{wessel_problems_2001}, NdE), de pouvoir rentrer facilement dans un logiciel, ce que ça va te coûter pour installer le logiciel et faire tes premiers sons d'une certaine manière... 

JMF — oui, voilà ... on a l'habitude, surtout dans notre société, qui nous ramène de plus en plus aux trucs déjà prêts, on a ça déjà presque dans les gènes, et donc quand tu vois un truc qui ne marche pas du premier coup, ou qui est trop compliqué, tu dis non c'est pas la peine si avec Live je peux faire la même chose ou beaucoup plus et je ne vais pas avoir toute cette courbe d'apprentissage pour faire un son qui fait pouet pouet, tandis que dans Max for Live j'ai tout un environnement déjà prêt où je prends un module et je fais un gros son tout de suite, tu vois... et je peux faire des \textit{break-point} et moduler et donc dans deux secondes je te fais une compo géniale et dans l'autre truc, ça fait un an que je tape mon clavier et voilà, j'arrive à faire quelques sons mais je n'ai pas la flexibilité et ce que j'ai dans Live... sauf que ... bien sûr tu peux faire tout, c'est mon avis encore une fois, les gens peuvent le partager ou non, et surtout pas ceux qui font du Live, mais dans Live le problème c'est quand même que tu as une boite à outil qui est très fermée, même si tu as l'impression que c'est très ouvert, parce que tu peux prendre, bon, comme dans mon système, des plugins et tu les mets, mais... mais c'est tout, tu ne peux pas faire plus que ça... après si tu veux faire des trucs un peu plus complexes avec le rythme de là qui va aller contrôler ça, ou même récursif... là tu ne peux pas parce qu'il est fait seulement pour avoir une timeline... c'est fait pour faire un type de musique assez spécifique, pour faire des loops, bien sûr maintenant ça c'est beaucoup étendu donc tu peux faire des trucs plus complexes que faire des loops ou tu peux faire des loops très complexes aussi... mais ça reste quand même orienté dans un truc déterminé... et moi je n'aime pas ça, justement, parce que je veux peut-être expérimenter, avoir des curseurs allant à différentes vitesse, et qui vont faire peut-être des rubatos par exemple qui vont peut-être changer dans le temps, qui vont, voilà, s'entremêler et moduler d'autres curseurs qui vont être en bas par exemple, c'est l'idée de... de tempos qui vont être moduler entre eux, des choses comme ça, et chaque groupe va être différent, de séquences, de tracks, de break-points... mais voilà si je veux faire ça, je ne peux pas si je veux suivre un instrumentiste avec les inputs, il n'y a pas que je sache, ou peut-être on peut le faire, un plugins Max for Live avec Antescofo, je ne sais pas mais pourquoi pas... mais bon c'est peut-être plus difficile après pour gérer... donc tu vois c'est vraiment très... 

VG — c'est comme l'autoroute... tu vas plus vite mais tu n'as pas le temps d'aller explorer les paysages que tu traverses...  

JMF — voilà... c'est parfait comme métaphore, je vais la noter celle là... elle est parfait celle-là, parce que justement c'est une autoroute qui peut te permettre de faire passer des gros camions, mais ... 

VG — ... tu rateras les chevreuils, les sangliers, et les autres espèces inconnues sur ta route... 

JMF — Oui, et c'est finalement ce qui arrive dans notre société où on nous façonne notre façon de faire... dès petit on nous dit il faut faire ça, ça, ça, et puis quand tu es plus grand, il faut faire ça, ça, ça... et après il y a peut-être tout un autre monde beaucoup plus riche à découvrir qui est à côté... et voilà c'est exactement, c'est parfait ta métaphore... 

VG — La création c'est peut-être aller voir sur les chemins de côté... 

JMF — voilà... après n'empêche que peut-être l'outil va évoluer et que peut-être tu peux faire des petits sauts sur les côtés, juste pour voir un peu et après revenir dans ton autoroute, mais disons c'est ça l'idée que ça continue à évoluer pour peut-être se ramifier un petit peu, mais tu ne vas pas pouvoir non plus aller voir peut-être le truc qui est vraiment là... 

VG — ... caché au fin fond de la forêt... 

JMF — ... au fond de la forêt, derrière la dune où tu peux te baigner et il y a le soleil magnifique, une cascade... (rires) 

VG — c'est pour ça qu'on fait du SC, c'est pour trouver la cascade au fond de la forêt... (rires) 

JMF — voilà... bon... je ne sais pas si c'est vraiment ça mais on peut faire de la métaphore et de la comparaison et c'est surtout que voilà, moi je ne me suis pas du tout intéressé à Live, même ici, ils l'utilisent en prod à fond, tu vois les RIMs utilisent à fond Live, Max for Live, parce que tu mettre... il y a quelques RIMs qui l'utilisent qui ont tout un environnement dans Max mais pour faire du prototypage... donc tu es avec le compositeur qui dit je veux faire ça et ça, et donc au lieu de faire le patch Max, tu prends tes plugins, tu les mets dans ta chaine et après tu fais quelques courbes, et donc là le compositeur dit « ah, super, c'est génial c'est ça » et après il repassent dans Max par exemple ... donc ça c'est une pratique, je ne sais pas s'ils le font encore, mais c'était une des pratiques qu'il y avait, avec en parallèle les mêmes traitements dans l'un que dans l'autre, sauf que dans Max c'est plus difficile parce qu'il faut mettre les boites, bon sauf si tu as un système de scripting comme je te décrivais avant, où tu peux faire des patchs dynamiquement... et surtout oui, l'idée c'était que je puisse enlever, remettre, tu vois, des modules, automatiquement dans le patch...  

VG — oui, Serge Lemouton en parlait hier de ça, du fait que non seulement les gens utilisaient Live mais que certaines pièces qui étaient finalisées avec Live et que ça devenait aussi un problème pour la préservation, la conservation et la documentation des œuvres... il parlait des pièces qui ont vingt ans et déjà avec Max, qui est un langage d'assez bas niveau, donc tu peux arriver à reconstituer une pièce même si les versions de Max ont changé, mais Live c'est beaucoup plus complexe et touffu comme environnement, donc ça pose plus de problèmes... 

JMF — oui, oui, c'est un problème, s'il y a un nouveau, c'est très risqué, bon moi je m'en fous un peu mais si jamais on peut penser à un logiciel qui tout d'un coup est un grand concurrent de Live et que tout le monde commence à passer sur cet autre logiciel, Live d'ici dix ans n'existe plus... je ne pense pas qu'ils vont mourir tout de suite, mais ça peut arriver... et comme souvent dans les marchés, c'est les marchés qui bouffent tout, et s'il n'est plus compétitif, on ferme la boite... et tu es obligé de garder les ordinateurs, parce que ça ne va pas marcher sur l'OS suivant... donc voilà, il faut garder tout... ce qu'il va falloir faire c'est garder les ordinateurs avec les configs, tout, dans des espèces de stockage... bon après il va y avoir des problèmes de stockage... et aussi les maintenir dans le temps, parce que si tu laisses des machines qui ne marchent plus pendant dix ans ou vingt ans, quand tu va l'ouvrir tu vas appoyer sur power et il va y avoir un silence... plutôt que l'accord de démarrage de mac... donc c'est sûr que c'est un gros problème... l'avantage des langages textuels c'est justement ça, que les définitions sont faites dans un fichier texte et donc c'est rien du tout, mais toutes les abstractions et toutes les définitions sont un langage plus ou moins informatique donc c'est facile de le ré-interpréter... même si tu veux faire un portage, tu peux facilement prendre le code, le transformer, ou même créer un script qui va transformer un langage comme par exemple Antescofo à cet époque, et peut-être dans cinquante ans quelqu'un voudra jouer cette pièce et il prendra le langage et il va le traduire dans peut-être un autre qu'il y aura à l'époque... mais comme c'est textuel, il faudra juste un petit script qui va scanner, analyser le truc et comme c'est que des fonctions logiques, ça va le ... 

VG — ...le porter dans « hyper collider » ... 

JMF — voilà... je ne sais pas ce qu'il va y avoir dans cinquante ans ... mais bon pour moi, ça n'est pas trop un problème, pour Serge bien sûr parce qu'il est en plein dedans, pour moi ce n'est pas ça plus que le problème plus que c'est une boite fermée... il y a des environnements qui sont des boites fermées et moi je ne veux pas faire ça... 

VG — oui, il y a aussi un problème personnel de se trouver déposséder de ton travail parce que le logiciel meure... 

JMF — oui, bon là tu migres après dans un autre truc, je l'ai fait plusieurs fois... j'utilisais ProTools à la base et un jour je n'en pouvais plus avec DigiDesign, c'était à l'époque, parce que je voulais avoir un truc plus puissant, mais il fallait acheter une carte qui valait, je ne sais pas, 5000€ ou 10000€ et j'ai dit non, laisse tomber je n'utilises plus ce truc... et j'ai arrêté du jour au lendemain, et j'ai fait du Logic (Apple Logic Pro, NdE) que je pouvais craquer plus facilement, je n'avais pas besoin d'avoir une carte... bon, après je l'ai acheté, bien sûr... mais ça marchait, c'était presque pareil... bon maintenant il y a Ardour qui est pas mal aussi... bon je ne l'utilises pas mais... un des avantages des logiciels Open-Source ou gratuit, c'est qu'il y a toujours, c'est le cas pour SC, il est gratuit depuis 15 ans à peu près, quand James McCartney a décidé de le donner en Open-Source et il y a toujours eu cette communauté, mais si ça a changé, mais le logiciel reste toujours Open-Source, gratuit et il continue à avancer ... peut-être que ça n'avance pas à des pas gigantesque, mais là, voilà si on voit Max8, on voit aussi que même si c'est un truc payant, ça n'avance pas non plus énormément, ça reste plus ou moins la même chose... le moteur de base c'est toujours le même et le code pour faire du DSP, ils ne l'ont pas optimisé ... et ce truc là justement ne permet pas trop de faire de trucs dynamiques, parce que ça peut commencer à cliquer, il n'est pas fait pour ça, tu vois... donc tu ne peux pas commencer à créer et détruire des patchs à la volée parce qu'il n'est pas optimisé pour faire ce genre de trucs... 

VG — ça a commencé peut-être justement comme un logiciel qui permettait d'aller dans des petits chemins à explorer et ils essaient un peu de faire des bretelles vers l'autoroute... ils ont optimisé le workflow pour que tu puisses travailler plus rapidement ... 

JMF — oui, là en plus c'est acheté par Ableton... donc ils sont passé du côté ... je ne sais pas si c'est obscur ou clair de la force, mais ça va vers l'autoroute, ça c'est mieux comme métaphore ... où le graphisme est très important, tellement important que c'est même dérangeant des fois, des trucs automatiques parce que tu ne voulais pas connecter là et il te le fait... j'ai eu un peu de mal à passer à Max7 justement, parce que je faisais les câbles et je voulais connecter là et ça partait vers le haut, parce que maintenant tu peux connecter le haut et le bas, donc tu as plus de possibilités mais des fois tu n'as pas l'habitude donc c'est plus des gadgets ... je ne sais pas si dans Max8 par exemple ils ont fait le truc pour connecter automatiquement, donc tu sélectionnes comme avec le plugins Toolbox (package Max Toolbox de Nathanaël Lécaudé, NdE)... 

VG — en partie oui... 

JMF — oui, parce que j'ai vu que tu pouvais insérer des objets... ça c'est super, ça existe dans Pd-extended depuis vingt ans je pense... c'était quelqu'un qui avait fait des extensions pour Pd où tu pouvais faire ça, il y a vingt ans je te dis...  

VG — oui, je ne sais pas pourquoi ils ne l'ont pas intégrer plutôt, la Max Toolbox, même maintenant ce n'est pas encore intégré... les connections un vers multiple ce n'est pas encore ça... 

JMF — oui, et ça c'est des trucs de base, parce que la tendinite que j'ai eu à force de câbler, je l'ai encore...  

VG — je vois très bien ce dont tu parles... ça s'améliore, mais ce n'est pas encore ça... il y a un truc qu'ils ont mis en place, encore à titre expérimental, c'est d'essayer de moins faire de distinction entre le mode d'édition et le mode d'action...  

JMF — entre lock et unlock 

VG — oui... que tu puisses faire un bang ou une number box alors que tu es en mode d'édition... 

JMF — mais ça on peut le faire avec la touche Pomme... 

VG — oui, c'est un peu ça mais dans l'autre sens en fait ... 

JMF — oui, mais tu vois ça reste superficiel... oui ça peut être sympa mais bon on a déjà des habitudes donc ... 

VG — c'est des choses pour faciliter le \textit{workflow} et le \textit{low entry fee}... parce que toutes les choses de scripting dynamique et tout ça, ce sont des choses très avancées, il n'y a pas tant de gens qui font des choses comme ça en fait... je serai curieux de savoir quel pourcentage d'utilisateurs ça représente... je ne pense pas que cela ne soit lié qu'à ça mais il y a une tendance générale dans les logiciels avec l'arrivée de tablettes et d'iOS etc. d'application monotâche... qui font un seul truc... avant tu avais des logiciels qui permettaient de faire plein de choses, des logiciels comme Word ou des suites Office ou photoshop, qui existent toujours pour la production, mais il y a aussi maintenant plein de logiciels qui permettent d'appliquer un certain nombre de filtres sur une image ou de faire ... 

JMF — ... oui pour faire plus vite et qu'il n'y ait pas besoin de connaître... 

VG — des logiciels très limités avec peu de fonctions mais qui vont être connectés par exemple ... qui vont faire un seul truc très spécifique... 

JMF — oui 

VG — et pour l'audio, il y a aussi parmi les apps sur iOS, tu vas trouver un granulateur par exemple, un programme qui fait uniquement de la synthèse granulaire... c'est un peu un plugin autonome...  

JMF — Peut-être qu'on va vers ça... on est en plein dedans je pense même... parce qu'ici l'IRCAM c'est une espèce de niche avec peu de monde, donc on est peut-être un peu des marginaux, d'une certaine façon... et en relation à la tendance générale, comme Live ou même Max for Live, c'est pas pour tout le monde non plus, on en parle comme ça, mais... mais peut-être pour un utilisateur qui fait que du Live, un logiciel comme Max4Live il va trouver que c'est pour les geeks... tu vois... que pour nous, c'est un truc qu'on ne veut même pas utiliser... mais tu vois, il y a peut-être une tendance à ce genre d'outils qui sont prêt à utiliser... plug'n play ... où tu as deux boutons et voilà... et peut-être que nous on est des extra-terrestres résistants qui ne veulent pas s'aligner dans le courant, dans l'autoroute justement ... je ne sais pas pourquoi mais on ne veut pas prendre l'autoroute et on continue à... bon, après bien sûr c'est... 

VG — en tout cas il y a une tendance à y avoir plein de logiciels très simples qui ne vont réaliser qu'une seule tâche... mais ce n'est pas forcément l'autoroute dans le sens où c'est aussi un peu, même si le contexte économico-social est très différent, le fonctionnement de Linux ... dans Linux il y a aussi cette tendance à faire des petits packages unitaires qui vont faire juste une fonction particulière, mais avec l'idée que tu peux utiliser des \textit{pipes} pour envoyer le résultat de la sortie d'une application dans l'autre, ou comme JACK (JACK Audio Connection Kit, développé par Paul Davis, NdE) qui s'est développé aussi comme ça ... 

JMF — oui donc tu peux créer un réseau fait de petits bouts, quoi... 

VG — voilà... tu as un logiciel qui ne fait que éditeur de notes, qui ne fait aucune synthèse, et tu vas envoyer ça avec JACK-MIDI dans un logiciel qui ne fait que la synthèse ... et ce fonctionnement très modulaire correspond aussi à un développement par des gens qui font ça de manière bénévole ... Développer un gros logiciel, c'est quelque chose qui est difficile pour une communauté anarchique et informelle ... Si tu veux développer un truc comme Live, c'est un peu les limites, par exemple Ardour existe mais ça a été très compliqué je crois pour Paul Davis de porter un truc comme ça tout seul parce que c'est une grosse usine... et c'est difficile de maintenir ça tout seul ou même à plusieurs sans qu'il y ait au moins une organisation, pas forcément lucrative, pas forcément une entreprise mais une fondation comme pour Wikipedia où se décident les politiques de développement... alors que les petites applications, c'est possible de les faire en tant qu'indépendant ...  

JMF — oui... mais bon j'ai vu quelques séquenceur qui ont l'air pas mal dans iOS et aussi un espèce de JACK où tu peux connecter différentes trucs par MIDI ou audio...  

VG — oui, c'est des choses qui se développent... 

JMF — oui... c'est peut-être une voie mais je pense qu'il faut aussi des choses centralisées parce que tu peux avoir différents satellites, on peut dire, mais il faut quand même un truc central qui va donner les informations et qui va recevoir les informations de chaque satellites, qu'est ce qu'il est en train de calculer, qu'est ce qu'il est en train de faire, mais moi je vais lui donner l'ordre maintenant de faire telle tâche... donc c'est peut-être une voie mais il faut quand même un qui gère d'une certaine façon ... après il peut y avoir un fonctionnement un peu comme internet où il n'y a pas vraiment un serveur central mais que tout le monde peut parler avec tout le monde sans hiérarchie... mais bon il faut quand même il faut l'exprimer quelque part et pour moi pour l'instant c'est Antescofo... après oui, les satellites peuvent par exemple les synthétiseurs dans SC c'est un satellite, mais lui quand même il créé des sons mais aussi il me renvoie des informations parce qu'il y beaucoup d'analyseurs, par exemple d'\textit{onset detection} ou je sais pas quoi ... et il va aussi me renvoyer ... et aussi tous les niveaux des vumètres donc je peux avoir par exemple un iPad et je vais créer une interface où je vais tout voir les groupes de groupes ... où chaque slider c'est un groupe de groupes et donc je n'ai pas besoin d'avoir l'interface sur l'ordinateur parce que je l'ai sur iPad mais je reçois les VUmètre, la somme de trucs qui sont en train de marcher sur ce \textit{track}... dans les concerts je fais comme ça, j'ai mon iPad avec les différentes \textit{tracks} dont je peux jouer avec les niveaux de sons si je veux un peu plus de niveau... 

VG — ...comme je commence par poser la question de ce qui t'a amené à faire ça, la question finale si on en reste là pour aujourd'hui, c'est si tu fais un pronostic pour dans 10 ans, 20 ans ou 50 ans, comme tu disais tout à l'heure... qu'est ce que tu vois, sachant qu'on n'est pas encore arrivé aujourd'hui encore, y arrivera t on jamais, à un langage ou un environnement idéal... qu'est ce qui te manque, toi ? 

JMF — non je pense que moi ce qui me manque dans l'immédiat c'est peut-être d'avoir plus de facilité d'intégrer tout ce \textit{workflow} dans quelque chose d'un peu plus souple ... parce que bon là, c'est toujours le code ou l'interface graphique d'un côté... donc pour moi, ce qui serait intéressant, ce serait d'avoir un logiciel qui soit mixte, comme un miroir... avec d'un côté une représentation graphique, mais d'un autre le code... donc tu peux faire des allers-retours... et donc si je veux faire un slider je le fais tout de suite avec le code ou je le fais comme dans Max, je prends le slider, je le créé et puis voilà automatiquement il va me faire la sélection au niveau graphique ... mais ça peut être aussi au niveau d'une chaîne de traitement, où je peux avoir une chaîne de traitement et de l'autre côté je vais avoir une représentation en graphe et les connections et que je peux même changer et ça va automatiquement changer le code... un truc comme ça où le \textit{workflow} c'est beaucoup plus dynamique, la façon d'interagir... parce que voilà mon truc ça a l'air très dynamique et je peux faire beaucoup de trucs mais je suis toujours dans le code et des fois voilà le code, si tu oublies une virgule ou un crochet, voilà il faut ... bon au moins le programme est intelligent et il te dit où tu as fait une erreur et tout ça ... mais peut-être que j'aimerais des fois éviter de faire du code et donc ... parce que bon, moi aussi, je suis toujours un Maxeur mais je pense que la partie graphique c'est quand même important comme un retour aussi d'expérience, des connections, voilà toutes les machines audio qu'on a, même les analogiques, on connecte des câbles... c'est peut-être pour ça aussi que ça marche très bien , parce que c'est très analogique en fonction de comment marche les machines en général, au moins pour l'instant... parce que dans le futur, justement, il n'y aura peut-être plus de câbles mais pour l'instant il faut câbler, et tu sais c'est très intuitif comme raisonnement ... le code c'est beaucoup plus abstrait comme mode de raisonnement, c'est beaucoup plus bas niveau ... et donc peut-être qu'il manque dans mon truc de pouvoir passer de l'un à l'autre, je ne sais pas si je vais le faire un jour... bon là je fais des interfaces qui se créent automatiquement pour avoir un peu la main sur différent trucs, mais aller encore plus profond même dans le code, dans les structure et trouver des façon de créer des algorithmes d'une façon graphique qui vont après être interprétés en code ... après bien sûr il y a des trucs que tu ne vois pas tout simplement, du moins au jour d'aujourd'hui, je ne vois pas comment l'imaginer de faire un graphisme des types de processus par exemple... que dans le code, ce n'est qu'une ligne de code, mais comment je vais représenter ce que fait ce processus d'une façon graphique, je ne sais pas... peut-être qu'il y a des logiciels comme Mathematica ou je ne sais pas, des choses qui font ça, ou d'autres trucs des mathématiciens... mais au moins pour tout ce qui est du contrôle, ce serait bien d'avoir ce logiciel idéal, en ce moment, qui serait voilà, de passer de l'un à l'autre avec les deux représentations... comme Gen (l'extension de Max permettant de créer de manière visuel des graphes convertis en code compilé, NdE) aussi, tu vois... voilà Gen, il y a un peu aussi cette idée... 

VG — FAUST aussi ... 

JMF — FAUST oui, mais dans FAUST tu ne peux pas aller interagir sur la représentation graphique... mais Gen tu peux agir et changer les câbles et ça va te changer le code automatiquement, donc ça par exemple c'est un truc qui m'intéresse dans Max... et puis bon après, je n'ai pas la boule de cristal avec moi pour te dire dans 50 ans mais je pense que ça dépend beaucoup, pas que de la musique, mais au moins il y a une partie de la société et de la politique, et de comment va le monde ... et par exemple on ne sait pas si des structures comme l'IRCAM vont exister dans 50 ans... c'est une structure qui soutient une sorte de recherche fondamentale, d'une certaine façon, c'est vraiment des réflexions... peut-être que ça va être chacun chez lui... parce que je ne crois pas que ça va exister encore... mais bon, c'est mon idée, mais j'espère que non, que ça va durer pendant des siècles... mais toujours les choses ont une durée de vie, tu nais, tu vis, et puis tu meurs et ça peut arriver pour tout, même pour la Terre, on sait bien que ça va finir un jour et même le système solaire... donc ce genre d'expérimentation, c'est je pense chacun qui va la faire chez lui, parce que bon on n'a plus finalement besoin de grandes structures comme l'IRCAM parce que tu peux bidouiller chez toi, et après s'il y a la communauté, comme tu dis, ça c'est très important de garder les communautés, de les agrandir, des communautés de gens qui veulent expérimenter ou bidouiller, parce que c'est ça qui est intéressant je pense... Si tu restes dans ton autoroute, bon c'est pas très ... tu peux peut-être gagner de l'argent, faire plein de trucs, mais c'est pas très intéressant pour certains genres de personnes, donc voilà... pour d'autres peut-être c'est super, c'est leur vie, ils s'éclatent à fond mais il y en a d'autres que ça n'intéressent pas... et voilà je pense que comme va le truc, il ne faut pas être je pense magicien ou avoir la boule, pour voir qu'il y a une tendance vers que les trucs culturels disparaissent de plus en plus, parce que tout simplement ça n'intéresse plus les politiques et comme c'est les politiques qui décident ou les gens qui sont classés à un haut niveau, il y a de moins en moins de... il y a toujours ce truc d'aller vers le plus simple, donc c'est assez naturel finalement, le logiciel avec un seul bouton mais c'est pareil partout, donc on ne va pas aller se compliquer l'existence à exister qui demande des efforts et donc je pense qu'on perd un peu la partie plus culturelle d'une certaine façon et ... peut-être que ça a été toujours comme ça, mais peut-être avant les politiciens, et surtout ici en France, ils avaient quand même une culture de ce qui se faisaient dans les arts, la littérature, la musique... il y avait quand même, bon, le truc qui a fait exister l'IRCAM c'est parce qu'il y a eu une rencontre politique et qui a fait que ce truc existe, mais ce genre de personnes ça a l'air qu'elles n'existent plus ... donc si tu vas demander à un politicien qui est Maessian par exemple, il va dire qu'il ne sait pas... c'est peut-être un compositeur très ancien et hyper connu qui a formulé toutes les notes et peut-être même Debussy, ils ne savent pas qui c'est où dans la musique classique, on peut parler d'autres genre de musiques, qui existaient dans le passé ... et donc il y a une espèce d'aculturisation... je vois ça, même si je ne suis pas un grand lecteur de philosophie parce que je n'y comprends rien, mais on voit ça très net, je pense, et c'est ce qui va faire que, et c'est le cas, qu'on a de moins en moins d'argent par rapport aux années 1980 et 1970... il y a eu une grande chute et ce qui est arrivé en Italie, c'est que la musique contemporaine, ou les centres d'expérimentation de ce genre là n'ont plus de subventions et si tu n'as pas de subvention, tu ne peux pas monter le moindre truc quoi... donc là je pense que, quand même, la curiosité ça fait partie de l'être humain, ça ne va jamais disparaître même s'il y a une tendance à faire toujours le truc avec le bouton, il y a je pense toujours quelques uns qui sont en train de bidouiller derrière et voilà je pense que c'est ça qui va continuer ... et bon il y a aussi la partie universitaire qui peut aussi des conférences internationales où on peut se recontrer... parce que des fois il y a des choses super intéressantes, il y a des gens qui vont là et qui montrent des trucs super intéressants... bon si tout continue à peu près comme ça, on ne sait jamais s'il y a une bombe nucléaire qui tombe ou une météorite... ça ferait une autre situation... 

VG — oui, probablement que ça changerait la situation... 

JMF — on pense toujours qu'on est immortels, mais on ne sait jamais ce qu'il va se passer demain donc on ne peut pas peut-être faire un pronostic de trop longe durée... mais si on pensait que tout continue plus ou moins comme maintenant, dans cet espèce de stabilité, même s'il y a plein de trucs qui se passent, mais bon l'histoire de l'humanité ça a toujours bougé pas mal... et donc l'IRCAM on voit qu'il a besoin de se renouveller, parce qu'il ne peut pas continuer avec les mêmes paradigmes des années 1970 et 1980 parce que c'était très focalisé sur le compositeur... maintenant le compositeur, bon on ne sait même pas ce que c'est, qu'est ce qu'il faut faire, quel type de musique... donc il y a aussi une crise d'une certaine façon, dans la musique elle-même, parce qu'il y a toujours ce truc de vouloir faire un truc nouveau, nouveau, nouveau... mais bon après il y a aussi des limites ... bon, moi je suis aussi positiviste de ce côté là parce que je crois encore que mon système et peut-être ce truc que je peux générer plein de choses va pouvoir créer des musiques, peut-être pas nouvelles, mais qui vont être très souples et qui vont faire ça, c'est mon idéal, te prendre et te faire voyager... mais voilà... je ne sais pas... mais je pense aussi que, c'est une évidence aussi, qu'il y a pas mal de gens qui bossent chez eux finalement ... donc je pense que ça, ça va continuer... et il y a toujours des gens qui vendent des Bela ou des Arduinos donc on peut continuer à bidouiller sans problème... après sûrement l'informatique, si tout va bien, va évoluer aussi... donc il y a des ordinateurs quantiques qui se profilent et donc peut-être dans 50 ans on aura les premiers prototypes d'ordinateurs quantiques... 

VG — ... on les aura probablement avant, quand même... 

JMF — oui, peut-être avant... ils disent qu'il y en a déjà quelques uns mais que c'est pas vraiment des quantiques ... mais oui espérons avant... et donc sûrement quand ça arrivera il va y avoir une réduction dans l'informatique, dans la façon du rapport aussi avec les machines, et donc tout ça fait que les gens qui font de la musique et qui bidouillent ça va continuer, et du moment qu'il y aura l'ordinateur quantique, il y aura des gens qui vont aussi bidouiller avec ça pour faire de la musique mais je ne sais pas quel genre de son ou systèmes de spatialisation ultra-sophistiqués ... ou le rêve de Stockhausen, qu'il disait dans un entretien, qu'il va penser la musique et que la musique va se créer tout seul, et on va peut-être pouvoir créer directement sans aucune interface tactile ni rien, tu vas faire de la musique ou de l'improvisation... on va se regarder et on va faire des sons qu'avec le regard... En tout cas, moi je pense que tant que l'humanité va exister, il va y avoir des nouveaux trucs, bon même si on revient aussi en arrière, c'est aussi pour aller vers d'autres chemins... parce qu'on a toujours dit que, ah oui l'homme va pouvoir aller sur la lune, pensant que l'homme ne va jamais aller sur Mars, donc on pense comme ça maintenant mais on ne pas ce qui va arriver dans 100 ans, tu vois, peut-être qu'un homme va pouvoir aller à l'autre bout de l'univers parce qu'il va passer par un trou noir ou je ne sais pas quoi... disons que chaque chose que l'Homme a pensé qu'il ne pouvait pas faire, ou qu'il pouvait faire, finalement il l'a fait ... 

VG — c'est souvent au moment où on pense que ce n'est pas possible de le faire que ça devient possible de le faire... parce que quelqu'un dit que ce n'est pas possible de faire quelque chose, il y a toujours quelqu'un d'autre qui a envie de lui donner tort... et à partir du moment où les choses sont pensées, elles existent déjà ... 

JMF — oui, voilà, à partir du moment où tu as l'imagination, tu vas tout faire pour aller jusque là... et nous on est confronté à ça parce que voilà, tu as ton idée de ton interface et tu commences à la faire et voilà tu l'as construite même si tu y passes beaucoup de temps... il faut taper, y passer des heures, mais bon on a une espèce d'obsession que ce truc c'est possible de le faire et puis tu sais intuitivement que c'est possible ... parce que bon je sais qu'il y a que je ne peux pas faire... par exemple ce logiciel qui a la partie graphique et le code, je sais que au vu de l'état actuel de l'informatique que c'est absolument possible de le faire, mais moi je n'ai pas les compétences de programmation pour le faire pour aller bidouiller du C++ ou je ne sais pas quoi, donc je peux avoir l'idée, mais j'aurais besoin de collaborateurs ou de dire à quelqu'un de le faire et puis faire un groupe de travail sur ça, mais donc voilà... mais bon en tout cas je suis très positiviste, donc je ne crois pas du tout quand quelqu'un me dit « ah c'est tout déjà inventé » je lui dit c'est n'importe quoi parce que c'est la même chose qu'on a dit toujours et puis le jour d'après, il y a un nouveau truc qui bouleverse tout... donc dans ce cas là, ça sera peut-être les ordinateurs quantiques ou une autre technologie, je ne sais pas quoi, ou quelque chose qu'on n'a même pas pensé... et dans la musique c'est pareil, la musique c'est très plastique et une théorie que j'ai, c'est que la musique tu peux faire tout ce que tu veux... la musique c'est comme une pâte à modeler, et plus tu as d'outils, plus tu peux la modeler comme tu veux, faire des métamorphoses et elle va continuer à se modeler au fur et à mesure que l'être humain va continuer à vivre je pense... c'est inifini... tout est possible...  

VG — c'est le mot de la fin ? Tout est possible ? 

JMF — voilà c'est bien... tout est possible 
