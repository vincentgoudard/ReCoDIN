
@article{hajdu_disposable_2016,
	title = {Disposable {Music}},
	volume = {40},
	issn = {0148-9267, 1531-5169},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00342},
	doi = {10.1162/COMJ_a_00342},
	abstract = {This article introduces the concept of real-time composition and composition as a “dispositif” in the sense of Foucault and Deleuze, defining it as a heterogeneous ensemble of pieces that together form an apparatus. The introduction situates the dispositif in the context of cultural developments, most notably its slow but steady shift away from textualization in digital media. As musicians are adapting to ensuing cultural and, above all, economic changes, new musical forms emerge that rely to a lesser degree on fully notated scores, such as “comprovisation” or laptop performance. Antithetically, the computer also allows the creation of “authorless” notated scores in real time to be sight-read by capable musicians—a practice for which special software has been developed in recent years. Because these scores are not meant to be kept and distributed, they are ephemeral and, therefore, disposable. Three examples by the author are given to illustrate the interwovenness of this approach, where carefully selected narratives and dramaturgies make up for the inherent unpredictability of the outcome.},
	language = {en},
	number = {1},
	urldate = {2019-05-22},
	journal = {Computer Music Journal},
	author = {Hajdu, Georg},
	month = mar,
	year = {2016},
	pages = {25--34},
	file = {2016.Hajdu_Disposable-Music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2016.Hajdu_Disposable-Music.pdf:application/pdf}
}

@inproceedings{bhagwati_vexations_2017,
	title = {Vexations of ephemerality. {Extreme} sight-reading in situative scores - for makers, performers, audiences.},
	abstract = {What do we do when we subject musicians and audiences to music prompted by real-time scores? Such situative scores create a new kind of immanent relationship between performers and audiences, between composers and performers, composers and audiences – a relationship whose ingrained disregard of context, memory, and knowledge has often been ignored. The use of situative scores seems to inscribe itself into a more general societal trend that uses technology to ephemeralize our lives, to decouple presence from its history. While this immanence has often been perceived as a force for the emancipation of performers and spectators, it can also give rise to unaccountability. Do artistic practices that ephemeralize our artistic 'regime of perception, sensation and interpretation' (Rancière) - such as situative scores – foster abuses of immanence?. In this paper, I will look at such questions from the perspective of the performers, the audiences and the makers of such scores – the composers.},
	language = {en},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Bhagwati, Sandeep},
	year = {2017},
	pages = {6},
	file = {15-vexations_ephemerality.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2017/15-vexations_ephemerality.pdf:application/pdf}
}

@article{freeman_extreme_2008,
	title = {Extreme {Sight}-{Reading}, {Mediated} {Expression}, and {Audience} {Participation}: {Real}-{Time} {Music} {Notation} in {Live} {Performance}},
	volume = {32},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Extreme {Sight}-{Reading}, {Mediated} {Expression}, and {Audience} {Participation}},
	url = {http://www.mitpressjournals.org/doi/10.1162/comj.2008.32.3.25},
	doi = {10.1162/comj.2008.32.3.25},
	language = {en},
	number = {3},
	urldate = {2019-05-22},
	journal = {Computer Music Journal},
	author = {Freeman, Jason},
	month = sep,
	year = {2008},
	pages = {25--41},
	file = {CMJ-32-3-Freeman_Extreme Sight-reading.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/CMJ-32-3-Freeman_Extreme Sight-reading.pdf:application/pdf}
}

@article{godoy_gestural-sonorous_2006,
	title = {Gestural-{Sonorous} {Objects}: embodied extensions of {Schaeffer}'s conceptual apparatus},
	volume = {11},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Gestural-{Sonorous} {Objects}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771806001439/type/journal_article},
	doi = {10.1017/S1355771806001439},
	language = {en},
	number = {2},
	urldate = {2019-05-22},
	journal = {Organised Sound},
	author = {Godøy, Rolf Inge},
	month = aug,
	year = {2006},
	pages = {149--157},
	file = {2006.Godoy.Gestural_Sonorous_Objects.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2006.Godoy.Gestural_Sonorous_Objects.pdf:application/pdf}
}

@article{wanderley_gestural_2004,
	title = {Gestural {Control} of {Sound} {Synthesis}},
	volume = {92},
	issn = {0018-9219},
	url = {http://ieeexplore.ieee.org/document/1278687/},
	doi = {10.1109/JPROC.2004.825882},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {Proceedings of the IEEE},
	author = {Wanderley, M.M. and Depalle, P.},
	month = apr,
	year = {2004},
	pages = {632--644},
	file = {2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_IEEE/2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:application/pdf}
}

@phdthesis{bin_show_2018,
	address = {London},
	title = {The {Show} {Must} {Go} {Wrong}: {Towards} an understanding of audience perception of error in digital musical instrument performance},
	abstract = {This thesis is about DMI (digital musical instrument) performance, its audiences, and their perception of error. The goal of this research is to improve current understanding of how audiences perceive DMI performance, where performers and their audiences often have no shared, external frame of reference with which to judge the musical output. Further complicating this audience-performer relationship are human-computer interaction (HCI) issues arising from the use of a computer as a musical instrument. In current DMI literature, there is little direct inquiry of audience perception on these issues. Error is an aspect of this kind of audience perception. Error, a condition reached by stepping out of bounds, appears at first to be a simple binary quantity, but the location and nature of those boundaries change with context. With deviation the locus of style and artistic progress, understanding how audiences perceive error has the potential to lend important insight to the cultural mechanics of DMI performance. In this thesis I describe the process of investigating audience perception and unpacking these issues through three studies. Each study examines the relative effects of various factors on audience perception — instrument familiarity and musical style, gesture size, and visible risk — using a novel methodology combining real-time data collected by mobile phone, and post- hoc data in the form of written surveys. The results have implications for DMI and HCI researchers as well as DMI performers and composers, and contribute insights on these confounding factors from the audience’s perspective as well as important insights on audience perception of error in this context. Further, through this thesis I contribute a practical method and tool that can be used to continue this audience-focused work in the future.},
	language = {en},
	school = {Queen Mary University of London},
	author = {Bin, S M Astrid},
	month = may,
	year = {2018},
	file = {2018.PhD.Bin.ShowMustGoWrong.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2018.PhD.Bin.ShowMustGoWrong.pdf:application/pdf}
}

@article{arfib_strategies_2002,
	title = {Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002054/type/journal_article},
	doi = {10.1017/S1355771802002054},
	abstract = {This paper is about mapping strategies between gesture data and synthesis model parameters by means of perceptual spaces. We define three layers in the mapping chain: from gesture data to gesture perceptual space, from sound perceptual space to synthesis model parameters, and between the two perceptual spaces. This approach makes the implementation highly modular. Both perceptual spaces are developed and depicted with their features. To get a simple mapping between the gesture perceptual subspace and the sound perceptual subspace, we need to focus our attention on the two other mappings. We explain the mapping types: explicit/implicit, static/dynamic. We also present the technical and esthetical limits introduced by mapping. Some practical examples are given of the use of perceptual spaces in experiments done at LMA in a musical context. Finally, we discuss several implications of the mapping strategies: the influence of chosen mapping limits onto performers’ virtuosity, and the incidence of mapping on the learning process with virtual instruments and on improvisation possibilities.},
	language = {en},
	number = {2},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Arfib, D. and Couturier, J. M. and Kessous, L. and Verfaille, V.},
	month = aug,
	year = {2002},
	pages = {127--144},
	file = {ARFIB - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/ARFIB - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:application/pdf}
}

@article{cascone_aesthetics_2000,
	title = {The {Aesthetics} of {Failure}: “{Post}-{Digital}” {Tendencies} in {Contemporary} {Computer} {Music}},
	volume = {24},
	language = {en},
	number = {4},
	journal = {Computer Music Journal},
	author = {Cascone, Kim},
	year = {2000},
	pages = {7},
	file = {CMJ24_4_Cascone_Aesthetics of failure.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/CMJ24_4_Cascone_Aesthetics of failure.pdf:application/pdf}
}

@article{born_musical_2005,
	title = {On {Musical} {Mediation}: {Ontology}, {Technology} and {Creativity}},
	volume = {2},
	issn = {1478-5722, 1478-5730},
	shorttitle = {On {Musical} {Mediation}},
	url = {https://www.cambridge.org/core/product/identifier/S147857220500023X/type/journal_article},
	doi = {10.1017/S147857220500023X},
	abstract = {This article develops a theoretical analysis of music and mediation, building on the work of Theodor Adorno, Tia DeNora and Antoine Hennion. It begins by suggesting that Lydia Goehr’s account of the work concept requires such a perspective. Drawing on Alfred Gell’s anthropology of art, the article outlines an approach to mediation that incorporates understandings of music’s social, technological and temporal dimensions. It suggests that music’s mediations have taken a number of historical forms, which cohere into assemblages, and that we should be alert to shifts in the dominant forms of musical assemblage. In the latter part of the article, these tools are used to conceptualize changing forms of musical creativity that emerged over the twentieth century. A comparison is made between the work concept and jazz and improvised electronic musics. Three contemporary digital music experiments are discussed in detail, demonstrating the concepts of the provisional work and of social, distributed and relayed creativity. Throughout, key motifs are mediation, creativity, and the negotiation of difference.},
	language = {en},
	number = {1},
	urldate = {2019-05-23},
	journal = {Twentieth-Century Music},
	author = {Born, Georgina},
	month = mar,
	year = {2005},
	pages = {7--36},
	file = {GeorginaBorn_On Musical Mediation Ontology Technology and Creativity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CambridgeTwentiethCenturyMusic/GeorginaBorn_On Musical Mediation Ontology Technology and Creativity.pdf:application/pdf}
}

@article{fels_mapping_2002,
	title = {Mapping transparency through metaphor: towards more expressive musical instruments},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Mapping transparency through metaphor},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002042/type/journal_article},
	doi = {10.1017/S1355771802002042},
	abstract = {We define a two-axis transparency framework that can be used as a predictor of the expressivity of a musical device. One axis is the player's transparency scale, while the other is the audience's transparency scale. Through consideration of both traditional instrumentation and new technology-driven interfaces, we explore the role that metaphor plays in developing expressive devices. Metaphor depends on a literature, which forms the basis for making transparent device mappings. We examine four examples of systems that use metaphor: Iamascope, Sound Sculpting, MetaMuse, and Glove-TalkII; and discuss implications on transparency and expressivity. We believe this theory provides a framework for design and evaluation of new human-machine and humanhuman interactions, including musical instruments.},
	language = {en},
	number = {2},
	urldate = {2019-05-24},
	journal = {Organised Sound},
	author = {Fels, Sidney and Gadd, Ashley and Mulder, Axel},
	month = aug,
	year = {2002},
	pages = {109--126},
	file = {2002.OS.Fels.Mapping Transparency through Metaphor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2002/2002.OS.Fels.Mapping Transparency through Metaphor.pdf:application/pdf}
}

@inproceedings{marquez-borbon_problem_2018,
	address = {Blacksburg, Virginia, USA},
	title = {The {Problem} of {DMI} {Adoption} and {Longevity}: {Envisioning} a {NIME} {Performance} {Pedagogy}},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0040.pdf},
	abstract = {This paper addresses the prevailing longevity problem of digital musical instruments (DMIs) in NIME research and design by proposing a holistic system design approach. Despite recent efforts to examine the main contributing factors of DMI falling into obsolescence, such attempts to remedy this issue largely place focus on the artifacts establishing themselves, their design processes and technologies. However, few existing studies have attempted to proactively build a community around technological platforms for DMIs, whilst bearing in mind the social dynamics and activities necessary for a budding community. We observe that such attempts while important in their undertaking, are limited in their scope. In this paper we will discuss that achieving some sort of longevity must be addressed beyond the device itself and must tackle broader ecosystemic factors. We hypothesize, that a longevous DMI design must not only take into account a target community but it may also require a non-traditional pedagogical system that sustains artistic practice.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Marquez-Borbon, Adnan and Martinez-Avila, Juan Pablo},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {190--195},
	file = {2018.MarquezBorbon-DMI Adoption and Longevity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/2018.MarquezBorbon-DMI Adoption and Longevity.pdf:application/pdf}
}

@inproceedings{morreale_design_2017,
	address = {Copenhagen, Denmark},
	title = {Design for {Longevity}: {Ongoing} {Use} of {Instruments} from {NIME} 2010-14},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0036.pdf},
	abstract = {Every new edition of NIME brings dozens of new DMIs and the feeling that only a few of them will eventually break through. Previous work tried to address this issue with a deductive approach by formulating design frameworks; we addressed this issue with a inductive approach by elaborating on successes and failures of previous DMIs. We contacted 97 DMI makers that presented a new instrument at five successive editions of NIME (2010-2014); 70 answered. They were asked to indicate the original motivation for designing the DMI and to present information about its uptake. Results confirmed that most of the instruments have difficulties establishing themselves. Also, they were asked to reflect on the specific factors that facilitated and those that hindered instrument longevity. By grounding these reflections on existing reserach on NIME and HCI, we propose a series of design considerations for future DMIs.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Morreale, Fabio and McPherson, Andrew},
	year = {2017},
	pages = {192--197},
	file = {2017.Morreale Design for Longevity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/2017.Morreale Design for Longevity.pdf:application/pdf}
}

@inproceedings{bowers_hybrid_2014,
	address = {London, United Kingdom},
	title = {Hybrid {Resonant} {Assemblages}: {Rethinking} {Instruments}, {Touch} and {Performance} in {New} {Interfaces} for {Musical} {Expression}},
	url = {http://www.nime.org/proceedings/2014/nime2014_438.pdf},
	abstract = {This paper outlines a concept of hybrid resonant assemblages, combinations of varied materials excited by sound transducers, feeding back to themselves via digital signal processing. We ground our concept as an extension of work by David Tudor, Nicolas Collins and Bowers and Archer [NIME 2005] and draw on a variety of critical perspectives in the social sciences and philosophy to explore such assemblages as an alternative to more familiar ideas of instruments and interfaces. We lay out a conceptual framework for the exploration of hybrid resonant assemblages and describe how we have approached implementing them. Our performance experience is presented and implications for work are discussed. In the light of our work, we urge a reconsideration of the implicit norms of performance which underlie much research in NIME. In particular, drawing on the philosophical work of Jean-Luc Nancy, we commend a wider notion of touch that also recognises the performative value of withholding contact.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Bowers, John and Haas, Annika},
	month = jun,
	year = {2014},
	pages = {7--12},
	file = {2014.Bowers.Hybrid Resonant assemblages_nime2014_438.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/2014.Bowers.Hybrid Resonant assemblages_nime2014_438.pdf:application/pdf}
}

@inproceedings{mamedes_composing_2014,
	address = {London, United Kingdom},
	title = {Composing for {DMIs} {Entoa}, a {Dedicate} {Piece} for {Intonaspacio}},
	url = {http://www.nime.org/proceedings/2014/nime2014_411.pdf},
	abstract = {Digital Musical Instruments (DMIs) have difficulties establishing themselves after their creation. A huge number of DMIs is presented every year and few of them actually remain in use. Several causes could explain this reality, among them the lack of a proper instrumental technique, inadequacy of the traditional musical notation and the non-existence of a repertoire dedicated to the instrument. In this paper we present Entoa, the first written music for Intonaspacio, a DMI we designed in our research project. We propose some strategies for mapping data from sensors to sound processing, in order to accomplish an expressive performance. Entoa is divided in five different sections that corresponds to five movements. For each, a different mapping is designed, introducing subtle alterations that progressively explore the ensemble of features of the instrument. The performer is then required to adapt his repertoire of gestures along the piece. Indications are expressed through a gestural notation, where freedom is give to performer to control certain parameters at specific moments in the music.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Mamedes, Clayton and Rodrigues, Mailis and Wanderley, Marcelo M. and Manzolli, Jônatas and Garcia, Denise H. L. and Ferreira-Lopes, Paulo},
	month = jun,
	year = {2014},
	pages = {509--512},
	file = {nime2014_411_Mamedes_Composing_for_entoa.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_411_Mamedes_Composing_for_entoa.pdf:application/pdf}
}

@inproceedings{fyans_ecological_2012,
	address = {Ann Arbor, Michigan},
	title = {Ecological considerations for participatory design of {DMIs}},
	url = {http://www.nime.org/proceedings/2012/nime2012_253.pdf},
	abstract = {A study is presented examining the participatory design of digital musical interactions. The study takes into consideration the entire ecology of digital musical interactions including the designer, performer and spectator. A new instrument is developed through iterative participatory design involving a group of performers. Across the study the evolution of creative practice and skill development in an emerging community of practice is examined and a spectator study addresses the cognition of performance and the perception of skill with the instrument. Observations are presented regarding the cognition of a novel interaction and evolving notions of skill. The design process of digital musical interactions is reflected on focusing on involvement of the spectator in design contexts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Fyans, A. Cavan and Marquez-Borbon, Adnan and Stapleton, Paul and Gurevich, Michael},
	year = {2012},
	keywords = {cognition, DMIs, participatory design, skill, spectator},
	file = {nime2012_253.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_253.pdf:application/pdf}
}

@inproceedings{bowers_creating_2006,
	address = {Paris, France},
	title = {Creating {Ad} {Hoc} {Instruments} with {Pin} \& {Play} \& {Perform}},
	url = {http://www.nime.org/proceedings/2006/nime2006_234.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bowers, John and Villar, Nicolas},
	year = {2006},
	keywords = {physical interfaces, music performance, Ad hoc instruments, new interfaces for musical expression., Pin\&Play},
	pages = {234--239},
	file = {2006.Bowers.Creating Ad Hoc Instruments with Pin&Play&Performnime2006_234.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/2006.Bowers.Creating Ad Hoc Instruments with Pin&Play&Performnime2006_234.pdf:application/pdf}
}

@inproceedings{jensenius_towards_2006,
	address = {Paris, France},
	title = {Towards a {Gesture} {Description} {Interchange} {Format}},
	url = {http://www.nime.org/proceedings/2006/nime2006_176.pdf},
	abstract = {This paper presents our need for a Gesture Description Interchange Format (GDIF) for storing, retrieving and sharing information about music-related gestures. Ideally, it should be possible to store all sorts of data from various commercial and custom made controllers, motion capture and computer vision systems, as well as results from different types of gesture analysis, in a coherent and consistent way. This would make it possible to use the information with different software, platforms and devices, and also allow for sharing data between research institutions. We present some of the data types that should be included, and discuss issues which need to be resolved.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jensenius, Alexander Refsum and Kvifte, Tellef and Godøy, Rolf Inge},
	year = {2006},
	keywords = {gesture analysis, Gesture description, standards},
	pages = {176--179},
	file = {nime2006_176.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_176.pdf:application/pdf}
}

@inproceedings{bowers_not_2005,
	address = {Vancouver, BC, Canada},
	title = {Not {Hyper}, {Not} {Meta}, {Not} {Cyber} but {Infra}-{Instruments}},
	url = {http://www.nime.org/proceedings/2005/nime2005_005.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bowers, John and Archer, Phil},
	year = {2005},
	keywords = {hyperinstruments, design concepts and principles., Infra-instruments, meta-instruments, virtual instruments},
	pages = {5--10},
	file = {nime2005_005_Bowers.Infra Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2005/nime2005_005_Bowers.Infra Instruments.pdf:application/pdf}
}

@inproceedings{jorda_digital_2004,
	address = {Hamamatsu, Japan},
	title = {Digital {Instruments} and {Players}: {Part} {I} – {Efficiency} and {Apprenticeship}},
	url = {http://www.nime.org/proceedings/2004/nime2004_059.pdf},
	abstract = {When envisaging new digital instruments, designers do not have to limit themselves to their sonic capabilities (which can be absolutely any), not even to their algorithmic power; they must be also especially careful about the instruments' conceptual capabilities, to the ways instruments impose or suggest to their players new ways of thinking, new ways of establishing relations, new ways of interacting, new ways of organizing time and textures; new ways, in short, of playing new musics. This article explores the dynamic relation that builds between the player and the instrument, introducing concepts such as efficiency, apprenticeship and learning curve It aims at constructing a framework in which the possibilities and the diversity of music instruments as well as the possibilities and the expressive freedom of human music performers could start being evaluated.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jordà, Sergi},
	year = {2004},
	keywords = {apprenticeship, learning curve, musical efficiency., Musical instruments design},
	pages = {59--63},
	file = {nime2004_059.Jorda.Digital Instruments and PlayersPt1.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2004/nime2004_059.Jorda.Digital Instruments and PlayersPt1.pdf:application/pdf}
}

@inproceedings{gadd_metamuse:_2002,
	address = {Dublin, Ireland},
	title = {{MetaMuse}: {Metaphors} for {Expressive} {Instruments}},
	url = {http://www.nime.org/proceedings/2002/nime2002_065.pdf},
	abstract = {We explore the role that metaphor plays in developing expressive devices by examining the MetaMuse system. MetaMuse is a prop-based system that uses the metaphor of rainfall to make the process of granular synthesis understandable. We discuss MetaMuse within a framework we call"transparency" that can be used as a predictor of the expressivity of musical devices. Metaphor depends on a literature,or cultural basis, which forms the basis for making transparent device mappings. In this context we evaluate the effect of metaphor in the MetaMuse system.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gadd, Ashley and Fels, Sidney S.},
	month = may,
	year = {2002},
	keywords = {metaphor, transparency, Expressive interface, granular synthesis., prop-based controller},
	pages = {65--70},
	file = {nime2002_065.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_065.Fels.MetaphorsForExpressiveInstruments.pdf:application/pdf}
}

@inproceedings{wessel_problems_2001,
	address = {Seattle, WA},
	title = {Problems and {Prospects} for {Intimate} {Musical} {Control} of {Computers}},
	url = {http://www.nime.org/proceedings/2001/nime2001_011.pdf},
	abstract = {In this paper we describe our efforts towards the development of live performance computer-based musical instrumentation. Our design criteria include initial ease of use coupled with a long term potential for virtuosity,minimal and low variance latency, and clear and simple strategies for programming the relationship between gesture and musical result. We present custom controllers and unique adaptations of standard gestural interfaces, a programmable connectivity processor, a communications protocol called Open Sound Control(OSC), and a variety of metaphors for musical control. We further describe applications of our technology to a variety of real musical performances and directions for future research.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Wessel, David and Wright, Matthew},
	month = apr,
	year = {2001},
	keywords = {latency, musical, gestural controllers, signal processing, communications protocols, reactive computing},
	pages = {11--14},
	file = {nime2001_011_WesselWright_Problems and Prospects for Intimate Musical Control of Computers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/nime2001_011_WesselWright_Problems and Prospects for Intimate Musical Control of Computers.pdf:application/pdf}
}

@article{chion_musique_1977,
	title = {La musique du futur a-t-elle un avenir ?},
	volume = {4},
	language = {french},
	journal = {Cahiers recherche/musique},
	author = {Chion, Michel},
	year = {1977},
	file = {1977.Chion.la musique du futur.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Cahiers recherche\:musique/1977.Chion.la musique du futur.pdf:application/pdf}
}

@article{bonardi_preservation_2008,
	title = {The preservation, emulation, migration, and virtualization of live electronics for performing arts: {An} overview of musical and technical issues},
	volume = {1},
	issn = {15564673},
	shorttitle = {The preservation, emulation, migration, and virtualization of live electronics for performing arts},
	url = {http://portal.acm.org/citation.cfm?doid=1367080.1367086},
	doi = {10.1145/1367080.1367086},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Bonardi, Alain and Barthélemy, Jérome},
	month = jun,
	year = {2008},
	pages = {1--16},
	file = {Bonardi and Barthélemy - 2008 - The preservation, emulation, migration, and virtua.pdf:/Users/vg/Zotero/storage/K7IG2RDE/Bonardi and Barthélemy - 2008 - The preservation, emulation, migration, and virtua.pdf:application/pdf}
}

@book{slade_made_2006,
	address = {Cambridge, Mass},
	title = {Made to break: technology and obsolescence in {America}},
	isbn = {978-0-674-02203-4},
	shorttitle = {Made to break},
	language = {en},
	publisher = {Harvard University Press},
	author = {Slade, Giles},
	year = {2006},
	note = {OCLC: ocm62679850},
	keywords = {Product obsolescence, Technological innovations, United States},
	file = {Slade - 2006 - Made to break technology and obsolescence in Amer.pdf:/Users/vg/Zotero/storage/FVGTWKD8/Slade - 2006 - Made to break technology and obsolescence in Amer.pdf:application/pdf}
}

@article{guillo_musique_2005,
	title = {Musique, {Images}, {Instruments}: {Revue} française d'organologie et d'iconographie musicale},
	volume = {91},
	issn = {00351601},
	shorttitle = {Musique, {Images}, {Instruments}},
	url = {https://www.jstor.org/stable/10.2307/20141602?origin=crossref},
	doi = {10.2307/20141602},
	language = {fr},
	number = {1},
	urldate = {2019-05-28},
	journal = {Revue de Musicologie},
	author = {Guillo, Laurent},
	month = jan,
	year = {2005},
	pages = {259},
	file = {MII-15-Haine-Classifications.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue française d’organologie et d’iconographie musicale/MII-15-Haine-Classifications.pdf:application/pdf}
}

@article{magnusson_ergodynamics_2019,
	title = {Ergodynamics and a semiotics of instrumental composition},
	volume = {73},
	number = {287},
	journal = {Tempo},
	author = {Magnusson, Thor},
	year = {2019},
	pages = {41--51},
	file = {Magnusson_Tempo_v3.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Tempo/Magnusson_Tempo_v3.pdf:application/pdf}
}

@article{buxton_artists_1997,
	title = {Artists and the art of the luthier},
	volume = {31},
	number = {1},
	journal = {ACM SIGGRAPH Computer Graphics},
	author = {Buxton, Bill},
	year = {1997},
	pages = {10--11},
	file = {Full Text:/Users/vg/Zotero/storage/SPN6M678/luthier.html:text/html}
}

@inproceedings{schnell_introducing_2002,
	address = {Dublin, Ireland},
	title = {Introducing {Composed} {Instruments}, {Technical} and {Musicological} {Implications}},
	url = {http://www.nime.org/proceedings/2002/nime2002_156.pdf},
	abstract = {In this paper, we develop the concept of "composed instruments". We will look at this idea from two perspectives: the design of computer systems in the context of live performed music and musicological considerations. A historical context is developed. Examples will be drawn from recent compositions. Finally basic concepts from computer science will be examined for their relation ship to this concept.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Schnell, Norbert and Battier, Marc},
	month = may,
	year = {2002},
	keywords = {interaction, composed instrument, Theremin, Instruments, Martenot, MAX., musicology, streams},
	pages = {156--160},
	file = {nime2002_156_Schnell_Introducing  Composed  Instruments,  Technical  and  Musicological  Implications.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_156_Schnell_Introducing  Composed  Instruments,  Technical  and  Musicological  Implications.pdf:application/pdf}
}

@inproceedings{kvifte_towards_2006,
	address = {Paris, France},
	title = {Towards a {Coherent} {Terminology} and {Model} of {Instrument} {Description} and {Design}},
	url = {http://www.nime.org/proceedings/2006/nime2006_220.pdf},
	abstract = {This paper discusses the need for a framework for describing musical instruments and their design, and discusses some possible elements in such a framework. The framework is meant as an aid in the development of a coherent terminology for describing, comparing and discussing different musical instruments and musical instrument designs. Three different perspectives are presented; that of the listener, the performer, and the constructor, and various levels of descriptions are introduced.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Kvifte, Tellef and Jensenius, Alexander Refsum},
	year = {2006},
	keywords = {mapping, gestures, Musical instrument design, organology.},
	pages = {220--225},
	file = {nime2006_220_KvifteARJ_Towards a Coherent Terminology and Model of Instrument Description and Design.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_220_KvifteARJ_Towards a Coherent Terminology and Model of Instrument Description and Design.pdf:application/pdf}
}

@inproceedings{fyans_where_2009,
	address = {Pittsburgh, PA, United States},
	title = {Where {Did} {It} {All} {Go} {Wrong} ? {A} {Model} of {Error} {From} the {Spectator}'s {Perspective}},
	url = {http://www.nime.org/proceedings/2009/nime2009_171.pdf},
	abstract = {The development of new interfaces for musical expressionhas created a need to study how spectators comprehend newperformance technologies and practices. As part of a largerproject examining how interactions with technology can becommunicated with the spectator, we relate our model ofspectator understanding of error to the NIME discourse surrounding transparency, mapping, skill and success.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fyans, A. Cavan and Gurevich, Michael and Stapleton, Paul},
	year = {2009},
	keywords = {performance, skill, design, HCI, transparency},
	pages = {171--172},
	file = {nime2009_171.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_171.pdf:application/pdf}
}

@inproceedings{schwarz_sound_2012,
	address = {Ann Arbor, Michigan},
	title = {The {Sound} {Space} as {Musical} {Instrument}: {Playing} {Corpus}-{Based} {Concatenative} {Synthesis}},
	url = {http://www.nime.org/proceedings/2012/nime2012_120.pdf},
	abstract = {Corpus-based concatenative synthesis is a fairly recent sound synthesis method, based on descriptor analysis of any number of existing or live-recorded sounds, and synthesis by selection of sound segments from the database matching given sound characteristics. It is well described in the literature, but has been rarely examined for its capacity as a new interface for musical expression. The interesting outcome of such an examination is that the actual instrument is the space of sound characteristics, through which the performer navigates with gestures captured by various input devices. We will take a look at different types of interaction modes and controllers (positional, inertial, audio analysis) and the gestures they afford, and provide a critical assessment of their musical and expressive capabilities, based on several years of musical experience, performing with the CataRT system for real-time CBCS.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Schwarz, Diemo},
	year = {2012},
	keywords = {gesture, CataRT, corpus-based concatenative synthesis},
	file = {nime2012_120.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_120.pdf:application/pdf}
}

@misc{collins_semiconducting_2013,
	title = {Semiconducting – {Making} {Music} {After} the {Transistor}},
	abstract = {Why does ‘Computer Music’ sound different from ‘Electronic Music’? The author examines several traits that distinguish hardware from software in terms of their application in music composition and performance. He discusses the often subtle influence of these differences on various aspects of the creative process, and presents a number of inferences as to the ‘intrinsic’ suitability of hardware and software for different musical tasks. His observations are based on several decades of experience as a composer and performer, and in close engagement with the music of his mentors and peers.},
	author = {Collins, Nicolas},
	year = {2013},
	file = {Collins_semiconducting.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Collins, Nicolas/Collins_semiconducting.pdf:application/pdf}
}

@inproceedings{mays_notation_2014,
	address = {London, United Kingdom},
	title = {A {Notation} {System} for the {Karlax} {Controller}},
	url = {http://www.nime.org/proceedings/2014/nime2014_509.pdf},
	abstract = {In this paper we expose the need to go beyond the composer/performer model of electronic instrument design and programming to encourage the transmission of compositions and the creation of a repertory via notation of repeatable performance practice. Drawing on 4 years of practice using the Karlax controller (Da Fact) as a base for new digital musical instruments, we present our notation system in detail and cite some mapping strategies and examples from to pieces in a growing repertory of chamber music compositions for electronic and acoustic instruments},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Mays, Tom and Faber, Francis},
	month = jun,
	year = {2014},
	pages = {553--556},
	file = {nime2014_509_Mays_Notation system for the Karlax.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_509_Mays_Notation system for the Karlax.pdf:application/pdf}
}

@inproceedings{tubb_divergent_2014,
	address = {London, United Kingdom},
	title = {The {Divergent} {Interface}: {Supporting} {Creative} {Exploration} of {Parameter} {Spaces}},
	url = {http://www.nime.org/proceedings/2014/nime2014_415.pdf},
	abstract = {This paper outlines a theoretical framework for creative technology based on two contrasting processes: divergent exploration and convergent optimisation. We claim that these two cases require different gesture-to-parameter mapping properties. Results are presented from a user experiment that motivates this theory. The experiment was conducted using a publicly available iPad app: “Sonic Zoom”. Participants were encouraged to conduct an open ended exploration of synthesis timbre using a combination of two different interfaces. The first was a standard interface with ten sliders, hypothesised to be suited to the “convergent” stage of creation. The second was a mapping of the entire 10-D combinatorial space to a 2-D surface using a space filling curve. This novel interface was intended to support the “divergent” aspect of creativity. The paths of around 250 users through both 2-D and 10-D space were logged and analysed. Both the interaction data and questionnaire results show that the different interfaces tended to be used for different aspects of sound creation, and a combination of these two navigation styles was deemed to be more useful than either individually. The study indicates that the predictable, separate parameters found in most music technology are more appropriate for convergent tasks.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Tubb, Robert and Dixon, Simon},
	month = jun,
	year = {2014},
	pages = {227--232},
	file = {nime2014_415.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_415.pdf:application/pdf}
}

@book{seve_instrument_2013,
	edition = {Le Seuil},
	series = {L'{Ordre} philosophique},
	title = {L'instrument de musique: une étude philosophique},
	language = {french},
	author = {Sève, Bernard},
	month = mar,
	year = {2013}
}

@article{ostertag_why_1998,
	title = {Why computer music sucks},
	volume = {5},
	journal = {Resonance},
	author = {Ostertag, Bob},
	year = {1998},
	pages = {4--5}
}

@incollection{beaudouin-lafon_moins_1999,
	edition = {Hermes Science Publications},
	title = {Moins d'interface pour plus d'interaction},
	booktitle = {Interfaces homme-machine et création musicale},
	author = {Beaudouin-Lafon, Michel},
	year = {1999},
	pages = {123--141}
}

@book{godoy_musical_2010,
	title = {Musical gestures: {Sound}, movement, and meaning},
	publisher = {Routledge},
	author = {Godøy, Rolf Inge and Leman, Marc},
	year = {2010}
}

@inproceedings{di_scipio_towards_1997,
	title = {Towards a critical theory of (music) technology},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Di Scipio, Agostino},
	year = {1997},
	pages = {62--65},
	file = {1997.ICMC.DiScipio.Towards a critical theory of (music) technology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1997/1997.ICMC.DiScipio.Towards a critical theory of (music) technology.pdf:application/pdf}
}

@incollection{jensenius_musical_2010,
	title = {Musical gestures. {Concepts} and methods in research},
	language = {en},
	booktitle = {Musical {Gestures}. {Sound}, movement, and meaning},
	publisher = {Routledge},
	author = {Jensenius, Alexander R and Wanderley, Marcelo M. and Godøy, Rolf Inge and Leman, Marc},
	year = {2010},
	pages = {13--35},
	file = {Jensenius_2010e.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Godoy\; Rolf Inge/MusicalGestures.Jensenius.pdf:application/pdf}
}

@incollection{risset_evolution_1999,
	title = {Evolution des outils de création sonore in {Interfaces} homme-machine et création musicale},
	booktitle = {Interfaces homme-machine et création musicale},
	publisher = {Hermès},
	author = {Risset, Jean-Claude},
	year = {1999}
}

@article{tresch_toward_2013,
	title = {Toward a new organology: instruments of music and science},
	volume = {28},
	number = {1},
	journal = {Osiris},
	author = {Tresch, John and Dolan, Emily I},
	year = {2013},
	pages = {278--298}
}

@article{dolan_toward_2012,
	title = {Toward a {Musicology} of {Interfaces}},
	volume = {5},
	journal = {Keyboard Perspectives},
	author = {Dolan, Emily I},
	year = {2012},
	pages = {1--12}
}

@article{moody_physics_2009,
	title = {The “physics” of notations: toward a scientific basis for constructing visual notations in software engineering},
	volume = {35},
	number = {6},
	journal = {IEEE Transactions on software engineering},
	author = {Moody, Daniel},
	year = {2009},
	pages = {756--779},
	file = {physics_of_notations.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_IEEE/physics_of_notations.pdf:application/pdf}
}

@book{tufte_visual_2001,
	title = {The visual display of quantitative information},
	volume = {2},
	publisher = {Graphics press Cheshire, CT},
	author = {Tufte, Edward R},
	year = {2001},
	file = {Tufte_2001_The visual display of quantitative information.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Tufte_2001_The visual display of quantitative information.pdf:application/pdf}
}

@article{pinch_why_2001,
	title = {Why you go to a music store to buy a synthesizer: path dependence and the social construction of technology},
	journal = {Path dependence and creation},
	author = {Pinch, Trevor J},
	year = {2001},
	pages = {381--400}
}