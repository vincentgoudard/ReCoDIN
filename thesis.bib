
@article{hajdu_disposable_2016,
	title = {Disposable {Music}},
	volume = {40},
	issn = {0148-9267, 1531-5169},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00342},
	doi = {10.1162/COMJ_a_00342},
	abstract = {This article introduces the concept of real-time composition and composition as a “dispositif” in the sense of Foucault and Deleuze, defining it as a heterogeneous ensemble of pieces that together form an apparatus. The introduction situates the dispositif in the context of cultural developments, most notably its slow but steady shift away from textualization in digital media. As musicians are adapting to ensuing cultural and, above all, economic changes, new musical forms emerge that rely to a lesser degree on fully notated scores, such as “comprovisation” or laptop performance. Antithetically, the computer also allows the creation of “authorless” notated scores in real time to be sight-read by capable musicians—a practice for which special software has been developed in recent years. Because these scores are not meant to be kept and distributed, they are ephemeral and, therefore, disposable. Three examples by the author are given to illustrate the interwovenness of this approach, where carefully selected narratives and dramaturgies make up for the inherent unpredictability of the outcome.},
	language = {en},
	number = {1},
	urldate = {2019-05-22},
	journal = {Computer Music Journal},
	author = {Hajdu, Georg},
	month = mar,
	year = {2016},
	pages = {25--34},
	file = {2016.Hajdu_Disposable-Music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2016.Hajdu_Disposable-Music.pdf:application/pdf}
}

@inproceedings{bhagwati_vexations_2017,
	title = {Vexations of ephemerality. {Extreme} sight-reading in situative scores - for makers, performers, audiences.},
	abstract = {What do we do when we subject musicians and audiences to music prompted by real-time scores? Such situative scores create a new kind of immanent relationship between performers and audiences, between composers and performers, composers and audiences – a relationship whose ingrained disregard of context, memory, and knowledge has often been ignored. The use of situative scores seems to inscribe itself into a more general societal trend that uses technology to ephemeralize our lives, to decouple presence from its history. While this immanence has often been perceived as a force for the emancipation of performers and spectators, it can also give rise to unaccountability. Do artistic practices that ephemeralize our artistic 'regime of perception, sensation and interpretation' (Rancière) - such as situative scores – foster abuses of immanence?. In this paper, I will look at such questions from the perspective of the performers, the audiences and the makers of such scores – the composers.},
	language = {en},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Bhagwati, Sandeep},
	year = {2017},
	pages = {6},
	file = {15-vexations_ephemerality.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2017/15-vexations_ephemerality.pdf:application/pdf}
}

@phdthesis{wierenga_searching_2016,
	address = {New York, U.S.A.},
	title = {Searching for {Sounds}: {Instrumental} {Agency} and {Modularity} in {Electroacoustic} {Improvisation}},
	language = {en},
	school = {City University of New York},
	author = {Wierenga, Stephen (Red)},
	year = {2016},
	file = {2016.PhD.Wierenga.Stephen.SearchingForSounds-InstrumentalAgencyAndModularityInElectronicMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2016.PhD.Wierenga.Stephen.SearchingForSounds-InstrumentalAgencyAndModularityInElectronicMusic.pdf:application/pdf}
}

@incollection{adams_inventing_2008,
	address = {Berlin, Heidelberg},
	title = {Inventing {Malleable} {Scores}: {From} {Paper} to {Screen} {Based} {Scores}},
	volume = {7},
	isbn = {978-3-540-79485-1 978-3-540-79486-8},
	shorttitle = {Inventing {Malleable} {Scores}},
	url = {http://link.springer.com/10.1007/978-3-540-79486-8_22},
	abstract = {This paper examines the idea of artistic license of the interpreter as a positive aspect of composition. The possibilities of participating in the creative act beyond the role of the traditional interpreter are illustrated by tracing the development of malleability in score writing in selected works of the author. Starting with the standard score, examples are given for the various forms of malleable scores that lead up to the application of real-time electronic scores in which a concept of self-conduction is feasibly implemented for use in distributed ensembles.},
	language = {en},
	urldate = {2019-05-22},
	booktitle = {Transdisciplinary {Digital} {Art}. {Sound}, {Vision} and the {New} {Screen}},
	publisher = {Springer Berlin Heidelberg},
	author = {Clay, Arthur},
	editor = {Adams, Randy and Gibson, Steve and Arisona, Stefan Müller},
	year = {2008},
	doi = {10.1007/978-3-540-79486-8_22},
	pages = {255--269},
	file = {Clay,Arthur Inventing Malleable Scores.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/Clay,Arthur Inventing Malleable Scores.pdf:application/pdf}
}

@article{freeman_extreme_2008,
	title = {Extreme {Sight}-{Reading}, {Mediated} {Expression}, and {Audience} {Participation}: {Real}-{Time} {Music} {Notation} in {Live} {Performance}},
	volume = {32},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Extreme {Sight}-{Reading}, {Mediated} {Expression}, and {Audience} {Participation}},
	url = {http://www.mitpressjournals.org/doi/10.1162/comj.2008.32.3.25},
	doi = {10.1162/comj.2008.32.3.25},
	language = {en},
	number = {3},
	urldate = {2019-05-22},
	journal = {Computer Music Journal},
	author = {Freeman, Jason},
	month = sep,
	year = {2008},
	pages = {25--41},
	file = {CMJ-32-3-Freeman_Extreme Sight-reading.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/CMJ-32-3-Freeman_Extreme Sight-reading.pdf:application/pdf}
}

@article{godoy_gestural-sonorous_2006,
	title = {Gestural-{Sonorous} {Objects}: embodied extensions of {Schaeffer}'s conceptual apparatus},
	volume = {11},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Gestural-{Sonorous} {Objects}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771806001439/type/journal_article},
	doi = {10.1017/S1355771806001439},
	language = {en},
	number = {2},
	urldate = {2019-05-22},
	journal = {Organised Sound},
	author = {Godøy, Rolf Inge},
	month = aug,
	year = {2006},
	pages = {149--157},
	file = {2006.Godoy.Gestural_Sonorous_Objects.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2006.Godoy.Gestural_Sonorous_Objects.pdf:application/pdf}
}

@book{roads_microsound_2001,
	address = {Cambridge, Mass.},
	title = {Microsound},
	isbn = {978-0-262-18215-7},
	language = {en},
	publisher = {MIT Press},
	author = {Roads, Curtis},
	year = {2001},
	note = {OCLC: 834185525},
	file = {Roads_Curtis_Microsound.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Roads, Curtis/Roads_Curtis_Microsound.pdf:application/pdf}
}

@article{hunt_mapping_2002,
	title = {Mapping performer parameters to synthesis engines},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002030/type/journal_article},
	doi = {10.1017/S1355771802002030},
	language = {en},
	number = {2},
	urldate = {2019-05-22},
	journal = {Organised Sound},
	author = {Hunt, Andy and Wanderley, Marcelo M.},
	month = aug,
	year = {2002},
	pages = {97--108},
	file = {2002.Hunt.Wanderley.MappingPerformerParametersToSynthesisEngines.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2002.Hunt.Wanderley.MappingPerformerParametersToSynthesisEngines.pdf:application/pdf}
}

@inproceedings{hunt_towards_2000,
	address = {Berlin, Allemagne.},
	title = {Towards a {Model} for {Instrumental} {Mapping} in {Expert} {Musical} {Interaction}},
	abstract = {This paper reviews models of the ways in which performer instrumental actions can be linked to sound synthesis parameters. We analyse available literature on both acoustical instrument simulation and mapping of input devices to sound synthesis in general human-computer interaction. We further demonstrate why a more complex mapping strategy is required to maximise human performance possibilities in expert manipulation situations by showing clear measurements of user performance improvement over time. We finally discuss a general model for instrumental mapping, by separating the mapping layer into two independent parts. This model allows the expressive use of different input devices within the same architecture, or conversely, the use of different synthesis algorithms, by only changing one part of the mapping layer.},
	language = {en},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Hunt, Andy and Wanderley, Marcelo M and Kirk, Ross},
	year = {2000},
	pages = {4},
	file = {HUNT - Towards a Model for Instrumental Mapping in Expert Musical Interaction.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/HUNT - Towards a Model for Instrumental Mapping in Expert Musical Interaction.pdf:application/pdf}
}

@article{wanderley_gestural_2004,
	title = {Gestural {Control} of {Sound} {Synthesis}},
	volume = {92},
	issn = {0018-9219},
	url = {http://ieeexplore.ieee.org/document/1278687/},
	doi = {10.1109/JPROC.2004.825882},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {Proceedings of the IEEE},
	author = {Wanderley, M.M. and Depalle, P.},
	month = apr,
	year = {2004},
	pages = {632--644},
	file = {2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_IEEE/2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:application/pdf}
}

@inproceedings{winkler_real-time_2004,
	address = {Paris},
	title = {The real-time score. {A} missing-link in computer-music performance},
	abstract = {Between the realms of improvisation and the execution of a paperwritten, fixed score the concept of RealtimeScore opens a kind of "Third Way" of interpretation.},
	language = {en},
	booktitle = {Proceedings of the {Sound} and music computing conference},
	author = {Winkler, Gerhard E},
	year = {2004},
	pages = {6},
	file = {2004.Winkler-THE  REALTIME-SCORE. A MISSING-LINK IN COMPUTER-MUSIC PERFORMANCE.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/2004.Winkler-THE  REALTIME-SCORE. A MISSING-LINK IN COMPUTER-MUSIC PERFORMANCE.pdf:application/pdf}
}

@article{vickery_limitations_2014,
	title = {The {Limitations} of {Representing} {Sound} and {Notation} on {Screen}},
	volume = {19},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S135577181400020X/type/journal_article},
	doi = {10.1017/S135577181400020X},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Vickery, Lindsay},
	month = dec,
	year = {2014},
	pages = {215--227},
	file = {2014.Vickery.The_Limitations_of_Representing_Sound_and_Notation_on_Screendiv.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2014/cambridge-core_mediation-notation-and-communication-in-electroacoustic-music-performance_1Dec2017/2014.Vickery.The_Limitations_of_Representing_Sound_and_Notation_on_Screendiv.pdf:application/pdf}
}

@phdthesis{bin_show_2018,
	address = {London},
	title = {The {Show} {Must} {Go} {Wrong}: {Towards} an understanding of audience perception of error in digital musical instrument performance},
	abstract = {This thesis is about DMI (digital musical instrument) performance, its audiences, and their perception of error. The goal of this research is to improve current understanding of how audiences perceive DMI performance, where performers and their audiences often have no shared, external frame of reference with which to judge the musical output. Further complicating this audience-performer relationship are human-computer interaction (HCI) issues arising from the use of a computer as a musical instrument. In current DMI literature, there is little direct inquiry of audience perception on these issues. Error is an aspect of this kind of audience perception. Error, a condition reached by stepping out of bounds, appears at first to be a simple binary quantity, but the location and nature of those boundaries change with context. With deviation the locus of style and artistic progress, understanding how audiences perceive error has the potential to lend important insight to the cultural mechanics of DMI performance. In this thesis I describe the process of investigating audience perception and unpacking these issues through three studies. Each study examines the relative effects of various factors on audience perception — instrument familiarity and musical style, gesture size, and visible risk — using a novel methodology combining real-time data collected by mobile phone, and post- hoc data in the form of written surveys. The results have implications for DMI and HCI researchers as well as DMI performers and composers, and contribute insights on these confounding factors from the audience’s perspective as well as important insights on audience perception of error in this context. Further, through this thesis I contribute a practical method and tool that can be used to continue this audience-focused work in the future.},
	language = {en},
	school = {Queen Mary University of London},
	author = {Bin, S. M. Astrid},
	month = may,
	year = {2018},
	file = {2018.PhD.Bin.ShowMustGoWrong.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2018.PhD.Bin.ShowMustGoWrong.pdf:application/pdf}
}

@article{arfib_strategies_2002,
	title = {Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002054/type/journal_article},
	doi = {10.1017/S1355771802002054},
	abstract = {This paper is about mapping strategies between gesture data and synthesis model parameters by means of perceptual spaces. We define three layers in the mapping chain: from gesture data to gesture perceptual space, from sound perceptual space to synthesis model parameters, and between the two perceptual spaces. This approach makes the implementation highly modular. Both perceptual spaces are developed and depicted with their features. To get a simple mapping between the gesture perceptual subspace and the sound perceptual subspace, we need to focus our attention on the two other mappings. We explain the mapping types: explicit/implicit, static/dynamic. We also present the technical and esthetical limits introduced by mapping. Some practical examples are given of the use of perceptual spaces in experiments done at LMA in a musical context. Finally, we discuss several implications of the mapping strategies: the influence of chosen mapping limits onto performers’ virtuosity, and the incidence of mapping on the learning process with virtual instruments and on improvisation possibilities.},
	language = {en},
	number = {2},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Arfib, D. and Couturier, J. M. and Kessous, L. and Verfaille, V.},
	month = aug,
	year = {2002},
	pages = {127--144},
	file = {ARFIB - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/ARFIB - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:application/pdf}
}

@incollection{cance_what_2012,
	title = {What is intrumentality in new digital musical devices ? {A} contribution from cognitive linguistics \& psychology},
	language = {en},
	booktitle = {La musique et ses instruments},
	author = {Cance, Caroline and Genevois, Hugues and Dubois, Danièle},
	year = {2012},
	pages = {283--298},
	file = {CIM_Article_Cance_al.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CIM/CIM_Article_Cance_al.pdf:application/pdf}
}

@article{cascone_aesthetics_2000,
	title = {The {Aesthetics} of {Failure}: “{Post}-{Digital}” {Tendencies} in {Contemporary} {Computer} {Music}},
	volume = {24},
	language = {en},
	number = {4},
	journal = {Computer Music Journal},
	author = {Cascone, Kim},
	year = {2000},
	pages = {7},
	file = {CMJ24_4_Cascone_Aesthetics of failure.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/CMJ24_4_Cascone_Aesthetics of failure.pdf:application/pdf}
}

@book{mcneill_gesture_2005,
	address = {Chicago},
	title = {Gesture and thought},
	isbn = {978-0-226-51462-8},
	language = {en},
	publisher = {University of Chicago Press},
	author = {McNeill, David},
	year = {2005},
	keywords = {Gesture, Language and languages, Psycholinguistics, Sign language, Speech, Thought and thinking},
	file = {David McNeill - Gesture and Thought (2005, University Of Chicago Press).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/McNeill, David/David McNeill - Gesture and Thought (2005, University Of Chicago Press).pdf:application/pdf}
}

@article{magnusson_scoring_2014,
	title = {Scoring with {Code}: {Composing} with algorithmic notation},
	volume = {19},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Scoring with {Code}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771814000259/type/journal_article},
	doi = {10.1017/S1355771814000259},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Magnusson, Thor},
	month = dec,
	year = {2014},
	pages = {268--275},
	file = {div_classtitleScoring_with_Code_Composing_with_algorithmic_notationdiv.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2014/cambridge-core_mediation-notation-and-communication-in-electroacoustic-music-performance_1Dec2017/div_classtitleScoring_with_Code_Composing_with_algorithmic_notationdiv.pdf:application/pdf}
}

@incollection{kronland-martinet_emergent_2008,
	address = {Berlin, Heidelberg},
	title = {Emergent {Rhythms} through {Multi}-agency in {Max}/{MSP}},
	volume = {4969},
	isbn = {978-3-540-85034-2 978-3-540-85035-9},
	url = {http://link.springer.com/10.1007/978-3-540-85035-9_26},
	abstract = {This paper presents a multi-agents architecture created in Max/MSP that generates polyphonic rhythmic patterns which continuously evolve and develop in a musically intelligent manner. Agent-based software offers a new method for real-time composition that allows for complex interactions between individual voices while requiring very little user interaction or supervision. The system described, Kinetic Engine is an environment in which networked computers, using individual software agents, emulate drummers improvising within a percussion ensemble. Player agents assume roles and personalities within the ensemble, and communicate with one another to create complex rhythmic interactions. The software has been premiered in a recent work, Drum Circle, which is briefly described.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {Computer {Music} {Modeling} and {Retrieval}. {Sense} of {Sounds}},
	publisher = {Springer Berlin Heidelberg},
	author = {Eigenfeldt, Arne},
	editor = {Kronland-Martinet, Richard and Ystad, Sølvi and Jensen, Kristoffer},
	year = {2008},
	doi = {10.1007/978-3-540-85035-9_26},
	pages = {368--379},
	file = {emergent_rhythms_maxmsp.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/emergent_rhythms_maxmsp.pdf:application/pdf}
}

@incollection{orlarey_faust_2008,
	address = {Paris, France},
	title = {{FAUST} : an {Efficient} {Functional} {Approach} to {DSP} {Programming}},
	volume = {290},
	abstract = {FAUST is a programming language that provides a purely functional approach to signal processing while offering a high level of performance. FAUST aims at being complemen-tary to existing audio languages by offering a viable and efficient alternative to C/C++ to develop signal processing libraries, audio plug-ins or standalone applications. The language is based on a simple and well defined formal semantics. A FAUST pro-gram denotes a signal processor, a mathematical function that transforms input signals into output signals. Being able to know precisely what a program computes is important not only for programmers, but also for compilers needing to generate the best possible code. Moreover these semantics questions are crucial for the long-term preservation of music programs 1 . The following paragraphs will give an overview of the language as well as a description of the compiler, including the generation of parallel code.},
	language = {en},
	booktitle = {New {Computational} {Paradigms} for {Computer} {Music}},
	publisher = {Delatour},
	author = {Orlarey, Yann and Fober, Dominique and Letz, Stephane},
	year = {2008},
	pages = {33},
	file = {FAUST_an_Efficient_Functional_Approach_to_DSP_Prog.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/IRCAM/New paradigms for computer music/FAUST_an_Efficient_Functional_Approach_to_DSP_Prog.pdf:application/pdf}
}

@article{born_musical_2005,
	title = {On {Musical} {Mediation}: {Ontology}, {Technology} and {Creativity}},
	volume = {2},
	issn = {1478-5722, 1478-5730},
	shorttitle = {On {Musical} {Mediation}},
	url = {https://www.cambridge.org/core/product/identifier/S147857220500023X/type/journal_article},
	doi = {10.1017/S147857220500023X},
	abstract = {This article develops a theoretical analysis of music and mediation, building on the work of Theodor Adorno, Tia DeNora and Antoine Hennion. It begins by suggesting that Lydia Goehr’s account of the work concept requires such a perspective. Drawing on Alfred Gell’s anthropology of art, the article outlines an approach to mediation that incorporates understandings of music’s social, technological and temporal dimensions. It suggests that music’s mediations have taken a number of historical forms, which cohere into assemblages, and that we should be alert to shifts in the dominant forms of musical assemblage. In the latter part of the article, these tools are used to conceptualize changing forms of musical creativity that emerged over the twentieth century. A comparison is made between the work concept and jazz and improvised electronic musics. Three contemporary digital music experiments are discussed in detail, demonstrating the concepts of the provisional work and of social, distributed and relayed creativity. Throughout, key motifs are mediation, creativity, and the negotiation of difference.},
	language = {en},
	number = {1},
	urldate = {2019-05-23},
	journal = {Twentieth-Century Music},
	author = {Born, Georgina},
	month = mar,
	year = {2005},
	pages = {7--36},
	file = {GeorginaBorn_On Musical Mediation Ontology Technology and Creativity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CambridgeTwentiethCenturyMusic/GeorginaBorn_On Musical Mediation Ontology Technology and Creativity.pdf:application/pdf}
}

@article{schloss_using_2003,
	title = {Using {Contemporary} {Technology} in {Live} {Performance}: {The} {Dilemma} of the {Performer}},
	volume = {32},
	issn = {0929-8215},
	shorttitle = {Using {Contemporary} {Technology} in {Live} {Performance}},
	url = {http://www.tandfonline.com/doi/abs/10.1076/jnmr.32.3.239.16866},
	doi = {10.1076/jnmr.32.3.239.16866},
	abstract = {The use of computers in live performance has resulted in a situation in which cause-and-effect has effectively disappeared, for the ﬁrst time since music began. Once we started to use computers in live performance – to interpret abstract gestures and generate sound as a result – the age-old relationship between gesture and result became so blurred as to be often imperceptible. In historical terms, this problem is extremely recent, involving only the last few decades of musical practice preceded by at least thirty thousand years of music-making by conventional (acoustic) means. The aim of this paper is to show how this affects contemporary performance and the relationship between the performer and the audience.},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Journal of New Music Research},
	author = {Schloss, W. Andrew},
	month = sep,
	year = {2003},
	pages = {239--242},
	file = {JNMR02.Schloss.Dilemma_of_the_Performer.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_J_NewMusicResearch/JNMR02.Schloss.Dilemma_of_the_Performer.pdf:application/pdf}
}

@book{butler_playing_2014,
	address = {New York},
	title = {Playing with something that runs: technology, improvisation, and composition in {DJ} and laptop performance},
	isbn = {978-0-19-539361-3 978-0-19-539362-0},
	shorttitle = {Playing with something that runs},
	language = {en},
	publisher = {Oxford University Press},
	author = {Butler, Mark J.},
	year = {2014},
	keywords = {History and criticism, Electronic dance music, Production and direction},
	file = {Mark J. Butler-Playing with Something That Runs_ Technology, Improvisation, and Composition in DJ and Laptop Performance-Oxford University Press (2014).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Butler, Mark J./Mark J. Butler-Playing with Something That Runs_ Technology, Improvisation, and Composition in DJ and Laptop Performance-Oxford University Press (2014).pdf:application/pdf}
}

@inproceedings{zbyszynski_ten_2007,
	address = {New York, New York},
	title = {Ten years of tablet musical interfaces at {CNMAT}},
	url = {http://portal.acm.org/citation.cfm?doid=1279740.1279758},
	doi = {10.1145/1279740.1279758},
	abstract = {We summarize a decade of musical projects and research employing Wacom digitizing tablets as musical controllers, discussing general implementation schemes using Max/MSP and OpenSoundControl, and specific implementations in musical improvisation, interactive sound installation, interactive multimedia performance, and as a compositional assistant. We examine two-handed sensing strategies and schemes for gestural mapping.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {Proceedings of the 7th international conference on {New} interfaces for musical expression - {NIME} '07},
	publisher = {ACM Press},
	author = {Zbyszynski, Michael and Wright, Matthew and Momeni, Ali and Cullen, Daniel},
	year = {2007},
	pages = {100},
	file = {nime2007_100.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2007/nime2007_100.pdf:application/pdf}
}

@article{canonne_improvisation_2012,
	title = {Improvisation collective libre et processus de création musicale: création et créativité au prisme de la coordination},
	language = {fr},
	number = {1},
	journal = {Revue de musicologie},
	author = {Canonne, Clément},
	year = {2012},
	pages = {42},
	file = {Rdm-98-2-Canonne_ImprovisationCollectiveLibre.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue_de_Musicologie/Rdm-98-2-Canonne_ImprovisationCollectiveLibre.pdf:application/pdf}
}

@inproceedings{wanderley_escher-modeling_1998,
	address = {San Diego, CA, USA},
	title = {{ESCHER}-modeling and performing composed instruments in real-time},
	volume = {2},
	isbn = {978-0-7803-4778-6},
	url = {http://ieeexplore.ieee.org/document/727836/},
	doi = {10.1109/ICSMC.1998.727836},
	abstract = {This article presents ESCHER, a sound synthesis environment based on IrcamÕs real-time audio environment jMax. ESCHER is a modular system providing synthesis-independent prototyping of gesturally-controlled instruments by means of parameter interpolation. The system divides into two components: gestural controller and synthesis engine. Mapping between components takes place on two independent levels, coupled by an intermediate abstract parameter layer. This separation allows a flexible choice of controllers and/or sound synthesis methods.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {{SMC}'98 {Conference} {Proceedings}. 1998 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({Cat}. {No}.98CH36218)},
	publisher = {IEEE},
	author = {Wanderley, M.M. and Schnell, N. and Rovan, J.},
	year = {1998},
	pages = {1080--1084},
	file = {WANDERLEY - Escher.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_INSTRU/WANDERLEY - Escher.pdf:application/pdf}
}

@article{fels_mapping_2002,
	title = {Mapping transparency through metaphor: towards more expressive musical instruments},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Mapping transparency through metaphor},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002042/type/journal_article},
	doi = {10.1017/S1355771802002042},
	abstract = {We define a two-axis transparency framework that can be used as a predictor of the expressivity of a musical device. One axis is the player's transparency scale, while the other is the audience's transparency scale. Through consideration of both traditional instrumentation and new technology-driven interfaces, we explore the role that metaphor plays in developing expressive devices. Metaphor depends on a literature, which forms the basis for making transparent device mappings. We examine four examples of systems that use metaphor: Iamascope, Sound Sculpting, MetaMuse, and Glove-TalkII; and discuss implications on transparency and expressivity. We believe this theory provides a framework for design and evaluation of new human-machine and humanhuman interactions, including musical instruments.},
	language = {en},
	number = {2},
	urldate = {2019-05-24},
	journal = {Organised Sound},
	author = {Fels, Sidney and Gadd, Ashley and Mulder, Axel},
	month = aug,
	year = {2002},
	pages = {109--126},
	file = {2002.OS.Fels.Mapping Transparency through Metaphor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2002/2002.OS.Fels.Mapping Transparency through Metaphor.pdf:application/pdf}
}

@inproceedings{bin_risky_2018,
	address = {Blacksburg, Virginia, USA},
	title = {Risky business: {Disfluency} as a design strategy},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0012.pdf},
	abstract = {This paper presents a study examining the effects of disfluent design on audience perception of digital musical instrument (DMI) performance. Disfluency, defined as a barrier to effortless cognitive processing, has been shown to generate better results in some contexts as it engages higher levels of cognition. We were motivated to determine if disfluent design in a DMI would result in a risk state that audiences would be able to perceive, and if this would have any effect on their evaluation of the performance. A DMI was produced that incorporated a disfluent characteristic: It would turn itself off if not constantly moved. Six physically identical instruments were produced, each in one of three versions: Control (no disfluent characteristics), mild disfluency (turned itself off slowly), and heightened disfluency (turned itself off more quickly). 6 percussionists each performed on one instrument for a live audience (N=31), and data was collected in the form of real-time feedback (via a mobile phone app), and post-hoc surveys. Though there was little difference in ratings of enjoyment between the versions of the instrument, the real-time and qualitative data suggest that disfluent behaviour in a DMI may be a way for audiences to perceive and appreciate performer skill.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Bin, S. M. Astrid and Bryan-Kinns, Nick and McPherson, Andrew P.},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {45--50},
	file = {nime2018_paper0012.Bin.DisfluencyAsADesignStrategy.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/nime2018_paper0012.Bin.DisfluencyAsADesignStrategy.pdf:application/pdf}
}

@inproceedings{marquez-borbon_problem_2018,
	address = {Blacksburg, Virginia, USA},
	title = {The {Problem} of {DMI} {Adoption} and {Longevity}: {Envisioning} a {NIME} {Performance} {Pedagogy}},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0040.pdf},
	abstract = {This paper addresses the prevailing longevity problem of digital musical instruments (DMIs) in NIME research and design by proposing a holistic system design approach. Despite recent efforts to examine the main contributing factors of DMI falling into obsolescence, such attempts to remedy this issue largely place focus on the artifacts establishing themselves, their design processes and technologies. However, few existing studies have attempted to proactively build a community around technological platforms for DMIs, whilst bearing in mind the social dynamics and activities necessary for a budding community. We observe that such attempts while important in their undertaking, are limited in their scope. In this paper we will discuss that achieving some sort of longevity must be addressed beyond the device itself and must tackle broader ecosystemic factors. We hypothesize, that a longevous DMI design must not only take into account a target community but it may also require a non-traditional pedagogical system that sustains artistic practice.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Marquez-Borbon, Adnan and Martinez-Avila, Juan Pablo},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {190--195},
	file = {2018.MarquezBorbon-DMI Adoption and Longevity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/2018.MarquezBorbon-DMI Adoption and Longevity.pdf:application/pdf}
}

@inproceedings{tahiroglu_contextualising_2018,
	address = {Blacksburg, Virginia, USA},
	title = {Contextualising {Idiomatic} {Gestures} in {Musical} {Interactions} with {NIMEs}},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0028.pdf},
	abstract = {This paper introduces various ways that idiomatic gestures emerge in performance practice with new musical instruments. It demonstrates that idiomatic gestures can play an important role in the development of personalized performance practices that can be the basis for the development of style and expression. Three detailed examples – biocontrollers, accordion-inspired instruments, and a networked intelligent controller – illustrate how a complex suite of factors throughout the design, composition and performance processes can influence the development of idiomatic gestures. We argue that the explicit consideration of idiomatic gestures throughout the life cycle of new instruments can facilitate the emergence of style and give rise to performances that can develop rich layers of meaning.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Tahiroglu, Koray and Gurevich, Michael and Knapp, R. Benjamin},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {126--131},
	file = {nime2018_paper0028.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/nime2018_paper0028.pdf:application/pdf}
}

@inproceedings{cantrell_designing_2017,
	address = {Copenhagen, Denmark},
	title = {Designing {Intent}: {Defining} {Critical} {Meaning} for {NIME} {Practitioners}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0032.pdf},
	abstract = {The ideation, conception and implementation of new musical interfaces and instruments provide more than the mere construction of digital objects. As physical and digital assemblages, interfaces also act as traces of the authoring entities that created them. Their intentions, likes, dislikes, and ultimate determinations of what is creatively useful all get embedded into the available choices of the interface. In this light, the self-perception of the musical HCI and instrument designer can be seen as occupying a primary importance in the instruments and interfaces that eventually come to be created. The work of a designer who self-identifies as an artist may result in a vastly different outcome than one who considers him or herself to be an entrepreneur, or a scientist, for example. These differing definitions of self as well as their HCI outcomes require their own means of critique, understanding and expectations. All too often, these definitions are unclear, or the considerations of overlapping means of critique remain unexamined.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Cantrell, Joe},
	year = {2017},
	pages = {169--173},
	file = {2017.Cantrell_Social Life Of Musical Instruments_nime2017_paper0032.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/2017.Cantrell_Social Life Of Musical Instruments_nime2017_paper0032.pdf:application/pdf}
}

@inproceedings{alexander-adams_flexible_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {A {Flexible} {Platform} for {Tangible} {Graphic} {Scores}},
	url = {http://www.nime.org/proceedings/2015/nime2015_172.pdf},
	abstract = {This paper outlines the development of a versatile platform for the performance and composition of tangible graphic scores, providing technical details of the hardware and software design. The system is conceived as a touch surface facilitating modular textured plates, coupled with corresponding visual feedback.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Alexander-Adams, Simon and Gurevich, Michael},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {174--175}
}

@inproceedings{haddad_fragile_2017,
	address = {Copenhagen, Denmark},
	title = {Fragile {Instruments}: {Constructing} {Destructible} {Musical} {Interfaces}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0006.pdf},
	abstract = {We introduce a family of fragile electronic musical instruments designed to be "played” through the act of destruction. Each Fragile Instrument consists of an analog synthesizing circuit with embedded sensors that detect the destruction of an outer shell, which is destroyed and replaced for each performance. Destruction plays an integral role in both the spectacle and the generated sounds. This paper presents several variations of Fragile Instruments we have created, discussing their circuit design as well as choices of material for the outer shell and tools of destruction. We conclude by considering other approaches to create intentionally destructible electronic musical instruments.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Haddad, Don Derek and Xiao, Xiao and Machover, Tod and Paradiso, Joseph},
	year = {2017},
	pages = {30--33}
}

@inproceedings{morreale_design_2017,
	address = {Copenhagen, Denmark},
	title = {Design for {Longevity}: {Ongoing} {Use} of {Instruments} from {NIME} 2010-14},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0036.pdf},
	abstract = {Every new edition of NIME brings dozens of new DMIs and the feeling that only a few of them will eventually break through. Previous work tried to address this issue with a deductive approach by formulating design frameworks; we addressed this issue with a inductive approach by elaborating on successes and failures of previous DMIs. We contacted 97 DMI makers that presented a new instrument at five successive editions of NIME (2010-2014); 70 answered. They were asked to indicate the original motivation for designing the DMI and to present information about its uptake. Results confirmed that most of the instruments have difficulties establishing themselves. Also, they were asked to reflect on the specific factors that facilitated and those that hindered instrument longevity. By grounding these reflections on existing reserach on NIME and HCI, we propose a series of design considerations for future DMIs.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Morreale, Fabio and McPherson, Andrew},
	year = {2017},
	pages = {192--197},
	file = {2017.Morreale Design for Longevity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/2017.Morreale Design for Longevity.pdf:application/pdf}
}

@inproceedings{berthaut_liveness_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Liveness {Through} the {Lens} of {Agency} and {Causality}},
	url = {http://www.nime.org/proceedings/2015/nime2015_272.pdf},
	abstract = {Liveness is a well-known problem with Digital Musical Instruments (DMIs). When used in performances, DMIs provide less visual information than acoustic instruments, preventing the audience from understanding how the musicians influence the music. In this paper, we look at this issue through the lens of causality. More specifically, we investigate the attribution of causality by an external observer to a performer, relying on the theory of apparent mental causation. We suggest that the perceived causality between a performer's gestures and the musical result is central to liveness. We present a framework for assessing attributed causality and agency to a performer, based on a psychological theory which suggests three criteria for inferred causality. These criteria then provide the basis of an experimental study investigating the effect of visual augmentations on audience's inferred causality. The results provide insights on how the visual component of performances with DMIs impacts the audience's causal inferences about the performer. In particular we show that visual augmentations help highlight the influence of the musician when parts of the music are automated, and help clarify complex mappings between gestures and sounds. Finally we discuss the potential wider implications for assessing liveness in the design of new musical interfaces.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Berthaut, Florent and Coyle, David and Moore, James and Limerick, Hannah},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {382--386},
	file = {nime2015_272.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2015/nime2015_272.pdf:application/pdf}
}

@inproceedings{bowers_hybrid_2014,
	address = {London, United Kingdom},
	title = {Hybrid {Resonant} {Assemblages}: {Rethinking} {Instruments}, {Touch} and {Performance} in {New} {Interfaces} for {Musical} {Expression}},
	url = {http://www.nime.org/proceedings/2014/nime2014_438.pdf},
	abstract = {This paper outlines a concept of hybrid resonant assemblages, combinations of varied materials excited by sound transducers, feeding back to themselves via digital signal processing. We ground our concept as an extension of work by David Tudor, Nicolas Collins and Bowers and Archer [NIME 2005] and draw on a variety of critical perspectives in the social sciences and philosophy to explore such assemblages as an alternative to more familiar ideas of instruments and interfaces. We lay out a conceptual framework for the exploration of hybrid resonant assemblages and describe how we have approached implementing them. Our performance experience is presented and implications for work are discussed. In the light of our work, we urge a reconsideration of the implicit norms of performance which underlie much research in NIME. In particular, drawing on the philosophical work of Jean-Luc Nancy, we commend a wider notion of touch that also recognises the performative value of withholding contact.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Bowers, John and Haas, Annika},
	month = jun,
	year = {2014},
	pages = {7--12},
	file = {2014.Bowers.Hybrid Resonant assemblages_nime2014_438.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/2014.Bowers.Hybrid Resonant assemblages_nime2014_438.pdf:application/pdf}
}

@inproceedings{jensenius_gesture_2014,
	address = {London, United Kingdom},
	title = {To gesture or {Not}? {An} {Analysis} of {Terminology} in {NIME} {Proceedings} 2001–2013},
	url = {http://www.nime.org/proceedings/2014/nime2014_351.pdf},
	abstract = {The term 'gesture' has represented a buzzword in the NIME community since the beginning of its conference series. But how often is it actually used, what is it used to describe, and how does its usage here differ from its usage in other fields of study? This paper presents a linguistic analysis of the motion-related terminology used in all of the papers published in the NIME conference proceedings to date (2001-2013). The results show that 'gesture' is in fact used in 62 \% of all NIME papers, which is a significantly higher percentage than in other music conferences (ICMC and SMC), and much more frequently than it is used in the HCI and biomechanics communities. The results from a collocation analysis support the claim that 'gesture' is used broadly in the NIME community, and indicate that it ranges from the description of concrete human motion and system control to quite metaphorical applications.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Jensenius, Alexander Refsum},
	month = jun,
	year = {2014},
	pages = {217--220}
}

@inproceedings{mamedes_composing_2014,
	address = {London, United Kingdom},
	title = {Composing for {DMIs} {Entoa}, a {Dedicate} {Piece} for {Intonaspacio}},
	url = {http://www.nime.org/proceedings/2014/nime2014_411.pdf},
	abstract = {Digital Musical Instruments (DMIs) have difficulties establishing themselves after their creation. A huge number of DMIs is presented every year and few of them actually remain in use. Several causes could explain this reality, among them the lack of a proper instrumental technique, inadequacy of the traditional musical notation and the non-existence of a repertoire dedicated to the instrument. In this paper we present Entoa, the first written music for Intonaspacio, a DMI we designed in our research project. We propose some strategies for mapping data from sensors to sound processing, in order to accomplish an expressive performance. Entoa is divided in five different sections that corresponds to five movements. For each, a different mapping is designed, introducing subtle alterations that progressively explore the ensemble of features of the instrument. The performer is then required to adapt his repertoire of gestures along the piece. Indications are expressed through a gestural notation, where freedom is give to performer to control certain parameters at specific moments in the music.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Mamedes, Clayton and Rodrigues, Mailis and Wanderley, Marcelo M. and Manzolli, Jônatas and Garcia, Denise H. L. and Ferreira-Lopes, Paulo},
	month = jun,
	year = {2014},
	pages = {509--512},
	file = {nime2014_411_Mamedes_Composing_for_entoa.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_411_Mamedes_Composing_for_entoa.pdf:application/pdf}
}

@inproceedings{tomas_tangible_2014,
	address = {London, United Kingdom},
	title = {Tangible {Scores}: {Shaping} the {Inherent} {Instrument} {Score}},
	url = {http://www.nime.org/proceedings/2014/nime2014_352.pdf},
	abstract = {Tangible Scores are a new paradigm for musical instrument design with a physical configuration inspired by graphic scores. In this paper we will focus on the design aspects of this new interface as well as on some of the related technical details. Creating an intuitive, modular and expressive instrument for textural music was the primary driving force. Following these criteria, we literally incorporated a musical score onto the surface of the instrument as a way of continuously controlling several parameters of the sound synthesis. Tangible Scores are played with both hands and they can adopt multiple physical forms. Complex and expressive sound textures can be easily played over a variety of timbres, enabling precise control in a natural manner.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Tomás, Enrique and Kaltenbrunner, Martin},
	month = jun,
	year = {2014},
	pages = {609--614},
	file = {nime2014_352.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_352.pdf:application/pdf}
}

@inproceedings{fyans_ecological_2012,
	address = {Ann Arbor, Michigan},
	title = {Ecological considerations for participatory design of {DMIs}},
	url = {http://www.nime.org/proceedings/2012/nime2012_253.pdf},
	abstract = {A study is presented examining the participatory design of digital musical interactions. The study takes into consideration the entire ecology of digital musical interactions including the designer, performer and spectator. A new instrument is developed through iterative participatory design involving a group of performers. Across the study the evolution of creative practice and skill development in an emerging community of practice is examined and a spectator study addresses the cognition of performance and the perception of skill with the instrument. Observations are presented regarding the cognition of a novel interaction and evolving notions of skill. The design process of digital musical interactions is reflected on focusing on involvement of the spectator in design contexts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Fyans, A. Cavan and Marquez-Borbon, Adnan and Stapleton, Paul and Gurevich, Michael},
	year = {2012},
	keywords = {cognition, DMIs, participatory design, skill, spectator},
	file = {nime2012_253.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_253.pdf:application/pdf}
}

@inproceedings{marquez-borbon_designing_2011,
	address = {Oslo, Norway},
	title = {Designing {Digital} {Musical} {Interactions} in {Experimental} {Contexts}},
	url = {http://www.nime.org/proceedings/2011/nime2011_373.pdf},
	abstract = {As NIME's focus has expanded beyond the design reportswhich were pervasive in the early days to include studies andexperiments involving music control devices, we report on aparticular area of activity that has been overlooked: designsof music devices in experimental contexts. We demonstratethis is distinct from designing for artistic performances, witha unique set of novel challenges. A survey of methodologicalapproaches to experiments in NIME reveals a tendency torely on existing instruments or evaluations of new devicesdesigned for broader creative application. We present twoexamples from our own studies that reveal the merits ofdesigning purpose-built devices for experimental contexts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Marquez-Borbon, Adnan and Gurevich, Michael and Fyans, A. Cavan and Stapleton, Paul},
	year = {2011},
	keywords = {DMIs, Experiment, Instrument Design, Methodology},
	pages = {373--376}
}

@inproceedings{fyans_examining_2010,
	address = {Sydney, Australia},
	title = {Examining the {Spectator} {Experience}},
	url = {http://www.nime.org/proceedings/2010/nime2010_451.pdf},
	abstract = {Drawing on a model of spectator understanding of error inperformance in the literature, we document a qualitativeexperiment that explores the relationships between domainknowledge, mental models, intention and error recognitionby spectators of performances with electronic instruments.Participants saw two performances with contrasting instruments, with controls on their mental model and understanding of intention. Based on data from a subsequent structured interview, we identify themes in participants' judgements and understanding of performance and explanationsof their spectator experience. These reveal both elementsof similarity and difference between the two performances,instruments and between domain knowledge groups. Fromthese, we suggest and discuss implications for the design ofnovel performative interactions with technology.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fyans, A. Cavan and Gurevich, Michael and Stapleton, Paul},
	year = {2010},
	keywords = {spectator, nime10, error, intention, mental model, qualitative},
	pages = {451--454},
	file = {nime2010_451.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2010/nime2010_451.pdf:application/pdf}
}

@inproceedings{cook_re-designing_2009,
	address = {Pittsburgh, PA, United States},
	title = {Re-{Designing} {Principles} for {Computer} {Music} {Controllers} : a {Case} {Study} of {SqueezeVox} {Maggie}},
	url = {http://www.nime.org/proceedings/2009/nime2009_218.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Cook, Perry R.},
	year = {2009},
	keywords = {wireless, voice synthesis, 1, hci, nime09, batteries, composed instruments, i will restate the, laptop orchestras, original 13 principles for, sensas, the original principles, to begin},
	pages = {218--221},
	file = {nime2009_218_PerryCook_Re-Designing Principles for Computer Music Controllers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_218_PerryCook_Re-Designing Principles for Computer Music Controllers.pdf:application/pdf}
}

@inproceedings{hsu_evaluating_2009,
	address = {Pittsburgh, PA, United States},
	title = {Evaluating {Interactive} {Music} {Systems} : {An} {HCI} {Approach}},
	url = {http://www.nime.org/proceedings/2009/nime2009_025.pdf},
	abstract = {In this paper, we discuss a number of issues related to the design of evaluation tests for comparing interactive music systems for improvisation. Our testing procedure covers rehearsal and performance environments, and captures the experiences of a musician/participant as well as an audience member/observer. We attempt to isolate salient components of system behavior, and test whether the musician or audience are able to discern between systems with significantly different behavioral components. We report on our experiences with our testing methodology, in comparative studies of our London and ARHS improvisation systems [1].},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Hsu, William and Sosnick, Marc},
	year = {2009},
	keywords = {human computer interaction, evaluation tests., Interactive music systems},
	pages = {25--28},
	file = {nime2009_025.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_025.pdf:application/pdf}
}

@inproceedings{bau_a20_2008,
	address = {Genoa, Italy},
	title = {The {A}20 : {Musical} {Metaphors} for {Interface} {Design}},
	url = {http://www.nime.org/proceedings/2008/nime2008_091.pdf},
	abstract = {We combine two concepts, the musical instrument as metaphorand technology probes, to explore how tangible interfaces canexploit the semantic richness of sound. Using participatorydesign methods from Human-Computer Interaction (HCI), wedesigned and tested the A20, a polyhedron-shaped, multichannel audio input/output device. The software maps soundaround the edges and responds to the user's gestural input,allowing both aural and haptic modes of interaction as well asdirect manipulation of media content. The software is designedto be very flexible and can be adapted to a wide range ofshapes. Our tests of the A20's perceptual and interactionproperties showed that users can successfully detect soundplacement, movement and haptic effects on this device. Ourparticipatory design workshops explored the possibilities of theA20 as a generative tool for the design of an extended,collaborative personal music player. The A20 helped users toenact scenarios of everyday mobile music player use and togenerate new design ideas.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bau, Olivier and Tanaka, Atau and Mackay, Wendy E.},
	year = {2008},
	keywords = {Generative design tools, Instrument building, Multi-faceted audio, Personal music devices, Tangible user interfaces, Technology probes},
	pages = {91--96},
	file = {nime2008_091.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_091.pdf:application/pdf}
}

@inproceedings{corness_performer_2008,
	address = {Genoa, Italy},
	title = {Performer {Model} : {Towards} a {Framework} for {Interactive} {Performance} {Based} on {Perceived} {Intention}},
	url = {http://www.nime.org/proceedings/2008/nime2008_265.pdf},
	abstract = {Through the developing of tools for analyzing the performerssonic and movement-based gestures, research into the systemperformer interaction has focused on the computer's ability torespond to the performer. Where as such work shows interestwithin the community in developing an interaction paradigmmodeled on the player, by focusing on the perception andreasoning of the system, this research assumes that theperformer's manner of interaction is in agreement with thiscomputational model. My study presents an alternative model ofinteraction designed for improvisatory performance centered onthe perception of the performer as understood by theories takenfrom performance practices and cognitive science.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Corness, Greg},
	year = {2008},
	keywords = {HCI, Interactive performance, Perception},
	pages = {265--268},
	file = {nime2008_265.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_265.pdf:application/pdf}
}

@inproceedings{kiefer_hci_2008,
	address = {Genoa, Italy},
	title = {{HCI} {Methodology} {For} {Evaluating} {Musical} {Controllers} : {A} {Case} {Study}},
	url = {http://www.nime.org/proceedings/2008/nime2008_087.pdf},
	abstract = {There is small but useful body of research concerning theevaluation of musical interfaces with HCI techniques. Inthis paper, we present a case study in implementing thesetechniques; we describe a usability experiment which evaluated the Nintendo Wiimote as a musical controller, andreflect on the effectiveness of our choice of HCI methodologies in this context. The study offered some valuable results,but our picture of the Wiimote was incomplete as we lackeddata concerning the participants' instantaneous musical experience. Recent trends in HCI are leading researchers totackle this problem of evaluating user experience; we reviewsome of their work and suggest that with some adaptation itcould provide useful new tools and methodologies for computer musicians.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Kiefer, Chris and Collins, Nick and Fitzpatrick, Geraldine},
	year = {2008},
	keywords = {Evaluating Musical Interac- tion, HCI Methodology, Wiimote},
	pages = {87--90},
	file = {nime2008_087.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_087.pdf:application/pdf}
}

@inproceedings{gurevich_expression_2007,
	address = {New York City, NY, United States},
	title = {Expression and {Its} {Discontents} : {Toward} an {Ecology} of {Musical} {Creation}},
	url = {http://www.nime.org/proceedings/2007/nime2007_106.pdf},
	abstract = {We describe the prevailing model of musical expression, which assumes a binary formulation of "the text" and "the act," along with its implied roles of composer and performer. We argue that this model not only excludes some contemporary aesthetic values but also limits the communicative ability of new music interfaces. As an alternative, an ecology of musical creation accounts for both a diversity of aesthetic goals and the complex interrelation of human and non-human agents. An ecological perspective on several approaches to musical creation with interactive technologies reveals an expanded, more inclusive view of artistic interaction that facilitates novel, compelling ways to use technology for music. This paper is fundamentally a call to consider the role of aesthetic values in the analysis of artistic processes and technologies.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gurevich, Michael and Treviño, Jeffrey},
	year = {2007},
	keywords = {evaluation, transparency, emotion, expressivity, aesthetic goal, communication, construct, discipline, discourse, experience, Expression, model, non-expressive},
	pages = {106--111},
	file = {nime2007_106.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2007/nime2007_106.pdf:application/pdf}
}

@inproceedings{bowers_creating_2006,
	address = {Paris, France},
	title = {Creating {Ad} {Hoc} {Instruments} with {Pin} \& {Play} \& {Perform}},
	url = {http://www.nime.org/proceedings/2006/nime2006_234.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bowers, John and Villar, Nicolas},
	year = {2006},
	keywords = {physical interfaces, music performance, Ad hoc instruments, new interfaces for musical expression., Pin\&Play},
	pages = {234--239},
	file = {2006.Bowers.Creating Ad Hoc Instruments with Pin&Play&Performnime2006_234.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/2006.Bowers.Creating Ad Hoc Instruments with Pin&Play&Performnime2006_234.pdf:application/pdf}
}

@inproceedings{dobrian_e_2006,
	address = {Paris, France},
	title = {The {E} in {NIME}: {Musical} {Expression} with {New} {Computer} {Interfaces}},
	url = {http://www.nime.org/proceedings/2006/nime2006_277.pdf},
	abstract = {Is there a distinction between New Interfaces for MusicalExpression and New Interfaces for Controlling Sound? Thisarticle begins with a brief overview of expression in musicalperformance, and examines some of the characteristics ofeffective "expressive" computer music instruments. Itbecomes apparent that sophisticated musical expressionrequires not only a good control interface but also virtuosicmastery of the instrument it controls. By studying effectiveacoustic instruments, choosing intuitive but complexgesture-sound mappings that take advantage of establishedinstrumental skills, designing intelligent characterizationsof performance gestures, and promoting long-term dedicatedpractice on a new interface, computer music instrumentdesigners can enhance the expressive quality of computermusic performance.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Dobrian, Christopher and Koppelman, Daniel},
	year = {2006},
	keywords = {performance, instrument design, Expression, virtuosity.},
	pages = {277--282},
	file = {nime2006_277.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_277.pdf:application/pdf}
}

@inproceedings{jensenius_towards_2006,
	address = {Paris, France},
	title = {Towards a {Gesture} {Description} {Interchange} {Format}},
	url = {http://www.nime.org/proceedings/2006/nime2006_176.pdf},
	abstract = {This paper presents our need for a Gesture Description Interchange Format (GDIF) for storing, retrieving and sharing information about music-related gestures. Ideally, it should be possible to store all sorts of data from various commercial and custom made controllers, motion capture and computer vision systems, as well as results from different types of gesture analysis, in a coherent and consistent way. This would make it possible to use the information with different software, platforms and devices, and also allow for sharing data between research institutions. We present some of the data types that should be included, and discuss issues which need to be resolved.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jensenius, Alexander Refsum and Kvifte, Tellef and Godøy, Rolf Inge},
	year = {2006},
	keywords = {gesture analysis, Gesture description, standards},
	pages = {176--179},
	file = {nime2006_176.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_176.pdf:application/pdf}
}

@inproceedings{bowers_not_2005,
	address = {Vancouver, BC, Canada},
	title = {Not {Hyper}, {Not} {Meta}, {Not} {Cyber} but {Infra}-{Instruments}},
	url = {http://www.nime.org/proceedings/2005/nime2005_005.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bowers, John and Archer, Phil},
	year = {2005},
	keywords = {hyperinstruments, design concepts and principles., Infra-instruments, meta-instruments, virtual instruments},
	pages = {5--10},
	file = {nime2005_005_Bowers.Infra Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2005/nime2005_005_Bowers.Infra Instruments.pdf:application/pdf}
}

@inproceedings{jorda_digital_2004,
	address = {Hamamatsu, Japan},
	title = {Digital {Instruments} and {Players}: {Part} {I} – {Efficiency} and {Apprenticeship}},
	url = {http://www.nime.org/proceedings/2004/nime2004_059.pdf},
	abstract = {When envisaging new digital instruments, designers do not have to limit themselves to their sonic capabilities (which can be absolutely any), not even to their algorithmic power; they must be also especially careful about the instruments' conceptual capabilities, to the ways instruments impose or suggest to their players new ways of thinking, new ways of establishing relations, new ways of interacting, new ways of organizing time and textures; new ways, in short, of playing new musics. This article explores the dynamic relation that builds between the player and the instrument, introducing concepts such as efficiency, apprenticeship and learning curve It aims at constructing a framework in which the possibilities and the diversity of music instruments as well as the possibilities and the expressive freedom of human music performers could start being evaluated.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jordà, Sergi},
	year = {2004},
	keywords = {apprenticeship, learning curve, musical efficiency., Musical instruments design},
	pages = {59--63},
	file = {nime2004_059.Jorda.Digital Instruments and PlayersPt1.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2004/nime2004_059.Jorda.Digital Instruments and PlayersPt1.pdf:application/pdf}
}

@inproceedings{gadd_metamuse:_2002,
	address = {Dublin, Ireland},
	title = {{MetaMuse}: {Metaphors} for {Expressive} {Instruments}},
	url = {http://www.nime.org/proceedings/2002/nime2002_065.pdf},
	abstract = {We explore the role that metaphor plays in developing expressive devices by examining the MetaMuse system. MetaMuse is a prop-based system that uses the metaphor of rainfall to make the process of granular synthesis understandable. We discuss MetaMuse within a framework we call"transparency" that can be used as a predictor of the expressivity of musical devices. Metaphor depends on a literature,or cultural basis, which forms the basis for making transparent device mappings. In this context we evaluate the effect of metaphor in the MetaMuse system.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gadd, Ashley and Fels, Sidney S.},
	month = may,
	year = {2002},
	keywords = {metaphor, transparency, Expressive interface, granular synthesis., prop-based controller},
	pages = {65--70},
	file = {nime2002_065.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_065.Fels.MetaphorsForExpressiveInstruments.pdf:application/pdf}
}

@inproceedings{orio_input_2001,
	address = {Seattle, WA},
	title = {Input {Devices} for {Musical} {Expression} : {Borrowing} {Tools} from {HCI}},
	url = {http://www.nime.org/proceedings/2001/nime2001_015.pdf},
	abstract = {This paper reviews the existing literature on input device evaluation and design in human-computer interaction (HCI)and discusses possible applications of this knowledge to the design and evaluation of new interfaces for musical expression. Specifically, a set of musical tasks is suggested to allow the evaluation of different existing controllers.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Orio, Nicola and Schnell, Norbert and Wanderley, Marcelo M.},
	month = apr,
	year = {2001},
	keywords = {gestural control, interactive systems, Input device design},
	pages = {15--18},
	file = {ORIO SCHNELL WANDERLEY - Input Devices for Musical Expression.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_INSTRU/ORIO SCHNELL WANDERLEY - Input Devices for Musical Expression.pdf:application/pdf}
}

@inproceedings{wessel_problems_2001,
	address = {Seattle, WA},
	title = {Problems and {Prospects} for {Intimate} {Musical} {Control} of {Computers}},
	url = {http://www.nime.org/proceedings/2001/nime2001_011.pdf},
	abstract = {In this paper we describe our efforts towards the development of live performance computer-based musical instrumentation. Our design criteria include initial ease of use coupled with a long term potential for virtuosity,minimal and low variance latency, and clear and simple strategies for programming the relationship between gesture and musical result. We present custom controllers and unique adaptations of standard gestural interfaces, a programmable connectivity processor, a communications protocol called Open Sound Control(OSC), and a variety of metaphors for musical control. We further describe applications of our technology to a variety of real musical performances and directions for future research.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Wessel, David and Wright, Matthew},
	month = apr,
	year = {2001},
	keywords = {latency, musical, gestural controllers, signal processing, communications protocols, reactive computing},
	pages = {11--14},
	file = {nime2001_011_WesselWright_Problems and Prospects for Intimate Musical Control of Computers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/nime2001_011_WesselWright_Problems and Prospects for Intimate Musical Control of Computers.pdf:application/pdf}
}

@article{chion_musique_1977,
	title = {La musique du futur a-t-elle un avenir ?},
	volume = {4},
	language = {french},
	journal = {Cahiers recherche/musique},
	author = {Chion, Michel},
	year = {1977},
	file = {1977.Chion.la musique du futur.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Cahiers recherche\:musique/1977.Chion.la musique du futur.pdf:application/pdf}
}

@article{bonardi_preservation_2008,
	title = {The preservation, emulation, migration, and virtualization of live electronics for performing arts: {An} overview of musical and technical issues},
	volume = {1},
	issn = {15564673},
	shorttitle = {The preservation, emulation, migration, and virtualization of live electronics for performing arts},
	url = {http://portal.acm.org/citation.cfm?doid=1367080.1367086},
	doi = {10.1145/1367080.1367086},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Bonardi, Alain and Barthélemy, Jérome},
	month = jun,
	year = {2008},
	pages = {1--16},
	file = {2008.Bonardi.PreservationEmulationMigratoinVirtualizationOfLiveElectronics.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_ACM_Journal on computing and cultural heritage/2008.Bonardi.PreservationEmulationMigratoinVirtualizationOfLiveElectronics.pdf:application/pdf}
}

@book{slade_made_2006,
	address = {Cambridge, Mass},
	title = {Made to break: technology and obsolescence in {America}},
	isbn = {978-0-674-02203-4},
	shorttitle = {Made to break},
	language = {en},
	publisher = {Harvard University Press},
	author = {Slade, Giles},
	year = {2006},
	note = {OCLC: ocm62679850},
	keywords = {Product obsolescence, Technological innovations, United States},
	file = {Slade - 2006 - Made to break technology and obsolescence in Amer.pdf:/Users/vg/Zotero/storage/FVGTWKD8/Slade - 2006 - Made to break technology and obsolescence in Amer.pdf:application/pdf}
}

@article{bates_social_2012,
	title = {The {Social} {Life} of {Musical} {Instruments}},
	volume = {56},
	issn = {00141836},
	url = {https://www.jstor.org/stable/10.5406/ethnomusicology.56.3.0363},
	doi = {10.5406/ethnomusicology.56.3.0363},
	language = {en},
	number = {3},
	urldate = {2019-05-28},
	journal = {Ethnomusicology},
	author = {{Bates}},
	year = {2012},
	pages = {363},
	file = {ETM_56_3_Bates.Social_Life_of_Musical instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Ethnomusicology/ETM_56_3_Bates.Social_Life_of_Musical instruments.pdf:application/pdf}
}

@article{haine_les_2018,
	title = {Les classifications des instruments de musique en {France} de 1761 à 1819 et l’élaboration d’une terminologie organologique.},
	volume = {15},
	issn = {00351601},
	url = {https://www.jstor.org/stable/10.2307/20141602?origin=crossref},
	doi = {10.2307/20141602},
	language = {fr},
	number = {1},
	urldate = {2019-05-28},
	journal = {Musique-Images-Instruments. Revue française d'organologie et d'iconographie musicale},
	author = {Haine, Malou},
	year = {2018},
	pages = {230--245},
	file = {MII-15-Haine-Classifications.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue française d’organologie et d’iconographie musicale/MII-15-Haine-Classifications.pdf:application/pdf}
}

@article{ferguson_imagined_2013,
	title = {Imagined {Agency}: {Technology}, {Unpredictability}, and {Ambiguity}},
	volume = {32},
	issn = {0749-4467, 1477-2256},
	shorttitle = {Imagined {Agency}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07494467.2013.775810},
	doi = {10.1080/07494467.2013.775810},
	language = {en},
	number = {2-03},
	urldate = {2019-05-28},
	journal = {Contemporary Music Review},
	author = {Ferguson, John Robert},
	month = jun,
	year = {2013},
	pages = {135--149},
	file = {2013.CMR.FergusonImagined_Agency_Technology_Unpredictabily.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Contemporary Music Review/2013.CMR.FergusonImagined_Agency_Technology_Unpredictabily.pdf:application/pdf}
}

@article{magnusson_ergodynamics_2019,
	title = {Ergodynamics and a semiotics of instrumental composition},
	volume = {73},
	number = {287},
	journal = {Tempo},
	author = {Magnusson, Thor},
	year = {2019},
	pages = {41--51},
	file = {Magnusson_Tempo_v3.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Tempo/Magnusson_Tempo_v3.pdf:application/pdf}
}

@article{omodhrain_framework_2011,
	title = {A {Framework} for the {Evaluation} of {Digital} {Musical} {Instruments}},
	volume = {35},
	issn = {0148-9267, 1531-5169},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00038},
	doi = {10.1162/COMJ_a_00038},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Computer Music Journal},
	author = {O'Modhrain, Sile},
	month = mar,
	year = {2011},
	pages = {28--42},
	file = {2011.OModhrain.FrameworkForEvaluationOfDMI.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2011.OModhrain.FrameworkForEvaluationOfDMI.pdf:application/pdf;O'Modhrain - 2011 - A Framework for the Evaluation of Digital Musical .pdf:/Users/vg/Zotero/storage/DIL4R4ZJ/O'Modhrain - 2011 - A Framework for the Evaluation of Digital Musical .pdf:application/pdf}
}

@article{buxton_artists_1997,
	title = {Artists and the art of the luthier},
	volume = {31},
	number = {1},
	journal = {ACM SIGGRAPH Computer Graphics},
	author = {Buxton, Bill},
	year = {1997},
	pages = {10--11},
	file = {Full Text:/Users/vg/Zotero/storage/SPN6M678/luthier.html:text/html}
}

@inproceedings{chadabe_limitations_2002,
	address = {Dublin, Ireland},
	title = {The {Limitations} of {Mapping} as a {Structural} {Descriptive} in {Electronic} {Instruments}},
	url = {http://www.nime.org/proceedings/2002/nime2002_038.pdf},
	abstract = {Mapping, which describes the way a performer's controls are connected to sound variables, is a useful concept when applied to the structure of electronic instruments modelled after traditional acoustic instruments. But mapping is a less useful concept when applied to the structure of complex and interactive instruments in which algorithms generate control information. This paper relates the functioning and benefits of different types of electronic instruments to the structural principles on which they are based. Structural models of various instruments will be discussed and musical examples played.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Chadabe, Joel},
	month = may,
	year = {2002},
	keywords = {mapping fly-by-wire algorithmic network interactivity instrument deterministic indeterministic},
	pages = {38--42},
	file = {Chadabe_2002_The Limitations of Mapping as a Structural Descriptive in Electronic Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Chadabe_2002_The Limitations of Mapping as a Structural Descriptive in Electronic Instruments.pdf:application/pdf}
}

@inproceedings{schnell_introducing_2002,
	address = {Dublin, Ireland},
	title = {Introducing {Composed} {Instruments}, {Technical} and {Musicological} {Implications}},
	url = {http://www.nime.org/proceedings/2002/nime2002_156.pdf},
	abstract = {In this paper, we develop the concept of "composed instruments". We will look at this idea from two perspectives: the design of computer systems in the context of live performed music and musicological considerations. A historical context is developed. Examples will be drawn from recent compositions. Finally basic concepts from computer science will be examined for their relation ship to this concept.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Schnell, Norbert and Battier, Marc},
	month = may,
	year = {2002},
	keywords = {interaction, composed instrument, Theremin, Instruments, Martenot, MAX., musicology, streams},
	pages = {156--160},
	file = {nime2002_156_Schnell_Introducing  Composed  Instruments,  Technical  and  Musicological  Implications.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_156_Schnell_Introducing  Composed  Instruments,  Technical  and  Musicological  Implications.pdf:application/pdf}
}

@inproceedings{kvifte_towards_2006,
	address = {Paris, France},
	title = {Towards a {Coherent} {Terminology} and {Model} of {Instrument} {Description} and {Design}},
	url = {http://www.nime.org/proceedings/2006/nime2006_220.pdf},
	abstract = {This paper discusses the need for a framework for describing musical instruments and their design, and discusses some possible elements in such a framework. The framework is meant as an aid in the development of a coherent terminology for describing, comparing and discussing different musical instruments and musical instrument designs. Three different perspectives are presented; that of the listener, the performer, and the constructor, and various levels of descriptions are introduced.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Kvifte, Tellef and Jensenius, Alexander Refsum},
	year = {2006},
	keywords = {mapping, gestures, Musical instrument design, organology.},
	pages = {220--225},
	file = {nime2006_220_KvifteARJ_Towards a Coherent Terminology and Model of Instrument Description and Design.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_220_KvifteARJ_Towards a Coherent Terminology and Model of Instrument Description and Design.pdf:application/pdf}
}

@inproceedings{fraietta_open_2008,
	address = {Genoa, Italy},
	title = {Open {Sound} {Control} : {Constraints} and {Limitations}},
	url = {http://www.nime.org/proceedings/2008/nime2008_019.pdf},
	abstract = {Open Sound Control (OSC) is being used successfully as amessaging protocol among many computers, gesturalcontrollers and multimedia systems. Although OSC hasaddressed some of the shortcomings of MIDI, OSC cannotdeliver on its promises as a real-time communication protocolfor constrained embedded systems. This paper will examinesome of the advantages but also dispel some of the mythsconcerning OSC. The paper will also describe how some of thebest features of OSC can be used to develop a lightweightprotocol that is microcontroller friendly.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fraietta, Angelo},
	year = {2008},
	keywords = {open sound control, osc, a, nime08, data transmission protocols, gestural controllers, has been implemented as, midi},
	pages = {19--23}
}

@inproceedings{fyans_where_2009,
	address = {Pittsburgh, PA, United States},
	title = {Where {Did} {It} {All} {Go} {Wrong} ? {A} {Model} of {Error} {From} the {Spectator}'s {Perspective}},
	url = {http://www.nime.org/proceedings/2009/nime2009_171.pdf},
	abstract = {The development of new interfaces for musical expressionhas created a need to study how spectators comprehend newperformance technologies and practices. As part of a largerproject examining how interactions with technology can becommunicated with the spectator, we relate our model ofspectator understanding of error to the NIME discourse surrounding transparency, mapping, skill and success.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fyans, A. Cavan and Gurevich, Michael and Stapleton, Paul},
	year = {2009},
	keywords = {performance, skill, design, HCI, transparency},
	pages = {171--172},
	file = {nime2009_171.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_171.pdf:application/pdf}
}

@inproceedings{gurevich_designing_2009,
	address = {Pittsburgh, PA, United States},
	title = {Designing for {Style} in {New} {Musical} {Interactions}},
	url = {http://www.nime.org/proceedings/2009/nime2009_213.pdf},
	abstract = {In this paper we discuss the concept of style, focusing in particular on methods of designing new instruments that facilitate the cultivation and recognition of style. We distinguishbetween style and structure of an interaction and discuss thesignificance of this formulation within the context of NIME.Two workshops that were conducted to explore style in interaction design are described, from which we identify elements of style that can inform and influence the design process. From these, we suggest steps toward designing forstyle in new musical interactions.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gurevich, Michael and Stapleton, Paul and Bennett, Peter},
	year = {2009},
	keywords = {expression, skill, structure, style, virtuosity},
	pages = {213--217},
	file = {nime2009_213.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_213.pdf:application/pdf}
}

@inproceedings{gurevich_style_2010,
	address = {Sydney, Australia},
	title = {Style and {Constraint} in {Electronic} {Musical} {Instruments}},
	url = {http://www.nime.org/proceedings/2010/nime2010_106.pdf},
	abstract = {A qualitative study to investigate the development of stylein performance with a highly constrained musical instrument is described. A new one-button instrument was designed, with which several musicians were each asked topractice and develop a solo performance. Observations oftrends in attributes of these performances are detailed in relation to participants' statements in structured interviews.Participants were observed to develop stylistic variationsboth within the domain of activities suggested by the constraint, and by discovering non-obvious techniques througha variety of strategies. Data suggest that stylistic variationsoccurred in spite of perceived constraint, but also becauseof perceived constraint. Furthermore, participants tendedto draw on unique experiences, approaches and perspectivesthat shaped individual performances.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gurevich, Michael and Stapleton, Paul and Marquez-Borbon, Adnan},
	year = {2010},
	keywords = {interaction, performance, design, persuasive technology},
	pages = {106--111}
}

@inproceedings{lee_real-time_2012,
	address = {Ann Arbor, Michigan},
	title = {Real-{Time} {Music} {Notation}, {Collaborative} {Improvisation}, and {Laptop} {Ensembles}},
	url = {http://www.nime.org/proceedings/2012/nime2012_62.pdf},
	abstract = {This paper describes recent extensions to LOLC, a text-based environment for collaborative improvisation for laptop ensembles, which integrate acoustic instrumental musicians into the environment. Laptop musicians author short commands to create, transform, and share pre-composed musical fragments, and the resulting notation is digitally displayed, in real time, to instrumental musicians to sight-read in performance. The paper describes the background and motivations of the project, outlines the design of the original LOLC environment and describes its new real-time notation components in detail, and explains the use of these new components in a musical composition, SGLC, by one of the authors.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Lee, Sang Won and Freeman, Jason and Collela, Andrew},
	year = {2012},
	file = {nime2012_62_Freeman Real-Time Music Notation Collaborative Improvisation and Laptop Ensembles.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_62_Freeman Real-Time Music Notation Collaborative Improvisation and Laptop Ensembles.pdf:application/pdf}
}

@inproceedings{schwarz_sound_2012,
	address = {Ann Arbor, Michigan},
	title = {The {Sound} {Space} as {Musical} {Instrument}: {Playing} {Corpus}-{Based} {Concatenative} {Synthesis}},
	url = {http://www.nime.org/proceedings/2012/nime2012_120.pdf},
	abstract = {Corpus-based concatenative synthesis is a fairly recent sound synthesis method, based on descriptor analysis of any number of existing or live-recorded sounds, and synthesis by selection of sound segments from the database matching given sound characteristics. It is well described in the literature, but has been rarely examined for its capacity as a new interface for musical expression. The interesting outcome of such an examination is that the actual instrument is the space of sound characteristics, through which the performer navigates with gestures captured by various input devices. We will take a look at different types of interaction modes and controllers (positional, inertial, audio analysis) and the gestures they afford, and provide a critical assessment of their musical and expressive capabilities, based on several years of musical experience, performing with the CataRT system for real-time CBCS.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Schwarz, Diemo},
	year = {2012},
	keywords = {gesture, CataRT, corpus-based concatenative synthesis},
	file = {nime2012_120.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_120.pdf:application/pdf}
}

@inproceedings{collins_semiconducting_2013,
	title = {Semiconducting – {Making} {Music} {After} the {Transistor}},
	abstract = {Why does ‘Computer Music’ sound different from ‘Electronic Music’? The author examines several traits that distinguish hardware from software in terms of their application in music composition and performance. He discusses the often subtle influence of these differences on various aspects of the creative process, and presents a number of inferences as to the ‘intrinsic’ suitability of hardware and software for different musical tasks. His observations are based on several decades of experience as a composer and performer, and in close engagement with the music of his mentors and peers.},
	author = {Collins, Nicolas},
	year = {2013},
	file = {Collins_semiconducting.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Collins, Nicolas/Collins_semiconducting.pdf:application/pdf}
}

@inproceedings{mays_notation_2014,
	address = {London, United Kingdom},
	title = {A {Notation} {System} for the {Karlax} {Controller}},
	url = {http://www.nime.org/proceedings/2014/nime2014_509.pdf},
	abstract = {In this paper we expose the need to go beyond the composer/performer model of electronic instrument design and programming to encourage the transmission of compositions and the creation of a repertory via notation of repeatable performance practice. Drawing on 4 years of practice using the Karlax controller (Da Fact) as a base for new digital musical instruments, we present our notation system in detail and cite some mapping strategies and examples from to pieces in a growing repertory of chamber music compositions for electronic and acoustic instruments},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Mays, Tom and Faber, Francis},
	month = jun,
	year = {2014},
	pages = {553--556},
	file = {nime2014_509_Mays_Notation system for the Karlax.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_509_Mays_Notation system for the Karlax.pdf:application/pdf}
}

@inproceedings{tubb_divergent_2014,
	address = {London, United Kingdom},
	title = {The {Divergent} {Interface}: {Supporting} {Creative} {Exploration} of {Parameter} {Spaces}},
	url = {http://www.nime.org/proceedings/2014/nime2014_415.pdf},
	abstract = {This paper outlines a theoretical framework for creative technology based on two contrasting processes: divergent exploration and convergent optimisation. We claim that these two cases require different gesture-to-parameter mapping properties. Results are presented from a user experiment that motivates this theory. The experiment was conducted using a publicly available iPad app: “Sonic Zoom”. Participants were encouraged to conduct an open ended exploration of synthesis timbre using a combination of two different interfaces. The first was a standard interface with ten sliders, hypothesised to be suited to the “convergent” stage of creation. The second was a mapping of the entire 10-D combinatorial space to a 2-D surface using a space filling curve. This novel interface was intended to support the “divergent” aspect of creativity. The paths of around 250 users through both 2-D and 10-D space were logged and analysed. Both the interaction data and questionnaire results show that the different interfaces tended to be used for different aspects of sound creation, and a combination of these two navigation styles was deemed to be more useful than either individually. The study indicates that the predictable, separate parameters found in most music technology are more appropriate for convergent tasks.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Tubb, Robert and Dixon, Simon},
	month = jun,
	year = {2014},
	pages = {227--232},
	file = {nime2014_415.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_415.pdf:application/pdf}
}

@inproceedings{marley_gestroviser:_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Gestroviser: {Toward} {Collaborative} {Agency} in {Digital} {Musical} {Instruments}.},
	url = {http://www.nime.org/proceedings/2015/nime2015_287.pdf},
	abstract = {This paper describes a software extension to the Reactable entitled Gestroviser that was developed to explore musician machine collaboration at the control signal level. The system functions by sampling a performers input, processing or reshaping this sampled input, and then repeatedly replaying it. The degree to which the sampled control signal is processed during replay is adjustable in real-time by the manipulation of a continuous finger slider function. The reshaping algorithm uses stochastic methods commonly used for MIDI note generation from a provided dataset. The reshaped signal therefore varies in an unpredictable manner. In this way the Gestroviser is a device to capture, reshape and replay an instrumental gesture. We describe the result of initial user testing of the system and discuss possible further development.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Marley, William and Ward, Nicholas},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {140--143},
	file = {Marley and Ward - 2015 - Gestroviser Toward Collaborative Agency in Digita.pdf:/Users/vg/Zotero/storage/LWU259U8/Marley and Ward - 2015 - Gestroviser Toward Collaborative Agency in Digita.pdf:application/pdf}
}

@inproceedings{gurevich_discovering_2017,
	address = {Copenhagen, Denmark},
	title = {Discovering {Instruments} in {Scores}: {A} {Repertoire}-{Driven} {Approach} to {Designing} {New} {Interfaces} for {Musical} {Expression}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0031.pdf},
	abstract = {This paper situates NIME practice with respect to models of social interaction among human agents. It argues that the conventional model of composer-performer-listener, and the underlying mid-20th century metaphor of music as communication upon which it relies, cannot reflect the richness of interaction and possibility afforded by interactive digital technologies. Building on Paul Lansky's vision of an expanded and dynamic social network, an alternative, ecological view of music-making is presented, in which meaning emerges not from "messages" communicated between individuals, but instead from the "noise" that arises through the uncertainty in their interactions. However, in our tendency in NIME to collapse the various roles in this network into a single individual, we place the increased potential afforded by digital systems at risk. Using examples from the author's NIME practices, the paper uses a practice-based methodology to describe approaches to designing instruments that respond to the technologies that form the interfaces of the network, which can include scores and stylistic conventions. In doing so, the paper demonstrates that a repertoire\&\#8212;a seemingly anachronistic concept\&\#8212;and a corresponding repertoire-driven approach to creating NIMEs can in fact be a catalyst for invention and creativity.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Gurevich, Michael},
	year = {2017},
	pages = {163--168},
	file = {Gurevich - 2017 - Discovering Instruments in Scores A Repertoire-Dr.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/Gurevich - 2017 - Discovering Instruments in Scores A Repertoire-Dr.pdf:application/pdf}
}

@book{seve_instrument_2013,
	edition = {Le Seuil},
	series = {L'{Ordre} philosophique},
	title = {L'instrument de musique: une étude philosophique},
	language = {french},
	publisher = {Le Seuil},
	author = {Sève, Bernard},
	month = mar,
	year = {2013}
}

@article{ostertag_why_1998,
	title = {Why computer music sucks},
	volume = {5},
	journal = {Resonance},
	author = {Ostertag, Bob},
	year = {1998},
	pages = {4--5}
}

@incollection{beaudouin-lafon_moins_1999,
	edition = {Hermes Science Publications},
	title = {Moins d'interface pour plus d'interaction},
	booktitle = {Interfaces homme-machine et création musicale},
	author = {Beaudouin-Lafon, Michel},
	year = {1999},
	pages = {123--141}
}

@inproceedings{vertegaal_towards_1996,
	title = {Towards a musician's cockpit: {Transducers}, feedback and musical function},
	volume = {96},
	booktitle = {{ICMC}},
	author = {Vertegaal, Roel and Ungvary, Tamas and Kieslinger, Michael},
	year = {1996},
	pages = {308--311}
}

@book{godoy_musical_2010,
	title = {Musical gestures: {Sound}, movement, and meaning},
	publisher = {Routledge},
	author = {Godøy, Rolf Inge and Leman, Marc},
	year = {2010}
}

@inproceedings{di_scipio_towards_1997,
	title = {Towards a critical theory of (music) technology},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Di Scipio, Agostino},
	year = {1997},
	pages = {62--65},
	file = {1997.ICMC.DiScipio.Towards a critical theory of (music) technology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1997/1997.ICMC.DiScipio.Towards a critical theory of (music) technology.pdf:application/pdf}
}

@incollection{jensenius_musical_2010,
	title = {Musical gestures. {Concepts} and methods in research},
	language = {en},
	booktitle = {Musical {Gestures}. {Sound}, movement, and meaning},
	publisher = {Routledge},
	author = {Jensenius, Alexander R and Wanderley, Marcelo M. and Godøy, Rolf Inge and Leman, Marc},
	year = {2010},
	pages = {13--35},
	file = {Jensenius_2010e.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Godoy\; Rolf Inge/MusicalGestures.Jensenius.pdf:application/pdf}
}

@incollection{risset_evolution_1999,
	title = {Evolution des outils de création sonore in {Interfaces} homme-machine et création musicale},
	booktitle = {Interfaces homme-machine et création musicale},
	publisher = {Hermès},
	author = {Risset, Jean-Claude},
	year = {1999}
}

@article{tresch_toward_2013,
	title = {Toward a new organology: instruments of music and science},
	volume = {28},
	number = {1},
	journal = {Osiris},
	author = {Tresch, John and Dolan, Emily I},
	year = {2013},
	pages = {278--298},
	file = {2013.Tresch-Dolan.Toward a New Organology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OSIRIS/2013.Tresch-Dolan.Toward a New Organology.pdf:application/pdf}
}

@article{moody_physics_2009,
	title = {The “physics” of notations: toward a scientific basis for constructing visual notations in software engineering},
	volume = {35},
	number = {6},
	journal = {IEEE Transactions on software engineering},
	author = {Moody, Daniel},
	year = {2009},
	pages = {756--779},
	file = {physics_of_notations.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_IEEE/physics_of_notations.pdf:application/pdf}
}

@book{tufte_visual_2001,
	title = {The visual display of quantitative information},
	volume = {2},
	publisher = {Graphics press Cheshire, CT},
	author = {Tufte, Edward R},
	year = {2001},
	file = {Tufte_2001_The visual display of quantitative information.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Tufte_2001_The visual display of quantitative information.pdf:application/pdf}
}

@article{pinch_why_2001,
	title = {Why you go to a music store to buy a synthesizer: path dependence and the social construction of technology},
	journal = {Path dependence and creation},
	author = {Pinch, Trevor J},
	year = {2001},
	pages = {381--400}
}

@article{gurevich_digital_2011,
	title = {Digital {Musical} {Interactions}: {Performer}–system relationships and their perception by spectators},
	volume = {16},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Digital {Musical} {Interactions}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771811000112/type/journal_article},
	doi = {10.1017/S1355771811000112},
	language = {en},
	number = {2},
	urldate = {2019-06-17},
	journal = {Organised Sound},
	author = {Gurevich, Michael and Cavan Fyans, A.},
	month = aug,
	year = {2011},
	pages = {166--175},
	file = {Organised Sound - Digital Musical Interactions Performer_system relationshi.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2011/Organised Sound - Digital Musical Interactions Performer_system relationshi.pdf:application/pdf}
}

@article{stuart_object_2003,
	title = {The object of performance: {Aural} performativity in contemporary laptop music},
	volume = {22},
	number = {4},
	journal = {Contemporary Music Review},
	author = {Stuart, Caleb},
	year = {2003},
	pages = {59--65},
	file = {Stuart_2003_The object of performance.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Stuart_2003_The object of performance.pdf:application/pdf}
}

@article{cadoz_geste_1994,
	title = {Le geste canal de communication homme/machine: la communication" instrumentale"},
	volume = {13},
	number = {1},
	journal = {Technique et science informatiques},
	author = {Cadoz, Claude},
	year = {1994},
	pages = {31--61},
	file = {CADOZ_LeGestreCanalDeCommunicationHommeMachine.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/CADOZ_LeGestreCanalDeCommunicationHommeMachine.pdf:application/pdf}
}

@book{stravinsky_igor_1936,
	title = {Igor {Stravinsky}. {An} {Autobiography}.},
	publisher = {Simon And Schuster, Inc.},
	author = {Stravinsky, Igor},
	year = {1936}
}

@incollection{bhagwati_notational_2013,
	title = {Notational perspective and comprovisation},
	booktitle = {Sound \& {Score}. {Essays} on {Sound}, {Score} and {Notation}},
	author = {Bhagwati, Sandeep},
	year = {2013},
	pages = {165--177}
}

@book{bayle_musique_1993,
	title = {Musique acousmatique: propositions... positions},
	publisher = {INA-GRM, Buchet-Chastel},
	author = {Bayle, François},
	year = {1993}
}

@incollection{couprie_eanalysis:_2016,
	title = {{EAnalysis}: developing a sound-based music analytical tool},
	booktitle = {Expanding the {Horizon} of {Electroacoustic} {Music} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Couprie, Pierre},
	year = {2016},
	pages = {170--194}
}

@inproceedings{fober_environment_2012,
	title = {An environment for the design of live music scores},
	booktitle = {Proceedings of the {Linux} {Audio} {Conference}, {CCRMA}, {Stanford} {University}, {California}, {US}},
	author = {Fober, Dominique and Orlarey, Yann and Letz, Stephane},
	year = {2012},
	pages = {47--54}
}

@inproceedings{favreau_lacousmographe_2010,
	title = {L’acousmographe 3},
	booktitle = {Journées d’{Informatique} {Musicale} ({JIM} 2010)},
	author = {Favreau, Emmanuel and Geslin, Yann and Lefèvre, Adrien},
	year = {2010}
}

@inproceedings{goudard_mapping_2017,
	title = {Mapping modulaire de processus polyphoniques},
	booktitle = {Actes des {Journées} d'{Informatique} {Musicale} ({JIM}’17)},
	author = {Goudard, Vincent and Genevois, Hugues},
	year = {2017}
}

@inproceedings{hope_screen_2011,
	address = {Huddersfield, UK},
	title = {Screen {Scores}: {New} {Media} {Music} {Manuscripts}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Computing}},
	author = {Hope, Cat and Vickery, Lindsay},
	year = {2011},
	file = {2011.Hope-Vickery_Screen Scores_ New Media Music Manuscripts.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/2011/2011.Hope-Vickery_Screen Scores_ New Media Music Manuscripts.pdf:application/pdf}
}

@inproceedings{hope_decibel_2015,
	address = {Paris, France},
	title = {The decibel scoreplayer-a digital tool for reading graphic notation},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Hope, Cat and Vickery, Lindsay and Wyatt, Aaron and James, Stuart},
	year = {2015},
	file = {2015_VickeryHope-DecibelScorePlayer.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2015/2015_VickeryHope-DecibelScorePlayer.pdf:application/pdf}
}

@inproceedings{maestri_notation_2016,
	address = {Cambridge, U.K.},
	title = {Notation as {Temporal} {Instrument}},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Maestri, Eric},
	year = {2016},
	file = {Maestri_NotationAsTemporalInstrument.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/2016/Maestri_NotationAsTemporalInstrument.pdf:application/pdf}
}

@article{magnusson_algorithms_2011,
	title = {Algorithms as scores: {Coding} live music},
	journal = {Leonardo Music Journal},
	author = {Magnusson, Thor},
	year = {2011},
	pages = {19--23},
	file = {Magnusson_Leonardo11_Algorithms as Scores_Coding Live Music.pdf:/Users/vg/Documents/_PERSO/THESE/BIBLIO/_AUTEURS/Magnusson, Thor/Magnusson_Leonardo11_Algorithms as Scores_Coding Live Music.pdf:application/pdf}
}

@article{delalande_les_1996,
	title = {Les {Unités} {Sémiotiques} {Temporelles}-Éléments nouveaux d’analyse musicale},
	journal = {Marseille: Edition MIM},
	author = {Delalande, François and Formosa, M and Frémiot, M and Gobin, P and Malbosc, P and Mandelbrojt, J and Pedler, E},
	year = {1996}
}

@book{schaeffer_traite_1966,
	series = {Pierres vives},
	title = {Traité des objets musicaux},
	publisher = {Le Seuil},
	author = {Schaeffer, Pierre},
	year = {1966}
}

@inproceedings{smith_atomic_2015,
	title = {An atomic approach to animated music notation},
	booktitle = {Proc. {Int}. {Conf}. {On} {New} {Tools} for {Music} {Notation} and {Representation}},
	author = {Smith, Ryan Ross},
	year = {2015}
}

@phdthesis{chapiro_globally-asynchronous_1984,
	title = {Globally-{Asynchronous} {Locally}-{Synchronous} {Systems}.},
	school = {Stanford Univ CA Dept of Computer Science},
	author = {Chapiro, Daniel M.},
	year = {1984},
	file = {Chapiro_1984_Globally-Asynchronous Locally-Synchronous Systems.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Chapiro_1984_Globally-Asynchronous Locally-Synchronous Systems.pdf:application/pdf}
}

@inproceedings{freed_dynamic_2011,
	title = {Dynamic, {Instance}-based, object-oriented programming in {Max}/{MSP} using open sound control message delegation.},
	booktitle = {{ICMC}},
	author = {Freed, Adrian and MacCallum, John and Schmeder, Andrew},
	year = {2011}
}

@inproceedings{goudard_dynamic_2011,
	title = {Dynamic {Intermediate} {Models} for audiographic synthesis},
	booktitle = {8th {Sound} and {Music} {Computing} {Conference}},
	publisher = {Padova University Press},
	author = {Goudard, Vincent and Genevois, Hugues and Ghomi, Emilien and Doval, Boris},
	year = {2011},
	pages = {486}
}

@inproceedings{kaltenbrunner_tuio:_2005,
	title = {{TUIO}: {A} protocol for table-top tangible user interfaces},
	booktitle = {Proc. of the {The} 6th {Int}’l {Workshop} on {Gesture} in {Human}-{Computer} {Interaction} and {Simulation}},
	author = {Kaltenbrunner, Martin and Bovermann, Till and Bencina, Ross and Costanza, Enrico and {others}},
	year = {2005},
	pages = {1--5}
}

@article{mcmillen_zipi_1994,
	title = {The {ZIPI} music parameter description language},
	volume = {18},
	number = {4},
	journal = {Computer Music Journal},
	author = {McMillen, Keith and Wessel, David L and Wright, Matthew},
	year = {1994},
	pages = {52--73}
}

@article{association_complete_1996,
	title = {The complete {MIDI} 1.0 detailed specification},
	journal = {Los Angeles, CA, The MIDI Manufacturers Association},
	author = {Association, MIDI Manufacturers and {others}},
	year = {1996}
}

@article{moore_dysfunctions_1988,
	title = {The dysfunctions of {MIDI}},
	volume = {12},
	number = {1},
	journal = {Computer music journal},
	author = {Moore, F Richard},
	year = {1988},
	pages = {19--28}
}

@inproceedings{rovan_instrumental_1997,
	title = {Instrumental gestural mapping strategies as expressivity determinants in computer music performance},
	booktitle = {Kansei, {The} {Technology} of {Emotion}. {Proceedings} of the {AIMI} {International} {Workshop}},
	publisher = {Citeseer},
	author = {Rovan, Joseph Butch and Wanderley, Marcelo M and Dubnov, Shlomo and Depalle, Philippe},
	year = {1997},
	pages = {68--73},
	file = {ROVAN WANDERLEY - Instrumental gestural mapping strategies as expressivity determinants.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/ROVAN WANDERLEY - Instrumental gestural mapping strategies as expressivity determinants.pdf:application/pdf}
}

@book{selfridge-field_beyond_1997,
	title = {Beyond {MIDI}: {The} {Handbook} of {Musical} {Codes}},
	publisher = {The MIT Press},
	author = {Selfridge-Field, Eleanor},
	year = {1997}
}

@book{bovermann_musical_2017,
	title = {Musical {Instruments} in the 21st {Century}},
	isbn = {978-981-10-2950-9},
	publisher = {Springer},
	author = {Bovermann, Till and de Campo, Alberto and Egermann, Hauke and Hardjowirogo, Sarah-Indriyati and Weinzierl, Stefan},
	year = {2017},
	file = {Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Bovermann, Till/Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:application/pdf}
}

@inproceedings{wright_open_1997,
	title = {Open {SoundControl}: {A} {New} {Protocol} for {Communicating} with {Sound} {Synthesizers}},
	booktitle = {{ICMC}},
	author = {Wright, Matthew and Freed, Adrian and {others}},
	year = {1997}
}

@inproceedings{kiefer_live_2019,
	address = {Media Lab, Madrid, Espagne},
	title = {Live coding machine learning and machine listening: a survey on the design of languages and environments for live coding.},
	booktitle = {Proceedings of the {International} {Conference} on {Live} {Coding}},
	author = {Kiefer, Chris and Magnusson, Thor},
	month = jan,
	year = {2019}
}

@inproceedings{baguyos_contemporary_2014,
	address = {Athènes, Grèce},
	title = {Contemporary {Practices} in the {Performance} and {Sustainability} of {Computer} {Music} {Repertoire}.},
	url = {http://dblp.uni-trier.de/db/conf/icmc/icmc2014.html#Baguyos14},
	booktitle = {{ICMC}},
	publisher = {Michigan Publishing},
	author = {Baguyos, Jeremy C.},
	year = {2014},
	keywords = {dblp}
}

@book{buci-glucksmann_esthetique_2003,
	address = {Paris},
	title = {Esthétique de l'éphémère},
	isbn = {978-2-7186-0622-4},
	language = {fr},
	publisher = {Galilée},
	author = {Buci-Glucksmann, Christine},
	year = {2003}
}

@article{couprie_meta-instrument:_2018,
	title = {Le {Méta}-{Instrument}: genèse et évolution d’un nouvel instrument.},
	volume = {17},
	journal = {COUPRIE, Pierre. Le Méta-Instrument: genèse et évolution d’un nouvel instrument. Musique-Images-Instruments. Revue française d'organologie et d'iconographie musicale,},
	author = {Couprie, Pierre},
	year = {2018},
	pages = {230--245}
}

@book{derrida_lecriture_2014,
	address = {Paris},
	title = {L'écriture et la différence},
	isbn = {978-2-7578-4171-6},
	publisher = {Éd. Points},
	author = {Derrida, Jacques},
	year = {2014}
}

@book{deleuze_mille_1980,
	address = {Paris},
	title = {Mille plateaux},
	isbn = {978-2-7073-0307-3},
	publisher = {Éditions de minuit},
	author = {Deleuze, Gilles},
	year = {1980}
}

@article{dudas_comprovisation:_2010,
	title = {"{Comprovisation}": {The} various facets of composed improvisation within interactive performance systems},
	volume = {20},
	abstract = {This article discusses the balance between composition and improvisation with respect to interactive performance using electronic and computer-based music systems. The author uses his own experience in this domain in the roles of both collaborator and composer as a point of reference to look at general trends in "composed improvisation" within the electronic and computer music community. Specifically, the intention is to uncover the limits and limitations of improvisation and its relationship to both composition and "composed instruments" within the world of interactive electronic musical performance. [ABSTRACT FROM AUTHOR] Copyright of Leonardo Music Journal is the property of MIT Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
	journal = {Leonardo Music Journal},
	author = {Dudas, Richard},
	year = {2010},
	doi = {10.1162/LMJ_a_00009},
	pages = {29--31}
}

@inproceedings{goudard_john_2018,
	address = {Montreal, Canada},
	title = {John, the {Semi}-{Conductor}: {A} {Tool} for {Comprovisation}},
	isbn = {978-1-5251-0551-7},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation} – {TENOR}'18},
	publisher = {Concordia University},
	author = {Goudard, Vincent},
	editor = {Bhagwati, Sandeep and Bresson, Jean},
	year = {2018},
	pages = {43--49}
}

@article{hadjeres_deepbach:_2016,
	title = {{DeepBach}: a {Steerable} {Model} for {Bach} chorales generation},
	volume = {abs/1612.01010},
	url = {http://arxiv.org/abs/1612.01010},
	journal = {CoRR},
	author = {Hadjeres, Gaëtan and Pachet, François},
	year = {2016}
}

@book{hugill_digital_2019,
	address = {New York London},
	title = {The digital musician},
	isbn = {978-1-138-56962-1},
	publisher = {Routledge},
	author = {Hugill, Andrew},
	year = {2019}
}

@article{magnusson_epistemic_2009,
	title = {Of {Epistemic} {Tools}: musical instruments as cognitive extensions},
	volume = {14},
	doi = {10.1017/S1355771809000272},
	number = {2},
	journal = {Organised Sound},
	author = {Magnusson, Thor},
	year = {2009},
	pages = {168--176}
}

@book{duchamp_notes_2008,
	address = {Paris},
	title = {Notes},
	isbn = {978-2-08-121741-6},
	publisher = {Flammarion},
	author = {Duchamp, Marcel},
	year = {2008}
}

@book{savouret_introduction_2010,
	address = {Lyon},
	title = {Introduction à un solfège de l'audible : l'improvisation libre comme outil pratique},
	isbn = {978-2-914373-73-9},
	publisher = {Symétrie},
	author = {Savouret, Alain},
	year = {2010}
}

@misc{sebestik_ecoute_1992,
	type = {Documentaire},
	title = {Écoute},
	publisher = {Arte Editions},
	author = {Sebestik, Miroslav},
	year = {1992}
}

@book{stiegler_for_2010,
	address = {Cambridge Malden, MA},
	title = {For a new critique of political economy},
	isbn = {978-0-7456-4803-3},
	publisher = {Polity},
	author = {Stiegler, Bernard},
	year = {2010}
}

@article{torre_hands:_2016,
	title = {The {Hands}: {The} {Making} of a {Digital} {Musical} {Instrument}},
	volume = {40},
	url = {https://doi.org/10.1162/COMJ_a_00356},
	doi = {10.1162/COMJ_a_00356},
	abstract = {Michel Waisvisz's The Hands is one of the most famous and long-lasting research projects in the literature of digital music instruments. Consisting of a pair of data gloves and exhibited for the first time in 1984, The Hands is a pioneering work in digital devices for performing live music. It is a work that engaged Waisvisz for almost a quarter of a century and, in turn, has inspired many generations of music technologists and performers of live music. Despite being often cited in the relevant literature, however, the documentation concerning the sensor architecture, design, mapping strategies, and development of these data gloves is sparse. In this article, we aim to fill this gap by offering a detailed history behind the development of The Hands. The information contained in this article was retrieved and collated by searching the STEIM archive, interviewing close collaborators of Waisvisz, and browsing through the paper documentation found in his personal folders and office.},
	number = {2},
	journal = {Computer Music Journal},
	author = {Torre, Giuseppe and Andersen, Kristina and Baldé, Frank},
	year = {2016},
	pages = {22--34}
}

@article{wessel_timbre_1979,
	title = {Timbre {Space} as a {Musical} {Control} {Structure}},
	volume = {3},
	issn = {01489267},
	url = {https://www.jstor.org/stable/3680283?origin=crossref},
	doi = {10.2307/3680283},
	language = {en},
	number = {2},
	urldate = {2019-06-25},
	journal = {Computer Music Journal},
	author = {Wessel, David L.},
	month = jun,
	year = {1979},
	pages = {45},
	file = {Wessel - 1979 - Timbre Space as a Musical Control Structure.pdf:/Users/vg/Zotero/storage/MGNJUAC5/Wessel - 1979 - Timbre Space as a Musical Control Structure.pdf:application/pdf}
}

@inproceedings{risset_sound_2014,
	address = {Athènes, Grèce},
	title = {Sound and {Music} {Computing} {Meets} {Philosophy} (keynote)},
	booktitle = {Proceedings {ICMC}{\textbar}{SMC}{\textbar}2014},
	publisher = {A. Georgaki and G. Kouroupetroglou (Eds.)},
	author = {Risset, Jean-Claude},
	year = {2014}
}

@article{collins_why_2008,
	title = {Why {Live}?: {Performance} in the {Age} of {Digital} {Reproduction}},
	volume = {18},
	journal = {Leonardo Music Journal},
	author = {Collins, Nicolas},
	month = jan,
	year = {2008},
	pages = {7--8}
}

@inproceedings{bascou_gmu_2005,
	title = {Gmu, a flexible granular synthesis environment in max/msp},
	booktitle = {Proceedings of the {Sound} and {Music} {Computing} {Conference} ({SMC}’05), {Salerno}, {Italy}},
	author = {Bascou, Charles and Pottier, Laurent},
	year = {2005}
}

@article{gabor_acoustical_1947,
	title = {Acoustical {Quanta} and the {Theory} of {Hearing}},
	volume = {159},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/159591a0},
	doi = {10.1038/159591a0},
	abstract = {IN popular expositions of wave mechanics, acoustical illustrations have been used by several authors, with particular success by Lande1. In a recent paper on the “Theory of Communication”2 I have taken the opposite course. Acoustical phenomena are discussed by mathematical methods closely related to those of quantum theory. While in physical acoustics a new formal approach to old problems cannot be expected to reveal much that is not already known, the position in subjective acoustics is rather different. In fact, the new methods have already proved their heuristic value, and can be expected to throw more light on the theory of hearing. In my original paper the point of view was mainly that of communication engineering ; in the following survey I have emphasized those features which may be of interest to physicists and to physiologists.},
	number = {4044},
	journal = {Nature},
	author = {GABOR, D.},
	month = may,
	year = {1947},
	pages = {591--594},
	file = {GaborTheoryQuanta.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Nature/GaborTheoryQuanta.pdf:application/pdf}
}

@book{leppert_sight_1993,
	title = {The sight of sound: {Music}, representation, and the history of the body},
	publisher = {Univ of California Press},
	author = {Leppert, Richard},
	year = {1993}
}

@article{risset_son_1992,
	title = {Le son numérique: une acoustique affranchie de la mécanique?},
	volume = {2},
	number = {C1},
	journal = {Le Journal de Physique IV},
	author = {Risset, J},
	year = {1992},
	pages = {C1--3},
	file = {Risset_Son numérique affranchi de la mécanique?.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Journal de Physique/Risset_Son numérique affranchi de la mécanique?.pdf:application/pdf}
}

@book{cage_silence:_1961,
	title = {Silence: {Lectures} and {Writings}},
	publisher = {Wesleyan University Press},
	author = {Cage, John},
	year = {1961}
}

@book{small_musicking:_1998,
	title = {Musicking: {The} meanings of performing and listening},
	publisher = {Wesleyan University Press},
	author = {Small, Christopher},
	year = {1998}
}

@inproceedings{risset_propos_2010,
	title = {A propos d'interdisciplinarité-informatique musicale: synthèse, traitement, perception; musicologie et {STIC}; oeuvre musicale et mixité},
	booktitle = {Journées d'{Informatique} {Musicale}},
	author = {Risset, Jean-Claude},
	year = {2010}
}

@book{magnusson_sonic_2019,
	title = {Sonic writing: technologies of material, symbolic, and signal inscriptions},
	publisher = {Bloomsbury Academic},
	author = {Magnusson, Thor},
	year = {2019}
}

@book{cage_radio_2015,
	address = {Paris},
	title = {Radio happenings : enregistrés à {Wbai}, {New} {York}, juillet 1966-janvier 1967},
	isbn = {979-10-304-0041-0},
	publisher = {Éditions Allia},
	author = {Cage, John},
	year = {2015}
}

@book{berliner_thinking_2009,
	title = {Thinking in jazz: {The} infinite art of improvisation},
	publisher = {University of Chicago Press},
	author = {Berliner, Paul F},
	year = {2009}
}

@article{delalande_geste_1988,
	title = {Le {Geste}, outil d'analyse: quelques enseignements d'une recherche sur la gestique de {Glenn} {Gould}},
	volume = {10},
	journal = {Analyse musicale},
	author = {Delalande, François},
	year = {1988},
	pages = {43--46}
}

@incollection{wanderley_controgestuel_1999,
	address = {Paris},
	title = {Contrôle gestuel de la synthèse sonore},
	language = {fr},
	booktitle = {Interfaces homme-machine et création musicale},
	publisher = {HERMES Science Publications},
	author = {Wanderley, Marcelo M and Depalle, Philippe},
	year = {1999},
	keywords = {Mapping, Contrôle gestuel de la synthèse sonore, Gestes, Interaction homme-machine, Nouveaux instruments},
	pages = {145--163},
	annote = {cote interne IRCAM: Wanderley99c},
	file = {Wanderley-Depalle_ControleGestuelDeLaSyntheseSonore.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Vinet, Hugues/Wanderley-Depalle_ControleGestuelDeLaSyntheseSonore.pdf:application/pdf}
}

@incollection{cadoz_gesture_2000,
	title = {Gesture - {Music}},
	url = {https://hal.archives-ouvertes.fr/hal-01105543},
	booktitle = {Trends in {Gestural} {Control} of {Music}},
	author = {Cadoz, Claude and Wanderley, Marcelo M.},
	editor = {Marcelo Wanderley et Marc Battier, Ircam-Centre Pompidou},
	month = mar,
	year = {2000},
	keywords = {gesture, Gesture typologies, Instrumental gesture},
	annote = {cote interne IRCAM: Cadoz00a},
	file = {00.cadoz_wanderley_gesture_music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Wanderley, Marcello/00.cadoz_wanderley_gesture_music.pdf:application/pdf}
}

@phdthesis{gibet_codage_1987,
	type = {{PhD} {Thesis}},
	title = {Codage, représentation et traitement du geste instrumental. {Application} à la synthèse de sons musicaux par simulation de mécanismes instrumentaux},
	author = {Gibet, Sylvie},
	year = {1987}
}

@inproceedings{godoy_exploring_2006,
	address = {Leeds, UK.},
	title = {Exploring music-related gestures by sound-tracing: {A} preliminary study},
	booktitle = {Proceedings of the {COST}287-{ConGAS} 2nd {International} {Symposium} on {Gesture} {Interfaces} for {Multimedia} {Systems}},
	author = {Godøy, Rolf Inge and Haga, Egil and Jensenius, Alexander Refsum},
	year = {2006},
	pages = {27--33},
	file = {Godxy_2006b_Exploring Music-Related Gestures by Sound-Tracing.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ConGAS/Godxy_2006b_Exploring Music-Related Gestures by Sound-Tracing.pdf:application/pdf}
}

@inproceedings{godoy_playing_2005,
	title = {Playing “air instruments”: mimicry of sound-producing gestures by novices and experts},
	booktitle = {International {Gesture} {Workshop}},
	publisher = {Springer},
	author = {Godøy, Rolf Inge and Haga, Egil and Jensenius, Alexander Refsum},
	year = {2005},
	pages = {256--267},
	file = {Godxy_2006a_Playing Air Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_International Gesture Workshop/Godxy_2006a_Playing Air Instruments.pdf:application/pdf}
}

@inproceedings{hunt_importance_2002,
	address = {Dublin, Ireland},
	title = {The importance of {Parameter} {Mapping} in {Electronic} {Instrument} {Design}},
	url = {http://www.nime.org/proceedings/2002/nime2002_088.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Hunt, Andy D. and Wanderley, Marcelo M. and Paradis, Matthew},
	month = may,
	year = {2002},
	keywords = {human-computer interaction, mapping strategies, electronic instruments and t, electronic musical instruments, h e},
	pages = {88--93},
	file = {nime2002_088_Hunt_Wanderley_TheImportanceOfParameterMappingInElectronicInstrumentDesign.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_088_Hunt_Wanderley_TheImportanceOfParameterMappingInElectronicInstrumentDesign.pdf:application/pdf}
}

@incollection{emerson_mapping_2017,
	title = {Mapping, causality and the perception of instrumentality: {Theoretical} and empirical approaches to the audience’s experience of digital musical instruments},
	booktitle = {Musical instruments in the 21st {Century}},
	publisher = {Springer},
	author = {Emerson, Gina and Egermann, Hauke},
	year = {2017},
	pages = {363--370},
	file = {Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Bovermann, Till/Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:application/pdf}
}

@article{conard_new_2009,
	title = {New flutes document the earliest musical tradition in southwestern {Germany}},
	volume = {460},
	number = {7256},
	journal = {Nature},
	author = {Conard, Nicholas J and Malina, Maria and Münzel, Susanne C},
	year = {2009},
	pages = {737}
}

@book{miranda_new_2006,
	title = {New digital musical instruments: control and interaction beyond the keyboard},
	volume = {21},
	publisher = {AR Editions, Inc.},
	author = {Miranda, Eduardo Reck and Wanderley, Marcelo M},
	year = {2006}
}

@incollection{mulder_mulder_2000,
	title = {{MULDER}, {Alex}. {Towards} a choice of gestural constraints for instrumental performers.},
	booktitle = {Trends in {Gestural} {Control} of {Music}},
	author = {Mulder, Axel},
	month = mar,
	year = {2000},
	keywords = {gesture, Gesture typologies, Instrumental gesture},
	file = {Towards_a_choice_of_gestural_constraints_for_instr.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Wanderley, Marcello/Towards_a_choice_of_gestural_constraints_for_instr.pdf:application/pdf}
}

@inproceedings{cadoz_instrumental_1988,
	address = {Cologne, Germany},
	title = {Instrumental {Gesture} and {Musical} {Composition}},
	url = {https://hal.archives-ouvertes.fr/hal-00491738},
	booktitle = {{ICMC} 1988 - {International} {Computer} {Music} {Conference}},
	author = {Cadoz, Claude},
	month = feb,
	year = {1988},
	keywords = {Gestural Interface, Real-time, Gesture Capture},
	pages = {1--12},
	annote = {http://computermusic.org/},
	file = {1988.Cadoz.Instrumental gesture and musical composition.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1988/1988.Cadoz.Instrumental gesture and musical composition.pdf:application/pdf}
}

@inproceedings{zhang_adaptive_2019,
	address = {Porto-Alegre, Brézil},
	title = {Adaptive {Multimodal} {Music} {Learning} via {Interactive}-haptic {Instrument}},
	abstract = {Haptic interfaces have untapped the sense of touch to assist multimodal music learning. We have recently seen various improvements of interface design on tactile feedback and force guidance aiming to make instrument learning more effective. However, most interfaces are still quite static; they cannot yet sense the learning progress and adjust the tutoring strategy accordingly. To solve this problem, we contribute an adaptive haptic interface based on the latest design of haptic flute. We first adopted a clutch mechanism to enable the interface to turn on and off the haptic control flexibly in real time. The interactive tutor is then able to follow human performances and apply the “teacher force” only when the software instructs so. Finally, we incorporated the adaptive interface with a step-by-step dynamic learning strategy. Experimental results showed that dynamic learning dramatically outperforms static learning, which boosts the learning rate by 45.3\% and shrinks the forgetting chance by 86\%.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Zhang, Yian and Li, Yinmiao and Chin, Daniel and Xia, Gus},
	month = jun,
	year = {2019}
}

@inproceedings{wanderley_non-obvious_1999,
	address = {Berlin, Heidelberg},
	title = {Non-obvious {Performer} {Gestures} in {Instrumental} {Music}},
	isbn = {978-3-540-46616-1},
	abstract = {This paper deals with the gestural language of instrumentalists playing wind instruments. It discusses the role of non-obvious performer gestures that may nevertheless influence the final sound produced by the acoustic instrument. These gestures have not commonly been considered in sound synthesis, although they are an integral part of the instrumentalist's full gestural language. The structure of this paper will be based on an analysis of these non-obvious gestures followed by some comments on how to best classify them according to existing research on gesture reviewed in the introduction; finally, the influence of these gestures on the sound produced by the instrument will be studied and measurement and simulation results presented.},
	booktitle = {Gesture-{Based} {Communication} in {Human}-{Computer} {Interaction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Wanderley, Marcelo M.},
	editor = {Braffort, Annelies and Gherbi, Rachid and Gibet, Sylvie and Teil, Daniel and Richardson, James},
	year = {1999},
	pages = {37--48}
}

@inproceedings{zattra_les_2013,
	title = {Les origines du nom de {RIM} ({Réalisateur} en informatique musicale)},
	booktitle = {Actes des {Journées} d’informatique musicale},
	author = {Zattra, Laura},
	year = {2013}
}

@phdthesis{dalessandro_realtime_2009,
	title = {Realtime and {Accurate} {Musical} {Control} of {Expression} in {Voice} {Synthesis}},
	author = {d’Alessandro, Nicolas},
	year = {2009},
	file = {2009.PhD.Nicolasd’Alessandro_ControlExpression in Voice Synthesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2009.PhD.Nicolasd’Alessandro_ControlExpression in Voice Synthesis.pdf:application/pdf}
}

@book{leroi-gourhan_geste_1964,
	address = {Paris},
	title = {Le geste et la parole},
	isbn = {978-2-226-02324-7},
	publisher = {Albin Michel},
	author = {Leroi-Gourhan, André},
	year = {1964}
}

@article{nia_evolution_2015,
	title = {The evolution of air resonance power efficiency in the violin and its ancestors},
	volume = {471},
	number = {2175},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Nia, Hadi T and Jain, Ankita D and Liu, Yuming and Alam, Mohammad-Reza and Barnas, Roman and Makris, Nicholas C},
	year = {2015},
	pages = {20140905}
}

@article{bricout_les_2011,
	title = {Les interfaces musicales: la question des «instruments aphones»},
	number = {11},
	journal = {Methodos. Savoirs et textes},
	author = {Bricout, Romain},
	year = {2011},
	file = {BRICOUT_Les interfaces musicales  la question des « instruments aphones ».pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Methodos/BRICOUT_Les interfaces musicales  la question des « instruments aphones ».pdf:application/pdf}
}

@inproceedings{wanderley_gestural_2001,
	title = {Gestural control of music},
	booktitle = {International {Workshop} {Human} {Supervision} and {Control} in {Engineering} and {Music}},
	publisher = {Citeseer},
	author = {Wanderley, Marcelo M},
	year = {2001},
	pages = {632--644},
	file = {Wanderley_GesturalControlOfMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_InternationalWorkshopHumanSupervisionAndControlInEngineeringAndMusic/Wanderley_GesturalControlOfMusic.pdf:application/pdf}
}

@article{bown_understanding_2009,
	title = {Understanding interaction in contemporary digital music: from instruments to behavioural objects},
	volume = {14},
	number = {2},
	journal = {Organised Sound},
	author = {Bown, Oliver and Eldridge, Alice and McCormack, Jon},
	year = {2009},
	pages = {188--196},
	file = {OrganisedSound2009.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2009/OrganisedSound2009.pdf:application/pdf}
}

@article{di_scipio_sound_2003,
	title = {‘{Sound} is the interface’: from interactive to ecosystemic signal processing},
	volume = {8},
	number = {3},
	journal = {Organised Sound},
	author = {Di Scipio, Agostino},
	year = {2003},
	pages = {269--277},
	file = {Sound_is_the_interface_From_interactive_to_ecosy.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2003/Sound_is_the_interface_From_interactive_to_ecosy.pdf:application/pdf}
}

@inproceedings{mumma_creative_1967,
	title = {Creative aspects of live-performance electronic music technology},
	booktitle = {Audio {Engineering} {Society} {Convention} 33},
	publisher = {Audio Engineering Society},
	author = {Mumma, Gordon},
	year = {1967},
	file = {mumma-1967.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_IEEE/mumma-1967.pdf:application/pdf}
}

@inproceedings{goudard_playing_2014,
	title = {On the playing of monodic pitch in digital music instruments},
	author = {Goudard, Vincent and Genevois, Hugues and Feugère, Lionel},
	year = {2014}
}

@article{bin_hands_2017,
	title = {Hands where we can see them! investigating the impact of gesture size on audience perception},
	author = {Bin, S. M. Astrid and Bryan-Kinns, Nick and McPherson, A and {others}},
	year = {2017}
}

@article{tsay_sight_2013,
	title = {Sight over sound in the judgment of music performance},
	volume = {110},
	number = {36},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Tsay, Chia-Jung},
	year = {2013},
	pages = {14580--14585}
}

@article{jorda_instruments_2004,
	title = {Instruments and players: {Some} thoughts on digital lutherie},
	volume = {33},
	number = {3},
	journal = {Journal of New Music Research},
	author = {Jordà, Sergi},
	year = {2004},
	pages = {321--341}
}

@inproceedings{collins_relating_2002,
	address = {Hallam University, Sheffield, England, UK.},
	title = {Relating superhuman virtuosity to human performance},
	url = {http://www.iodesign.free-online.co.uk/maxis/maxis2002.html},
	booktitle = {Proceedings of {MAXIS}},
	author = {Collins, Nick},
	year = {2002},
	pages = {12--14},
	file = {2002.NickCollins.RelatingSuperhumanVirtuosity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_MAXIS/2002.NickCollins.RelatingSuperhumanVirtuosity.pdf:application/pdf}
}

@phdthesis{bacot_geste_2017,
	type = {{PhD} {Thesis}},
	title = {Geste et instrument dans la musique électronique: organologie des pratiques de création contemporaines},
	school = {Paris, EHESS},
	author = {Bacot, Baptiste},
	year = {2017},
	file = {Bacot_2017_Geste et instrument dans la musique électronique.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Bacot_2017_Geste et instrument dans la musique électronique.pdf:application/pdf}
}

@incollection{giavitto_du_2014,
	address = {Paris},
	edition = {Hermann},
	title = {Du temps écrit au temps produit en informatique musicale},
	language = {fr},
	booktitle = {Produire le temps},
	author = {Giavitto, Jean-Louis},
	year = {2014},
	pages = {73--105},
	file = {19-Dutempscritautempsproduit.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Vinet, Hugues/19-Dutempscritautempsproduit.pdf:application/pdf}
}

@book{eco_oeuvre_2015,
	address = {Paris},
	title = {L'oeuvre ouverte},
	isbn = {978-2-7578-5017-6},
	publisher = {Points},
	author = {Eco, Umberto},
	translator = {Roux de Bézieux, Chantal and Boucourechliev, André},
	year = {2015},
	note = {édition italienne : 1962}
}

@inproceedings{goudard_ephemeral_2019,
	address = {Porto Alegre, Brazil},
	title = {Ephemeral instruments},
	copyright = {All rights reserved},
	url = {http://www.nime.org/proceedings/2019/nime2019_067.pdf},
	abstract = {This article questions the notion of ephemerality of digital musical instruments (DMI). Longevity is generally regarded as a valuable quality that good design criteria should help to achieve. However, the nature of the tools, of the performance conditions and of the music itself may lead to think of ephemerality as an intrinsic modality of the existence of DMIs. In particular, the conditions of contemporary musical production suggest that contextual adaptations of instrumental devices beyond the monolithic unity of classical instruments should be considered. The first two parts of this article analyse various reasons to reassess the issue of longevity and ephemerality. The last two sections attempt to propose an articulation of these two aspects to inform both the design of the DMI and their learning.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {UFRGS},
	author = {Goudard, Vincent},
	editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
	month = jun,
	year = {2019},
	pages = {349--354}
}

@book{guerin_philosophie_2018,
	title = {Philosophie du geste},
	publisher = {Éditions Actes Sud},
	author = {Guérin, Michel},
	year = {2018}
}

@article{imberty_mouvement_2013,
	title = {Mouvement, geste et figure: la musique ancrée dans le corps},
	journal = {S. Kogler, S. \& J.-P. Olive (Éd.), Expression et geste musical},
	author = {Imberty, Michel},
	year = {2013},
	pages = {25--36}
}

@book{olive_expression_2013,
	title = {Expression et geste musical},
	author = {Olive, Jean Paul and Kogler, Susanne},
	year = {2013}
}

@incollection{genevois_geste_1999,
	title = {Geste et pensée musicale : de l'outil à l'instrument},
	url = {https://hal.archives-ouvertes.fr/hal-00160720},
	booktitle = {Les nouveaux gestes de la musique},
	publisher = {Parenthèses},
	author = {Genevois, Hugues},
	year = {1999},
	pages = {25}
}

@article{shannon_mathematical_1948,
	title = {A mathematical theory of communication},
	volume = {27},
	number = {3},
	journal = {Bell system technical journal},
	author = {Shannon, Claude Elwood},
	year = {1948},
	pages = {379--423}
}

@article{stiegler_circuit_2004,
	title = {Le circuit du désir musical : {L}’interprète, le compositeur, l’auditeur — organes et instruments},
	volume = {15},
	doi = {https://doi.org/10.7202/902340ar},
	number = {1},
	journal = {Circuit: Musiques contemporaines},
	author = {Stiegler, Bernard and Donin, Nicolas},
	year = {2004},
	pages = {41--56},
	file = {Stiegler_CircuitDuDesirMusical.pdf:/Users/vg/Documents/_BIBLIO/PHILOSOPHY/Stiegler, Bernard/Stiegler_CircuitDuDesirMusical.pdf:application/pdf}
}

@book{auroux_revolution_1994,
	series = {Philosophie et langage},
	title = {La révolution technologique de la grammatisation: introduction à l'histoire des sciences du langage},
	isbn = {978-2-87009-565-2},
	url = {https://halshs.archives-ouvertes.fr/halshs-00529159},
	publisher = {Mardaga},
	author = {Auroux, Sylvain},
	year = {1994},
	lccn = {95109400}
}

@book{merleau-ponty_loeil_1964,
	title = {L'Œil et {L}'{Esprit}},
	publisher = {Gallimard},
	author = {Merleau-Ponty, Maurice},
	year = {1964}
}

@inproceedings{timsit-berthier_les_2004,
	title = {Les {Unités} {Sémiotiques} {Temporelles} ({UST}) {Un} nouvel outil d'analyse musicale. {Description} et approche biosémiotique.},
	booktitle = {Description et approche biosemiotique [{United} temporal semiotics—a novel method of musical analysis. {Description} and biosemiotic approach]. {Colloque} de {Rochebrune}, {January}},
	author = {Timsit-Berthier, M and Bootz, Ph and Favory, J and Formosa, M and Mandelbrojt, J and Paillard, J and Pro'dhomme, L and Frémoit, M},
	year = {2004},
	pages = {26--30},
	file = {ust-janvier04.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_TOPICS/UST/ust-janvier04.pdf:application/pdf}
}

@article{iazzetta_meaning_2000,
	title = {Meaning in musical gesture},
	journal = {Trends in gestural control of music},
	author = {Iazzetta, Fernando},
	year = {2000},
	pages = {259--268}
}

@article{kurtenbach_art_1990,
	title = {The art of human-computer interface design},
	journal = {Gestures in Human-Computer Communication},
	author = {Kurtenbach, Gordon and Hulteen, Eric A and Laurel, Brenda},
	year = {1990},
	pages = {309--317}
}

@incollection{cadoz_musique_1999,
	title = {Musique, geste, technologie},
	url = {https://hal.archives-ouvertes.fr/hal-01083792},
	booktitle = {Les nouveaux gestes de la musique},
	publisher = {Editions Parenthèses},
	author = {Cadoz, Claude},
	editor = {Vivo, Hugues Genevois et Raphaël de},
	year = {1999},
	pages = {47--92}
}

@phdthesis{schnell_playing_2013,
	address = {Graz, Austria},
	title = {Playing (with) {Sound}-{Of} the {Animation} of {Digitized} {Sounds} and their {Reenactment} by {Playful} {Scenarios} in the {Design} of {Interactive} {Audio} {Applications}},
	school = {Institute of Electronic Music and Acoustics, University of Music and Performing Arts},
	author = {Schnell, Norbert},
	year = {2013},
	file = {2013.PhD.Schnell.Reenactment.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2013.PhD.Schnell.Reenactment.pdf:application/pdf}
}

@article{dolan_toward_2012,
	title = {Toward a {Musicology} of {Interfaces}},
	volume = {5},
	journal = {Keyboard Perspectives},
	author = {Dolan, Emily I},
	year = {2012},
	pages = {1--12},
	file = {2012-dolan_-_toward_a_musicology_of_interfaces_kp5.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/KeyboardPerspectives/2012-dolan_-_toward_a_musicology_of_interfaces_kp5.pdf:application/pdf}
}

@inproceedings{winkler_making_1995,
	address = {Banff Centre for the Arts, Banff, Canada},
	title = {Making {Motion} {Musical}: {Gesture} {Mapping} {Strategies} for {Interactive} {Computer} {Music}},
	abstract = {The increase in sophistication of new devices that allow gesture and movement to be translated into computer data holds great promise for interactive composition, dance, and creating responsive music in virtual reality systems. Data describing human motion can produce musically satisfying results by their impact on sound and musical processes.
This paper will take a general look at the use of physical gesture data as primary compositional constraints in interactive music systems. Theoretical concepts for the interpretation and evaluation of these data will be discussed. Finally, these devices and techniques will be shown be viable in multimedia applications.},
	booktitle = {Proceedings of the 1995 {International} {Computer} {Music} {Conference}},
	author = {Winkler, Todd},
	year = {1995},
	file = {1995.Winkler-MakingMotionMusical_gestureMappingStrategiesForInteractiveComputerMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1995/1995.Winkler-MakingMotionMusical_gestureMappingStrategiesForInteractiveComputerMusic.pdf:application/pdf}
}

@inproceedings{cadoz_simuler_1990,
	title = {Simuler pour connaître, {Connaître} pour simuler},
	booktitle = {Colloque {Modèles} {Physiques}, {Création} {Musicale} et {Ordinateurs}–{Grenoble}},
	author = {Cadoz, Claude},
	year = {1990},
	file = {Cad94_Conf_Modeles-physiques-1990.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_REPORTS/Cadoz, Claude/Cad94_Conf_Modeles-physiques-1990.pdf:application/pdf}
}

@inproceedings{wanderley_choice_2000,
	title = {On the {Choice} of {Transducer} {Technologies} for {Specific} {Musical} {Functions}.},
	booktitle = {{ICMC}},
	author = {Wanderley, Marcelo M and Viollet, Jean-Philippe and Isart, Fabrice and Rodet, Xavier},
	year = {2000}
}

@book{mazzola_topos_2018,
	title = {The {Topos} of {Music} {III}: {Gestures}},
	publisher = {Springer},
	author = {Mazzola, Guerino and Guitart, René and Ho, Jocelyn and Lubet, Alex and Mannone, Maria and Rahaim, Matt and Thalmann, Florian},
	year = {2018},
	file = {[Computational Music Science] Guerino Mazzola - The Topos of Music III_ Gestures .pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Mazzola, Guerino/[Computational Music Science] Guerino Mazzola - The Topos of Music III_ Gestures .pdf:application/pdf}
}

@article{wegner_apparent_1999,
	title = {Apparent mental causation: {Sources} of the experience of will.},
	volume = {54},
	number = {7},
	journal = {American psychologist},
	author = {Wegner, Daniel M and Wheatley, Thalia},
	year = {1999},
	pages = {480},
	file = {wegner20199920apparent20mental20causation.20sources20of20the20experience20of20will.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_AmericanPsychologist/wegner20199920apparent20mental20causation.20sources20of20the20experience20of20will.pdf:application/pdf}
}

@book{deleuze_francis_2002,
	address = {Paris},
	series = {L'{Ordre} philosophique},
	title = {Francis {Bacon}, {Logique} de la sensation},
	publisher = {Le Seuil},
	author = {Deleuze, Gilles},
	year = {2002}
}

@book{deleuze_logique_1981,
	address = {Paris},
	title = {Logique de la sensation},
	publisher = {Editions de la Différence},
	author = {Deleuze, Gilles},
	year = {1981}
}

@article{cadoz_synthese_1981,
	title = {Synthèse musicale par simulation des mécanismes instrumentaux, transducteurs gestuels rétroactifs pour l'étude du jeu instrumental},
	volume = {4},
	url = {https://hal.archives-ouvertes.fr/hal-00878815},
	number = {59},
	journal = {Revue d'acoustique},
	author = {Cadoz, Claude and Luciani, Annie and Florens, Jean-Loup},
	year = {1981},
	pages = {279--292},
	annote = {Vibrations - environnement sonore. 14e année. Publié sous l'égide du GALF (Groupement des Acousticiens de Langue Française)},
	file = {CLF81_Rev_Acoustique.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue d'acoustique/CLF81_Rev_Acoustique.pdf:application/pdf}
}

@book{hatten_interpreting_2004,
	title = {Interpreting musical gestures, topics, and tropes: {Mozart}, {Beethoven}, {Schubert}},
	publisher = {Indiana University Press},
	author = {Hatten, Robert S},
	year = {2004},
	file = {(Musical meaning and interpretation.) Beethoven, Ludwig van_ Hatten, Robert S._ Mozart, Wolfgang Amadeus_ Schubert, Franz - Interpreting musical gestures, topics, and tropes _ Mozart, Beethoven, Schub.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Hatten, Robert/(Musical meaning and interpretation.) Beethoven, Ludwig van_ Hatten, Robert S._ Mozart, Wolfgang Amadeus_ Schubert, Franz - Interpreting musical gestures, topics, and tropes _ Mozart, Beethoven, Schub.pdf:application/pdf}
}

@book{genevois_les_1999,
	address = {Marseille},
	edition = {Editions Paenthèses},
	series = {Collection eupalinos},
	title = {Les nouveaux gestes de la musique},
	editor = {Genevois, Hugues and De Vivo, Raphaël},
	year = {1999}
}

@book{wanderley_trends_2000,
	title = {Trends in gestural control of music},
	publisher = {Ircam},
	editor = {Wanderley, Marcelo and Battier, Marc},
	year = {2000}
}

@book{castellengo_ecoute_2015,
	title = {Ecoute musicale et acoustique},
	publisher = {Eyrolles},
	author = {Castellengo, Michèle},
	collaborator = {Liénard, Jean-Sylvain and Bloch, Georges},
	year = {2015}
}

@book{frances_perception_1984,
	address = {Paris},
	title = {La perception de la musique (2ème ed.)},
	volume = {14},
	publisher = {Vrin},
	author = {Francès, Robert},
	year = {1984}
}

@inproceedings{gilbert_influence_2006,
	title = {Influence de la température sur la justesse d’un instrument à vent},
	booktitle = {Proceedings of {Congres} {Français} d’{Acoustique} 2006, {Tours}},
	author = {Gilbert, Joël and Ruiz, LM Leboso and Gougeon, Samuel},
	year = {2006}
}

@article{benford_performing_2010,
	title = {Performing {Musical} {Interaction}: {Lessons} from the {Study} of {Extended} {Theatrical} {Performances}},
	volume = {34},
	url = {https://doi.org/10.1162/COMJ_a_00025},
	doi = {10.1162/COMJ_a_00025},
	number = {4},
	journal = {Computer Music Journal},
	author = {Benford, Steve},
	year = {2010},
	pages = {49--61},
	file = {comj_a_00025.Benford.Performing MusicalInteraction.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2010/34.4-HCI/comj_a_00025.Benford.Performing MusicalInteraction.pdf:application/pdf}
}

@inproceedings{raboisson_experience_2017,
	address = {Paris, France},
	series = {Journées d'informatique musicale},
	title = {Une expérience de captation et d'analyse de l'interprétation acousmatique},
	url = {https://hal.archives-ouvertes.fr/hal-01525481},
	booktitle = {Journées d'informatique musicale},
	publisher = {Collegium Music{\textbackslash}a e},
	author = {Raboisson, Nathanaëlle and Couprie, Pierre},
	editor = {Couprie, Pierre and Davy-Rigaux, Cécile and Genevois, Hugues and Liao, Lin-Ni and Malt, Mikhail and Mifune, Marie-France},
	month = may,
	year = {2017},
	keywords = {Acousmonium, Analyse de l'interprétation, Digital musicology, Musique acousmatique, Performance studies, Représentation visuelle}
}

@phdthesis{mooney_sound_2006,
	type = {{PhD} {Thesis}},
	title = {Sound diffusion systems for the live performance of electroacoustic music},
	school = {Citeseer},
	author = {Mooney, James R},
	year = {2006},
	file = {2006.Mooney.SoundDiffusionSystemsForTheLivePerformanceOfElectroacousticMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2006.Mooney.SoundDiffusionSystemsForTheLivePerformanceOfElectroacousticMusic.pdf:application/pdf}
}

@incollection{graybill_whose_2016,
	series = {{SEMPRE} {Studies} in {The} {Psychology} of {Music}},
	title = {Whose {Gestures}? {Chamber} {Music} and the {Construction} of {Permanent} {Agents}},
	language = {En},
	booktitle = {New {Perspectives} on {Music} and {Gesture}},
	publisher = {Routledge},
	editor = {Graybill, Roger and Gritten, Anthony and King, Elaine},
	year = {2016},
	pages = {247--268}
}

@book{theberge_any_1997,
	title = {Any {Sound} {You} {Can} {Imagine}: {Making} {Music} / {Consuming} {Technology}},
	isbn = {0-8195-6309-9},
	url = {https://www.xarg.org/ref/a/0819563099/},
	publisher = {Wesleyan University Press},
	author = {Théberge, Paul},
	month = may,
	year = {1997}
}