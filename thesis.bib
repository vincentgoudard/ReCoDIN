
@article{magnusson_musical_2017,
	title = {Musical {Organics} : {A} {Heterarchical} {Approach} to {Digital} {Organology}},
	volume = {46},
	issn = {0929-8215, 1744-5027},
	shorttitle = {Musical {Organics}},
	url = {https://www.tandfonline.com/doi/full/10.1080/09298215.2017.1353636},
	doi = {10.1080/09298215.2017.1353636},
	abstract = {Gaining a comprehensive understanding and overview of new musical technologies is fraught with difﬁculties. They are made of digital materials of such diverse origins and nature, that they do not ﬁt comfortably into traditional organological classiﬁcations. This article traces the history of musical instrument classiﬁcations relevant to the understanding of new digital instruments, and proposes an alternative method to the centuries-old tree-structure of downwards divisions. The proposed musical organics is a multidimensional, heterarchical, and organic approach to the analysis and classiﬁcation of both traditional and new musical instruments that suits the rhizomatic nature of their material design and technical origins. Outlines of a hypothetical organological informatics retrieval system are also presented.},
	language = {en},
	number = {3},
	urldate = {2019-05-22},
	journal = {Journal of New Music Research},
	author = {Magnusson, Thor},
	month = jul,
	year = {2017},
	pages = {286--303},
	file = {Musical Organics A Heterarchical Approach to Digital Organology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JNMR_JournalOfNewMusicResearch/Musical Organics A Heterarchical Approach to Digital Organology.pdf:application/pdf}
}

@article{hajdu_disposable_2016,
	title = {Disposable {Music}},
	volume = {40},
	issn = {0148-9267, 1531-5169},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00342},
	doi = {10.1162/COMJ_a_00342},
	abstract = {This article introduces the concept of real-time composition and composition as a “dispositif” in the sense of Foucault and Deleuze, defining it as a heterogeneous ensemble of pieces that together form an apparatus. The introduction situates the dispositif in the context of cultural developments, most notably its slow but steady shift away from textualization in digital media. As musicians are adapting to ensuing cultural and, above all, economic changes, new musical forms emerge that rely to a lesser degree on fully notated scores, such as “comprovisation” or laptop performance. Antithetically, the computer also allows the creation of “authorless” notated scores in real time to be sight-read by capable musicians—a practice for which special software has been developed in recent years. Because these scores are not meant to be kept and distributed, they are ephemeral and, therefore, disposable. Three examples by the author are given to illustrate the interwovenness of this approach, where carefully selected narratives and dramaturgies make up for the inherent unpredictability of the outcome.},
	language = {en},
	number = {1},
	urldate = {2019-05-22},
	journal = {Computer Music Journal},
	author = {Hajdu, Georg},
	month = mar,
	year = {2016},
	pages = {25--34},
	file = {2016.Hajdu_Disposable-Music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2016.Hajdu_Disposable-Music.pdf:application/pdf}
}

@inproceedings{bhagwati_vexations_2017,
	title = {Vexations of ephemerality. {Extreme} sight-reading in situative scores - for makers, performers, audiences.},
	abstract = {What do we do when we subject musicians and audiences to music prompted by real-time scores? Such situative scores create a new kind of immanent relationship between performers and audiences, between composers and performers, composers and audiences – a relationship whose ingrained disregard of context, memory, and knowledge has often been ignored. The use of situative scores seems to inscribe itself into a more general societal trend that uses technology to ephemeralize our lives, to decouple presence from its history. While this immanence has often been perceived as a force for the emancipation of performers and spectators, it can also give rise to unaccountability. Do artistic practices that ephemeralize our artistic 'regime of perception, sensation and interpretation' (Rancière) - such as situative scores – foster abuses of immanence?. In this paper, I will look at such questions from the perspective of the performers, the audiences and the makers of such scores – the composers.},
	language = {en},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Bhagwati, Sandeep},
	year = {2017},
	pages = {6},
	file = {15-vexations_ephemerality.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2017/15-vexations_ephemerality.pdf:application/pdf}
}

@phdthesis{momeni_composing_2005,
	address = {Berkeley},
	title = {Composing {Instruments}: {Inventing} and {Performing} with {Generative} {Computer}-based {Instruments}},
	abstract = {This dissertation describes music composition as an act of composing instruments. The building blocks of such instruments are discussed: the fundamentally interdisciplinary approach, the role of gesture, the role of real-time generative software, the mappings between gesture and generative processes, and the interaction between performer and instrument. A real-time performance instrument that was composed to accompany the opera Takemitsu: My Way of Life is described. Key constraints imposed by this project are described, namely: the need for the real-time electronic sound to blend and relate musically to the rest of the music, the need to create a stateless and playable instrument, and the need for an instrument that is robust, adaptable, portable. Design and compositional decisions that address these constraints are proposed and the actual implementation is discussed. As a contrasting example of a composed instrument, a second project is presented: an interactive installation named …in memory of Leah Deni created in memory of Leah Deni. This project serves as an example of the same compositional interest in instrument building and interactivity, but applied to an installation setting where the performer is the audience member. Connections between the conceptual and technological aspects of the installation are drawn. Finally, a set of software modules for real-time creative work named \_aLib is presented. The modules in \_aLib (a set of abstractions for the Max/MSP environment) were used extensively in the described instruments and will hopefully make a contribution to the real-time computer performance community.},
	language = {en},
	school = {University of California},
	author = {Momeni, Ali},
	year = {2005},
	file = {2005.PhD.AliMomeni.Composing Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2005.PhD.AliMomeni.Composing Instruments.pdf:application/pdf}
}

@phdthesis{wierenga_searching_2016,
	address = {New York, U.S.A.},
	title = {Searching for {Sounds}: {Instrumental} {Agency} and {Modularity} in {Electroacoustic} {Improvisation}},
	language = {en},
	school = {City University of New York},
	author = {Wierenga, Stephen (Red)},
	year = {2016},
	file = {2016.PhD.Wierenga.Stephen.SearchingForSounds-InstrumentalAgencyAndModularityInElectronicMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2016.PhD.Wierenga.Stephen.SearchingForSounds-InstrumentalAgencyAndModularityInElectronicMusic.pdf:application/pdf}
}

@incollection{adams_inventing_2008,
	address = {Berlin, Heidelberg},
	title = {Inventing {Malleable} {Scores}: {From} {Paper} to {Screen} {Based} {Scores}},
	volume = {7},
	isbn = {978-3-540-79485-1 978-3-540-79486-8},
	shorttitle = {Inventing {Malleable} {Scores}},
	url = {http://link.springer.com/10.1007/978-3-540-79486-8_22},
	abstract = {This paper examines the idea of artistic license of the interpreter as a positive aspect of composition. The possibilities of participating in the creative act beyond the role of the traditional interpreter are illustrated by tracing the development of malleability in score writing in selected works of the author. Starting with the standard score, examples are given for the various forms of malleable scores that lead up to the application of real-time electronic scores in which a concept of self-conduction is feasibly implemented for use in distributed ensembles.},
	language = {en},
	urldate = {2019-05-22},
	booktitle = {Transdisciplinary {Digital} {Art}. {Sound}, {Vision} and the {New} {Screen}},
	publisher = {Springer Berlin Heidelberg},
	author = {Clay, Arthur},
	editor = {Adams, Randy and Gibson, Steve and Arisona, Stefan Müller},
	year = {2008},
	doi = {10.1007/978-3-540-79486-8_22},
	pages = {255--269},
	file = {Clay,Arthur Inventing Malleable Scores.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/Clay,Arthur Inventing Malleable Scores.pdf:application/pdf}
}

@article{freeman_extreme_2008,
	title = {Extreme {Sight}-{Reading}, {Mediated} {Expression}, and {Audience} {Participation}: {Real}-{Time} {Music} {Notation} in {Live} {Performance}},
	volume = {32},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Extreme {Sight}-{Reading}, {Mediated} {Expression}, and {Audience} {Participation}},
	url = {http://www.mitpressjournals.org/doi/10.1162/comj.2008.32.3.25},
	doi = {10.1162/comj.2008.32.3.25},
	language = {en},
	number = {3},
	urldate = {2019-05-22},
	journal = {Computer Music Journal},
	author = {Freeman, Jason},
	month = sep,
	year = {2008},
	pages = {25--41},
	file = {CMJ-32-3-Freeman_Extreme Sight-reading.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/CMJ-32-3-Freeman_Extreme Sight-reading.pdf:application/pdf}
}

@inproceedings{ishii_tangible_1997,
	address = {Atlanta, Georgia, United States},
	title = {Tangible bits: towards seamless interfaces between people, bits and atoms},
	isbn = {978-0-89791-802-2},
	shorttitle = {Tangible bits},
	url = {http://portal.acm.org/citation.cfm?doid=258549.258715},
	doi = {10.1145/258549.258715},
	abstract = {This paper presents our vision of Human Computer Interaction (HCI): "Tangible Bits." Tangible Bits allows users to "grasp \& manipulate" bits in the center of users’ attention by coupling the bits with everyday physical objects and architectural surfaces. Tangible Bits also enables users to be aware of background bits at the periphery of human perception using ambient display media such as light, sound, airflow, and water movement in an augmented space. The goal of Tangible Bits is to bridge the gaps between both cyberspace and the physical environment, as well as the foreground and background of human activities.},
	language = {en},
	urldate = {2019-05-22},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems  - {CHI} '97},
	publisher = {ACM Press},
	author = {Ishii, Hiroshi and Ullmer, Brygg},
	year = {1997},
	pages = {234--241},
	file = {1997.Ishii.Tangible Bits.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/1997/1997.Ishii.Tangible Bits.pdf:application/pdf}
}

@article{godoy_gestural-sonorous_2006,
	title = {Gestural-{Sonorous} {Objects}: embodied extensions of {Schaeffer}'s conceptual apparatus},
	volume = {11},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Gestural-{Sonorous} {Objects}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771806001439/type/journal_article},
	doi = {10.1017/S1355771806001439},
	language = {en},
	number = {2},
	urldate = {2019-05-22},
	journal = {Organised Sound},
	author = {Godøy, Rolf Inge},
	month = aug,
	year = {2006},
	pages = {149--157},
	file = {2006.Godoy.Gestural_Sonorous_Objects.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2006.Godoy.Gestural_Sonorous_Objects.pdf:application/pdf}
}

@book{roads_microsound_2001,
	address = {Cambridge, Mass.},
	title = {Microsound},
	isbn = {978-0-262-18215-7},
	language = {en},
	publisher = {MIT Press},
	author = {Roads, Curtis},
	year = {2001},
	note = {OCLC: 834185525},
	file = {Roads_Curtis_Microsound.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Roads, Curtis/Roads_Curtis_Microsound.pdf:application/pdf}
}

@article{hunt_mapping_2002,
	title = {Mapping performer parameters to synthesis engines},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002030/type/journal_article},
	doi = {10.1017/S1355771802002030},
	language = {en},
	number = {2},
	urldate = {2019-05-22},
	journal = {Organised Sound},
	author = {Hunt, Andy and Wanderley, Marcelo M.},
	month = aug,
	year = {2002},
	pages = {97--108},
	file = {2002.Hunt.Wanderley.MappingPerformerParametersToSynthesisEngines.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2002.Hunt.Wanderley.MappingPerformerParametersToSynthesisEngines.pdf:application/pdf}
}

@article{verfaille_mapping_2006,
	title = {Mapping strategies for gestural and adaptive control of digital audio effects},
	volume = {35},
	issn = {0929-8215, 1744-5027},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09298210600696881},
	doi = {10.1080/09298210600696881},
	abstract = {This paper discusses explicit mapping strategies for gestural and adaptive control of digital audio effects. We address the problem of deﬁning what is the control and what is the effect. We then propose a mapping strategy derived from mapping techniques used in sound synthesis. The explicit mapping strategy we developed has two levels and two layers for each level: the ﬁrst level is the adaptive control with a feature combination layer and a control signal conditioning layer; the second level is the gestural control layer. We give musical examples that illustrate the interest of this strategy.},
	language = {en},
	number = {1},
	urldate = {2019-05-22},
	journal = {Journal of New Music Research},
	author = {Verfaille, Vincent and Wanderley, Marcelo M. and Depalle, Philippe},
	month = mar,
	year = {2006},
	pages = {71--93},
	file = {Verfaille_Mapping Strategies for Gestural and Adaptive Control of Digital Audio Effects.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_TOPICS/Musical Gesture Mapping/Verfaille_Mapping Strategies for Gestural and Adaptive Control of Digital Audio Effects.pdf:application/pdf}
}

@inproceedings{hunt_towards_2000,
	address = {Berlin, Allemagne.},
	title = {Towards a {Model} for {Instrumental} {Mapping} in {Expert} {Musical} {Interaction}},
	abstract = {This paper reviews models of the ways in which performer instrumental actions can be linked to sound synthesis parameters. We analyse available literature on both acoustical instrument simulation and mapping of input devices to sound synthesis in general human-computer interaction. We further demonstrate why a more complex mapping strategy is required to maximise human performance possibilities in expert manipulation situations by showing clear measurements of user performance improvement over time. We finally discuss a general model for instrumental mapping, by separating the mapping layer into two independent parts. This model allows the expressive use of different input devices within the same architecture, or conversely, the use of different synthesis algorithms, by only changing one part of the mapping layer.},
	language = {en},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Hunt, Andy and Wanderley, Marcelo M and Kirk, Ross},
	year = {2000},
	pages = {4},
	file = {HUNT - Towards a Model for Instrumental Mapping in Expert Musical Interaction.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/HUNT - Towards a Model for Instrumental Mapping in Expert Musical Interaction.pdf:application/pdf}
}

@article{fels_designing_2004,
	title = {Designing for {Intimacy}: {Creating} {New} {Interfaces} for {Musical} {Expression}},
	volume = {92},
	issn = {0018-9219},
	shorttitle = {Designing for {Intimacy}},
	url = {http://ieeexplore.ieee.org/document/1278690/},
	doi = {10.1109/JPROC.2004.825887},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {Proceedings of the IEEE},
	author = {Fels, S.},
	month = apr,
	year = {2004},
	pages = {672--685},
	file = {2004.Fels.DesigningForIntimacy_NIME.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_IEEE/2004.Fels.DesigningForIntimacy_NIME.pdf:application/pdf}
}

@article{wanderley_gestural_2004,
	title = {Gestural {Control} of {Sound} {Synthesis}},
	volume = {92},
	issn = {0018-9219},
	url = {http://ieeexplore.ieee.org/document/1278687/},
	doi = {10.1109/JPROC.2004.825882},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {Proceedings of the IEEE},
	author = {Wanderley, M.M. and Depalle, P.},
	month = apr,
	year = {2004},
	pages = {632--644},
	file = {2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_IEEE/2004.Wanderley_DePalle.GesturalControlOfSoundSynthesis.pdf:application/pdf}
}

@inproceedings{winkler_real-time_2004,
	address = {Paris},
	title = {The real-time score. {A} missing-link in computer-music performance},
	abstract = {Between the realms of improvisation and the execution of a paperwritten, fixed score the concept of RealtimeScore opens a kind of "Third Way" of interpretation.},
	language = {en},
	booktitle = {Proceedings of the {Sound} and music computing conference},
	author = {Winkler, Gerhard E},
	year = {2004},
	pages = {6},
	file = {2004.Winkler-THE  REALTIME-SCORE. A MISSING-LINK IN COMPUTER-MUSIC PERFORMANCE.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/2004.Winkler-THE  REALTIME-SCORE. A MISSING-LINK IN COMPUTER-MUSIC PERFORMANCE.pdf:application/pdf}
}

@article{vickery_limitations_2014,
	title = {The {Limitations} of {Representing} {Sound} and {Notation} on {Screen}},
	volume = {19},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S135577181400020X/type/journal_article},
	doi = {10.1017/S135577181400020X},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Vickery, Lindsay},
	month = dec,
	year = {2014},
	pages = {215--227},
	file = {2014.Vickery.The_Limitations_of_Representing_Sound_and_Notation_on_Screendiv.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2014/cambridge-core_mediation-notation-and-communication-in-electroacoustic-music-performance_1Dec2017/2014.Vickery.The_Limitations_of_Representing_Sound_and_Notation_on_Screendiv.pdf:application/pdf}
}

@phdthesis{bin_show_2018,
	address = {London},
	title = {The {Show} {Must} {Go} {Wrong}: {Towards} an understanding of audience perception of error in digital musical instrument performance},
	abstract = {This thesis is about DMI (digital musical instrument) performance, its audiences, and their perception of error. The goal of this research is to improve current understanding of how audiences perceive DMI performance, where performers and their audiences often have no shared, external frame of reference with which to judge the musical output. Further complicating this audience-performer relationship are human-computer interaction (HCI) issues arising from the use of a computer as a musical instrument. In current DMI literature, there is little direct inquiry of audience perception on these issues. Error is an aspect of this kind of audience perception. Error, a condition reached by stepping out of bounds, appears at first to be a simple binary quantity, but the location and nature of those boundaries change with context. With deviation the locus of style and artistic progress, understanding how audiences perceive error has the potential to lend important insight to the cultural mechanics of DMI performance. In this thesis I describe the process of investigating audience perception and unpacking these issues through three studies. Each study examines the relative effects of various factors on audience perception — instrument familiarity and musical style, gesture size, and visible risk — using a novel methodology combining real-time data collected by mobile phone, and post- hoc data in the form of written surveys. The results have implications for DMI and HCI researchers as well as DMI performers and composers, and contribute insights on these confounding factors from the audience’s perspective as well as important insights on audience perception of error in this context. Further, through this thesis I contribute a practical method and tool that can be used to continue this audience-focused work in the future.},
	language = {en},
	school = {Queen Mary University of London},
	author = {Bin, S. M. Astrid},
	month = may,
	year = {2018},
	file = {2018.PhD.Bin.ShowMustGoWrong.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2018.PhD.Bin.ShowMustGoWrong.pdf:application/pdf}
}

@article{arfib_strategies_2002,
	title = {Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002054/type/journal_article},
	doi = {10.1017/S1355771802002054},
	abstract = {This paper is about mapping strategies between gesture data and synthesis model parameters by means of perceptual spaces. We define three layers in the mapping chain: from gesture data to gesture perceptual space, from sound perceptual space to synthesis model parameters, and between the two perceptual spaces. This approach makes the implementation highly modular. Both perceptual spaces are developed and depicted with their features. To get a simple mapping between the gesture perceptual subspace and the sound perceptual subspace, we need to focus our attention on the two other mappings. We explain the mapping types: explicit/implicit, static/dynamic. We also present the technical and esthetical limits introduced by mapping. Some practical examples are given of the use of perceptual spaces in experiments done at LMA in a musical context. Finally, we discuss several implications of the mapping strategies: the influence of chosen mapping limits onto performers’ virtuosity, and the incidence of mapping on the learning process with virtual instruments and on improvisation possibilities.},
	language = {en},
	number = {2},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Arfib, D. and Couturier, J. M. and Kessous, L. and Verfaille, V.},
	month = aug,
	year = {2002},
	pages = {127--144},
	file = {ARFIB - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/ARFIB - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:application/pdf}
}

@incollection{cance_what_2012,
	title = {What is intrumentality in new digital musical devices ? {A} contribution from cognitive linguistics \& psychology},
	language = {en},
	booktitle = {La musique et ses instruments},
	author = {Cance, Caroline and Genevois, Hugues and Dubois, Danièle},
	year = {2012},
	pages = {283--298},
	file = {CIM_Article_Cance_al.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CIM/CIM_Article_Cance_al.pdf:application/pdf}
}

@article{cascone_aesthetics_2000,
	title = {The {Aesthetics} of {Failure}: “{Post}-{Digital}” {Tendencies} in {Contemporary} {Computer} {Music}},
	volume = {24},
	language = {en},
	number = {4},
	journal = {Computer Music Journal},
	author = {Cascone, Kim},
	year = {2000},
	pages = {7},
	file = {CMJ24_4_Cascone_Aesthetics of failure.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/CMJ24_4_Cascone_Aesthetics of failure.pdf:application/pdf}
}

@book{mcneill_gesture_2005,
	address = {Chicago},
	title = {Gesture and thought},
	isbn = {978-0-226-51462-8},
	language = {en},
	publisher = {University of Chicago Press},
	author = {McNeill, David},
	year = {2005},
	keywords = {Gesture, Language and languages, Psycholinguistics, Sign language, Speech, Thought and thinking},
	file = {David McNeill - Gesture and Thought (2005, University Of Chicago Press).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/McNeill, David/David McNeill - Gesture and Thought (2005, University Of Chicago Press).pdf:application/pdf}
}

@article{magnusson_scoring_2014,
	title = {Scoring with {Code}: {Composing} with algorithmic notation},
	volume = {19},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Scoring with {Code}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771814000259/type/journal_article},
	doi = {10.1017/S1355771814000259},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Magnusson, Thor},
	month = dec,
	year = {2014},
	pages = {268--275},
	file = {div_classtitleScoring_with_Code_Composing_with_algorithmic_notationdiv.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2014/cambridge-core_mediation-notation-and-communication-in-electroacoustic-music-performance_1Dec2017/div_classtitleScoring_with_Code_Composing_with_algorithmic_notationdiv.pdf:application/pdf}
}

@incollection{kronland-martinet_emergent_2008,
	address = {Berlin, Heidelberg},
	title = {Emergent {Rhythms} through {Multi}-agency in {Max}/{MSP}},
	volume = {4969},
	isbn = {978-3-540-85034-2 978-3-540-85035-9},
	url = {http://link.springer.com/10.1007/978-3-540-85035-9_26},
	abstract = {This paper presents a multi-agents architecture created in Max/MSP that generates polyphonic rhythmic patterns which continuously evolve and develop in a musically intelligent manner. Agent-based software offers a new method for real-time composition that allows for complex interactions between individual voices while requiring very little user interaction or supervision. The system described, Kinetic Engine is an environment in which networked computers, using individual software agents, emulate drummers improvising within a percussion ensemble. Player agents assume roles and personalities within the ensemble, and communicate with one another to create complex rhythmic interactions. The software has been premiered in a recent work, Drum Circle, which is briefly described.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {Computer {Music} {Modeling} and {Retrieval}. {Sense} of {Sounds}},
	publisher = {Springer Berlin Heidelberg},
	author = {Eigenfeldt, Arne},
	editor = {Kronland-Martinet, Richard and Ystad, Sølvi and Jensen, Kristoffer},
	year = {2008},
	doi = {10.1007/978-3-540-85035-9_26},
	pages = {368--379},
	file = {emergent_rhythms_maxmsp.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/emergent_rhythms_maxmsp.pdf:application/pdf}
}

@incollection{orlarey_faust_2008,
	address = {Paris, France},
	title = {{FAUST} : an {Efficient} {Functional} {Approach} to {DSP} {Programming}},
	volume = {290},
	abstract = {FAUST is a programming language that provides a purely functional approach to signal processing while offering a high level of performance. FAUST aims at being complemen-tary to existing audio languages by offering a viable and efficient alternative to C/C++ to develop signal processing libraries, audio plug-ins or standalone applications. The language is based on a simple and well defined formal semantics. A FAUST pro-gram denotes a signal processor, a mathematical function that transforms input signals into output signals. Being able to know precisely what a program computes is important not only for programmers, but also for compilers needing to generate the best possible code. Moreover these semantics questions are crucial for the long-term preservation of music programs 1 . The following paragraphs will give an overview of the language as well as a description of the compiler, including the generation of parallel code.},
	language = {en},
	booktitle = {New {Computational} {Paradigms} for {Computer} {Music}},
	publisher = {Delatour},
	author = {Orlarey, Yann and Fober, Dominique and Letz, Stephane},
	year = {2008},
	pages = {33},
	file = {FAUST_an_Efficient_Functional_Approach_to_DSP_Prog.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/IRCAM/New paradigms for computer music/FAUST_an_Efficient_Functional_Approach_to_DSP_Prog.pdf:application/pdf}
}

@article{born_musical_2005,
	title = {On {Musical} {Mediation}: {Ontology}, {Technology} and {Creativity}},
	volume = {2},
	issn = {1478-5722, 1478-5730},
	shorttitle = {On {Musical} {Mediation}},
	url = {https://www.cambridge.org/core/product/identifier/S147857220500023X/type/journal_article},
	doi = {10.1017/S147857220500023X},
	abstract = {This article develops a theoretical analysis of music and mediation, building on the work of Theodor Adorno, Tia DeNora and Antoine Hennion. It begins by suggesting that Lydia Goehr’s account of the work concept requires such a perspective. Drawing on Alfred Gell’s anthropology of art, the article outlines an approach to mediation that incorporates understandings of music’s social, technological and temporal dimensions. It suggests that music’s mediations have taken a number of historical forms, which cohere into assemblages, and that we should be alert to shifts in the dominant forms of musical assemblage. In the latter part of the article, these tools are used to conceptualize changing forms of musical creativity that emerged over the twentieth century. A comparison is made between the work concept and jazz and improvised electronic musics. Three contemporary digital music experiments are discussed in detail, demonstrating the concepts of the provisional work and of social, distributed and relayed creativity. Throughout, key motifs are mediation, creativity, and the negotiation of difference.},
	language = {en},
	number = {1},
	urldate = {2019-05-23},
	journal = {Twentieth-Century Music},
	author = {Born, Georgina},
	month = mar,
	year = {2005},
	pages = {7--36},
	file = {GeorginaBorn_On Musical Mediation Ontology Technology and Creativity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CambridgeTwentiethCenturyMusic/GeorginaBorn_On Musical Mediation Ontology Technology and Creativity.pdf:application/pdf}
}

@article{goudeseune_interpolated_2002,
	title = {Interpolated mappings for musical instruments},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002029/type/journal_article},
	doi = {10.1017/S1355771802002029},
	language = {en},
	number = {2},
	urldate = {2019-05-23},
	journal = {Organised Sound},
	author = {Goudeseune, Camille},
	month = aug,
	year = {2002},
	pages = {85--96},
	file = {GOUDESEUNE - Interpolated Mappings for Musical Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_INTERP/GOUDESEUNE - Interpolated Mappings for Musical Instruments.pdf:application/pdf}
}

@article{hunt_mapping_2000,
	title = {Mapping {Strategies} for {Musical} {Performance}},
	language = {en},
	author = {Hunt, Andy and Kirk, Ross},
	year = {2000},
	pages = {28},
	file = {HUNT - Mapping strategies for musical performance.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/HUNT - Mapping strategies for musical performance.pdf:application/pdf}
}

@article{schloss_using_2003,
	title = {Using {Contemporary} {Technology} in {Live} {Performance}: {The} {Dilemma} of the {Performer}},
	volume = {32},
	issn = {0929-8215},
	shorttitle = {Using {Contemporary} {Technology} in {Live} {Performance}},
	url = {http://www.tandfonline.com/doi/abs/10.1076/jnmr.32.3.239.16866},
	doi = {10.1076/jnmr.32.3.239.16866},
	abstract = {The use of computers in live performance has resulted in a situation in which cause-and-effect has effectively disappeared, for the ﬁrst time since music began. Once we started to use computers in live performance – to interpret abstract gestures and generate sound as a result – the age-old relationship between gesture and result became so blurred as to be often imperceptible. In historical terms, this problem is extremely recent, involving only the last few decades of musical practice preceded by at least thirty thousand years of music-making by conventional (acoustic) means. The aim of this paper is to show how this affects contemporary performance and the relationship between the performer and the audience.},
	language = {en},
	number = {3},
	urldate = {2019-05-23},
	journal = {Journal of New Music Research},
	author = {Schloss, W. Andrew},
	month = sep,
	year = {2003},
	pages = {239--242},
	file = {JNMR02.Schloss.Dilemma_of_the_Performer.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JNMR_JournalOfNewMusicResearch/JNMR02.Schloss.Dilemma_of_the_Performer.pdf:application/pdf}
}

@book{butler_playing_2014,
	address = {New York},
	title = {Playing with something that runs: technology, improvisation, and composition in {DJ} and laptop performance},
	isbn = {978-0-19-539361-3 978-0-19-539362-0},
	shorttitle = {Playing with something that runs},
	language = {en},
	publisher = {Oxford University Press},
	author = {Butler, Mark J.},
	year = {2014},
	keywords = {History and criticism, Electronic dance music, Production and direction},
	file = {Mark J. Butler-Playing with Something That Runs_ Technology, Improvisation, and Composition in DJ and Laptop Performance-Oxford University Press (2014).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Butler, Mark J./Mark J. Butler-Playing with Something That Runs_ Technology, Improvisation, and Composition in DJ and Laptop Performance-Oxford University Press (2014).pdf:application/pdf}
}

@inproceedings{zbyszynski_ten_2007,
	address = {New York, New York},
	title = {Ten years of tablet musical interfaces at {CNMAT}},
	url = {http://portal.acm.org/citation.cfm?doid=1279740.1279758},
	doi = {10.1145/1279740.1279758},
	abstract = {We summarize a decade of musical projects and research employing Wacom digitizing tablets as musical controllers, discussing general implementation schemes using Max/MSP and OpenSoundControl, and specific implementations in musical improvisation, interactive sound installation, interactive multimedia performance, and as a compositional assistant. We examine two-handed sensing strategies and schemes for gestural mapping.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {Proceedings of the 7th international conference on {New} interfaces for musical expression - {NIME} '07},
	publisher = {ACM Press},
	author = {Zbyszynski, Michael and Wright, Matthew and Momeni, Ali and Cullen, Daniel},
	year = {2007},
	pages = {100},
	file = {nime2007_100.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2007/nime2007_100.pdf:application/pdf}
}

@article{canonne_improvisation_2012,
	title = {Improvisation collective libre et processus de création musicale: création et créativité au prisme de la coordination},
	language = {fr},
	number = {1},
	journal = {Revue de musicologie},
	author = {Canonne, Clément},
	year = {2012},
	pages = {42},
	file = {Rdm-98-2-Canonne_ImprovisationCollectiveLibre.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue_de_Musicologie/Rdm-98-2-Canonne_ImprovisationCollectiveLibre.pdf:application/pdf}
}

@incollection{ungvary_cognition_1999,
	address = {Paris},
	title = {Cognition and {Physicality} in {Musical} {CyberInstruments}},
	language = {en},
	booktitle = {Trends in {Gestural} {Control} of {Music}},
	publisher = {IRCAM, Centre Pompidou},
	author = {Ungvary, Tamas and Vertegaal, Roel},
	editor = {Wanderley, Marcelo M and Battier, Marc},
	year = {1999},
	pages = {371--386},
	file = {UNGVARY VERTEGAAL Cognition and Physicality in Musical Cyberinstruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/UNGVARY VERTEGAAL Cognition and Physicality in Musical Cyberinstruments.pdf:application/pdf}
}

@inproceedings{wanderley_escher-modeling_1998,
	address = {San Diego, CA, USA},
	title = {{ESCHER}-modeling and performing composed instruments in real-time},
	volume = {2},
	isbn = {978-0-7803-4778-6},
	url = {http://ieeexplore.ieee.org/document/727836/},
	doi = {10.1109/ICSMC.1998.727836},
	abstract = {This article presents ESCHER, a sound synthesis environment based on IrcamÕs real-time audio environment jMax. ESCHER is a modular system providing synthesis-independent prototyping of gesturally-controlled instruments by means of parameter interpolation. The system divides into two components: gestural controller and synthesis engine. Mapping between components takes place on two independent levels, coupled by an intermediate abstract parameter layer. This separation allows a flexible choice of controllers and/or sound synthesis methods.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {{SMC}'98 {Conference} {Proceedings}. 1998 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({Cat}. {No}.98CH36218)},
	publisher = {IEEE},
	author = {Wanderley, M.M. and Schnell, N. and Rovan, J.},
	year = {1998},
	pages = {1080--1084},
	file = {WANDERLEY - Escher.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_INSTRU/WANDERLEY - Escher.pdf:application/pdf}
}

@article{mccartney_rethinking_2002,
	title = {Rethinking the {Computer} {Music} {Language}: {SuperCollider}},
	volume = {26},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Rethinking the {Computer} {Music} {Language}},
	url = {http://www.mitpressjournals.org/doi/10.1162/014892602320991383},
	doi = {10.1162/014892602320991383},
	language = {en},
	number = {4},
	urldate = {2019-05-23},
	journal = {Computer Music Journal},
	author = {McCartney, James},
	month = dec,
	year = {2002},
	pages = {61--68},
	file = {McCartney - 2002 - Rethinking the Computer Music Language SuperColli.pdf:/Users/vg/Zotero/storage/JG5569KJ/McCartney - 2002 - Rethinking the Computer Music Language SuperColli.pdf:application/pdf;mccartney2002.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/mccartney2002.pdf:application/pdf}
}

@article{fels_mapping_2002,
	title = {Mapping transparency through metaphor: towards more expressive musical instruments},
	volume = {7},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Mapping transparency through metaphor},
	url = {https://www.cambridge.org/core/product/identifier/S1355771802002042/type/journal_article},
	doi = {10.1017/S1355771802002042},
	abstract = {We define a two-axis transparency framework that can be used as a predictor of the expressivity of a musical device. One axis is the player's transparency scale, while the other is the audience's transparency scale. Through consideration of both traditional instrumentation and new technology-driven interfaces, we explore the role that metaphor plays in developing expressive devices. Metaphor depends on a literature, which forms the basis for making transparent device mappings. We examine four examples of systems that use metaphor: Iamascope, Sound Sculpting, MetaMuse, and Glove-TalkII; and discuss implications on transparency and expressivity. We believe this theory provides a framework for design and evaluation of new human-machine and humanhuman interactions, including musical instruments.},
	language = {en},
	number = {2},
	urldate = {2019-05-24},
	journal = {Organised Sound},
	author = {Fels, Sidney and Gadd, Ashley and Mulder, Axel},
	month = aug,
	year = {2002},
	pages = {109--126},
	file = {2002.OS.Fels.Mapping Transparency through Metaphor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2002/2002.OS.Fels.Mapping Transparency through Metaphor.pdf:application/pdf}
}

@inproceedings{bin_risky_2018,
	address = {Blacksburg, Virginia, USA},
	title = {Risky business: {Disfluency} as a design strategy},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0012.pdf},
	abstract = {This paper presents a study examining the effects of disfluent design on audience perception of digital musical instrument (DMI) performance. Disfluency, defined as a barrier to effortless cognitive processing, has been shown to generate better results in some contexts as it engages higher levels of cognition. We were motivated to determine if disfluent design in a DMI would result in a risk state that audiences would be able to perceive, and if this would have any effect on their evaluation of the performance. A DMI was produced that incorporated a disfluent characteristic: It would turn itself off if not constantly moved. Six physically identical instruments were produced, each in one of three versions: Control (no disfluent characteristics), mild disfluency (turned itself off slowly), and heightened disfluency (turned itself off more quickly). 6 percussionists each performed on one instrument for a live audience (N=31), and data was collected in the form of real-time feedback (via a mobile phone app), and post-hoc surveys. Though there was little difference in ratings of enjoyment between the versions of the instrument, the real-time and qualitative data suggest that disfluent behaviour in a DMI may be a way for audiences to perceive and appreciate performer skill.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Bin, S. M. Astrid and Bryan-Kinns, Nick and McPherson, Andrew P.},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {45--50},
	file = {nime2018_paper0012.Bin.DisfluencyAsADesignStrategy.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/nime2018_paper0012.Bin.DisfluencyAsADesignStrategy.pdf:application/pdf}
}

@inproceedings{marquez-borbon_problem_2018,
	address = {Blacksburg, Virginia, USA},
	title = {The {Problem} of {DMI} {Adoption} and {Longevity}: {Envisioning} a {NIME} {Performance} {Pedagogy}},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0040.pdf},
	abstract = {This paper addresses the prevailing longevity problem of digital musical instruments (DMIs) in NIME research and design by proposing a holistic system design approach. Despite recent efforts to examine the main contributing factors of DMI falling into obsolescence, such attempts to remedy this issue largely place focus on the artifacts establishing themselves, their design processes and technologies. However, few existing studies have attempted to proactively build a community around technological platforms for DMIs, whilst bearing in mind the social dynamics and activities necessary for a budding community. We observe that such attempts while important in their undertaking, are limited in their scope. In this paper we will discuss that achieving some sort of longevity must be addressed beyond the device itself and must tackle broader ecosystemic factors. We hypothesize, that a longevous DMI design must not only take into account a target community but it may also require a non-traditional pedagogical system that sustains artistic practice.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Marquez-Borbon, Adnan and Martinez-Avila, Juan Pablo},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {190--195},
	file = {2018.MarquezBorbon-DMI Adoption and Longevity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/2018.MarquezBorbon-DMI Adoption and Longevity.pdf:application/pdf}
}

@inproceedings{robertson_harmonic_2018,
	address = {Blacksburg, Virginia, USA},
	title = {Harmonic {Wand}: {An} {Instrument} for {Microtonal} {Control} and {Gestural} {Excitation}},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0017.pdf},
	abstract = {The Harmonic Wand is a transducer-based instrument that combines physical excitation, synthesis, and gestural control. Our objective was to design a device that affords exploratory modes of interaction with the performer’s surroundings, as well as precise control over microtonal pitch content and other concomitant parameters. The instrument is comprised of a hand-held wand, containing two piezo-electric transducers affixed to a pair of metal probes. The performer uses the wand to physically excite surfaces in the environment and capture resultant signals. Input materials are then processed using a novel application of Karplus-Strong synthesis, in which these impulses are imbued with discrete resonances. We achieved gestural control over synthesis parameters using a secondary tactile interface, consisting of four force-sensitive resistors (FSR), a fader, and momentary switch. As a unique feature of our instrument, we modeled pitch organization and associated parametric controls according to theoretical principles outlined in Harry Partch’s “monophonic fabric” of Just Intonation—specifically his conception of odentities, udentities, and a variable numerary nexus. This system classifies pitch content based upon intervallic structures found in both the overtone and undertone series. Our paper details the procedural challenges in designing the Harmonic Wand.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Robertson, Ben Luca and Dahl, Luke},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {72--77}
}

@inproceedings{tahiroglu_contextualising_2018,
	address = {Blacksburg, Virginia, USA},
	title = {Contextualising {Idiomatic} {Gestures} in {Musical} {Interactions} with {NIMEs}},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0028.pdf},
	abstract = {This paper introduces various ways that idiomatic gestures emerge in performance practice with new musical instruments. It demonstrates that idiomatic gestures can play an important role in the development of personalized performance practices that can be the basis for the development of style and expression. Three detailed examples – biocontrollers, accordion-inspired instruments, and a networked intelligent controller – illustrate how a complex suite of factors throughout the design, composition and performance processes can influence the development of idiomatic gestures. We argue that the explicit consideration of idiomatic gestures throughout the life cycle of new instruments can facilitate the emergence of style and give rise to performances that can develop rich layers of meaning.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Tahiroglu, Koray and Gurevich, Michael and Knapp, R. Benjamin},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {126--131},
	file = {nime2018_paper0028.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/nime2018_paper0028.pdf:application/pdf}
}

@inproceedings{cantrell_designing_2017,
	address = {Copenhagen, Denmark},
	title = {Designing {Intent}: {Defining} {Critical} {Meaning} for {NIME} {Practitioners}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0032.pdf},
	abstract = {The ideation, conception and implementation of new musical interfaces and instruments provide more than the mere construction of digital objects. As physical and digital assemblages, interfaces also act as traces of the authoring entities that created them. Their intentions, likes, dislikes, and ultimate determinations of what is creatively useful all get embedded into the available choices of the interface. In this light, the self-perception of the musical HCI and instrument designer can be seen as occupying a primary importance in the instruments and interfaces that eventually come to be created. The work of a designer who self-identifies as an artist may result in a vastly different outcome than one who considers him or herself to be an entrepreneur, or a scientist, for example. These differing definitions of self as well as their HCI outcomes require their own means of critique, understanding and expectations. All too often, these definitions are unclear, or the considerations of overlapping means of critique remain unexamined.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Cantrell, Joe},
	year = {2017},
	pages = {169--173},
	file = {2017.Cantrell_Social Life Of Musical Instruments_nime2017_paper0032.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/2017.Cantrell_Social Life Of Musical Instruments_nime2017_paper0032.pdf:application/pdf}
}

@inproceedings{donneaud_designing_2017,
	address = {Copenhagen, Denmark},
	title = {Designing a {Multi}-{Touch} {eTextile} for {Music} {Performances}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0002.pdf},
	abstract = {We present a textile pressure sensor matrix, designed to be used as a musical multi-touch input device. An evaluation of our design demonstrated that the sensors pressure response profile fits a logarithmic curve (R² = 0.98). The input delay of the sensor is 2.1ms. The average absolute error in one direction of the sensor was measured to be less than 10\% of one of the matrix’s strips (M = 1.8mm, SD = 1.37mm). We intend this technology to be easy to use and implement by experts and novices alike: We ensure the ease of use by providing a host application that tracks touch points and passes these on as OSC or MIDI messages. We make our design easy to implement by providing open source software and hardware and by choosing evaluation methods that use accessible tools, making quantitative comparisons between different branches of the design easy. We chose to work with textile to take advantage of its tactile properties and its malleability of form and to pay tribute to textile’s rich cultural heritage.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Donneaud, Maurin and Honnet, Cedric and Strohmeier, Paul},
	year = {2017},
	pages = {7--12}
}

@inproceedings{mehes_virtual-acoustic_2017,
	address = {Copenhagen, Denmark},
	title = {Virtual-{Acoustic} {Instrument} {Design}: {Exploring} the {Parameter} {Space} of a {String}-{Plate} {Model}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0075.pdf},
	abstract = {Exploration is an intrinsic element of designing and engaging with acoustic as well as digital musical instruments. This paper reports on the ongoing development of a virtual-acoustic instrument based on a physical model of a string coupled nonlinearly to a plate. The performer drives the model by tactile interaction with a string-board controller fitted with piezo-electric sensors. The string-plate model is formulated in a way that prioritises its parametric explorability. Where the roles of creating performance gestures and designing instruments are traditionally separated, such a design provides a continuum across these domains. The string-plate model, its real-time implementation, and the control interface are described, and the system is preliminarily evaluated through informal observations of how musicians engage with the system.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Mehes, Sandor and Walstijn, Maarten van and Stapleton, Paul},
	year = {2017},
	pages = {399--403}
}

@inproceedings{wicaksono_fabrickeyboard:_2017,
	address = {Copenhagen, Denmark},
	title = {{FabricKeyboard}: {Multimodal} {Textile} {Sensate} {Media} as an {Expressive} and {Deformable} {Musical} {Interface}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0066.pdf},
	abstract = {This paper presents FabricKeyboard: a novel deformable keyboard interface based on a multi-modal fabric sensate surface. Multi-layer fabric sensors that detect touch, proximity, electric field, pressure, and stretch are machine-sewn in a keyboard pattern on a stretchable substrate. The result is a fabric-based musical controller that combines both the discrete controls of a keyboard and various continuous controls from the embedded fabric sensors. This enables unique tactile experiences and new interactions both with physical and non-contact gestures: physical by pressing, pulling, stretching, and twisting the keys or the fabric and non-contact by hovering and waving towards/against the keyboard and an electromagnetic source. We have also developed additional fabric-based modular interfaces such as a ribbon-controller and trackpad, allowing performers to add more expressive and continuous controls. This paper will discuss implementation strategies for our system-on-textile, fabric-based sensor developments, as well as sensor-computer interfacing and musical mapping examples of this multi-modal and expressive fabric keyboard.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Wicaksono, Irmandy and Paradiso, Joseph},
	year = {2017},
	pages = {348--353}
}

@inproceedings{williams_pitch_2017,
	address = {Copenhagen, Denmark},
	title = {Pitch {Fork}: {A} {Novel} tactile {Digital} {Musical} {Instrument}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0013.pdf},
	abstract = {Pitch Fork is a prototype of an alternate, actuated digital musical instrument (DMI). It uses 5 infra-red and 4 piezoelectric sensors to control an additive synthesis engine. Iron bars are used as the physical point of contact in interaction with the aim of using material computation to control aspects of the digitally produced sound. This choice of material was also chosen to affect player experience. Sensor readings are relayed to a Macbook via an Arduino Mega. Mappings and audio output signal is carried out with Pure Data Extended.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Williams, Peter and Overholt, Daniel},
	year = {2017},
	pages = {62--64}
}

@inproceedings{haddad_fragile_2017,
	address = {Copenhagen, Denmark},
	title = {Fragile {Instruments}: {Constructing} {Destructible} {Musical} {Interfaces}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0006.pdf},
	abstract = {We introduce a family of fragile electronic musical instruments designed to be "played” through the act of destruction. Each Fragile Instrument consists of an analog synthesizing circuit with embedded sensors that detect the destruction of an outer shell, which is destroyed and replaced for each performance. Destruction plays an integral role in both the spectacle and the generated sounds. This paper presents several variations of Fragile Instruments we have created, discussing their circuit design as well as choices of material for the outer shell and tools of destruction. We conclude by considering other approaches to create intentionally destructible electronic musical instruments.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Haddad, Don Derek and Xiao, Xiao and Machover, Tod and Paradiso, Joseph},
	year = {2017},
	pages = {30--33}
}

@inproceedings{morreale_design_2017,
	address = {Copenhagen, Denmark},
	title = {Design for {Longevity}: {Ongoing} {Use} of {Instruments} from {NIME} 2010-14},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0036.pdf},
	abstract = {Every new edition of NIME brings dozens of new DMIs and the feeling that only a few of them will eventually break through. Previous work tried to address this issue with a deductive approach by formulating design frameworks; we addressed this issue with a inductive approach by elaborating on successes and failures of previous DMIs. We contacted 97 DMI makers that presented a new instrument at five successive editions of NIME (2010-2014); 70 answered. They were asked to indicate the original motivation for designing the DMI and to present information about its uptake. Results confirmed that most of the instruments have difficulties establishing themselves. Also, they were asked to reflect on the specific factors that facilitated and those that hindered instrument longevity. By grounding these reflections on existing reserach on NIME and HCI, we propose a series of design considerations for future DMIs.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Morreale, Fabio and McPherson, Andrew},
	year = {2017},
	pages = {192--197},
	file = {2017.Morreale Design for Longevity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/2017.Morreale Design for Longevity.pdf:application/pdf}
}

@inproceedings{berthaut_liveness_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Liveness {Through} the {Lens} of {Agency} and {Causality}},
	url = {http://www.nime.org/proceedings/2015/nime2015_272.pdf},
	abstract = {Liveness is a well-known problem with Digital Musical Instruments (DMIs). When used in performances, DMIs provide less visual information than acoustic instruments, preventing the audience from understanding how the musicians influence the music. In this paper, we look at this issue through the lens of causality. More specifically, we investigate the attribution of causality by an external observer to a performer, relying on the theory of apparent mental causation. We suggest that the perceived causality between a performer's gestures and the musical result is central to liveness. We present a framework for assessing attributed causality and agency to a performer, based on a psychological theory which suggests three criteria for inferred causality. These criteria then provide the basis of an experimental study investigating the effect of visual augmentations on audience's inferred causality. The results provide insights on how the visual component of performances with DMIs impacts the audience's causal inferences about the performer. In particular we show that visual augmentations help highlight the influence of the musician when parts of the music are automated, and help clarify complex mappings between gestures and sounds. Finally we discuss the potential wider implications for assessing liveness in the design of new musical interfaces.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Berthaut, Florent and Coyle, David and Moore, James and Limerick, Hannah},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {382--386},
	file = {nime2015_272.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2015/nime2015_272.pdf:application/pdf}
}

@inproceedings{mcpherson_exposing_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Exposing the {Scaffolding} of {Digital} {Instruments} with {Hardware}-{Software} {Feedback} {Loops}},
	url = {http://www.nime.org/proceedings/2015/nime2015_258.pdf},
	abstract = {The implementation of digital musical instruments is often opaque to the performer. Even when the relationship between action and sound is readily understandable, the internal hardware or software operations that create that relationship may be inaccessible to scrutiny or modification. This paper presents a new approach to digital instrument design which lets the performer alter and subvert the instrument's internal operation through circuit-bending techniques. The approach uses low-latency feedback loops between software and analog hardware to expose the internal working of the instrument. Compared to the standard control voltage approach used on analog synths, alterations to the feedback loops produce distinctive and less predictable changes in behaviour with original artistic applications. This paper discusses the technical foundations of the approach, its roots in hacking and circuit bending, and case studies of its use in live performance with the D-Box hackable instrument.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {McPherson, Andrew and Zappi, Victor},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {162--167}
}

@inproceedings{myllykoski_prototyping_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Prototyping hand-based wearable music education technology},
	url = {http://www.nime.org/proceedings/2015/nime2015_151.pdf},
	abstract = {This paper discusses perspectives for conceptualizing and developing hand-based wearable musical interface. Previous implementations of such interfaces have not been targeted for music pedagogical use. We propose principles for pedagogically oriented `musical hand' and outline its development through the process of prototyping, which involves a variety of methods. The current functional prototype, a touch-based musical glove, is presented.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Myllykoski, Mikko and Tuuri, Kai and Viirret, Esa and Louhivuori, Jukka and Peltomaa, Antti and Kekäläinen, Janne},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {182--183},
	file = {nime2015_151.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2015/nime2015_151.pdf:application/pdf}
}

@inproceedings{bowers_hybrid_2014,
	address = {London, United Kingdom},
	title = {Hybrid {Resonant} {Assemblages}: {Rethinking} {Instruments}, {Touch} and {Performance} in {New} {Interfaces} for {Musical} {Expression}},
	url = {http://www.nime.org/proceedings/2014/nime2014_438.pdf},
	abstract = {This paper outlines a concept of hybrid resonant assemblages, combinations of varied materials excited by sound transducers, feeding back to themselves via digital signal processing. We ground our concept as an extension of work by David Tudor, Nicolas Collins and Bowers and Archer [NIME 2005] and draw on a variety of critical perspectives in the social sciences and philosophy to explore such assemblages as an alternative to more familiar ideas of instruments and interfaces. We lay out a conceptual framework for the exploration of hybrid resonant assemblages and describe how we have approached implementing them. Our performance experience is presented and implications for work are discussed. In the light of our work, we urge a reconsideration of the implicit norms of performance which underlie much research in NIME. In particular, drawing on the philosophical work of Jean-Luc Nancy, we commend a wider notion of touch that also recognises the performative value of withholding contact.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Bowers, John and Haas, Annika},
	month = jun,
	year = {2014},
	pages = {7--12},
	file = {2014.Bowers.Hybrid Resonant assemblages_nime2014_438.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/2014.Bowers.Hybrid Resonant assemblages_nime2014_438.pdf:application/pdf}
}

@inproceedings{jensenius_gesture_2014,
	address = {London, United Kingdom},
	title = {To gesture or {Not}? {An} {Analysis} of {Terminology} in {NIME} {Proceedings} 2001–2013},
	url = {http://www.nime.org/proceedings/2014/nime2014_351.pdf},
	abstract = {The term 'gesture' has represented a buzzword in the NIME community since the beginning of its conference series. But how often is it actually used, what is it used to describe, and how does its usage here differ from its usage in other fields of study? This paper presents a linguistic analysis of the motion-related terminology used in all of the papers published in the NIME conference proceedings to date (2001-2013). The results show that 'gesture' is in fact used in 62 \% of all NIME papers, which is a significantly higher percentage than in other music conferences (ICMC and SMC), and much more frequently than it is used in the HCI and biomechanics communities. The results from a collocation analysis support the claim that 'gesture' is used broadly in the NIME community, and indicate that it ranges from the description of concrete human motion and system control to quite metaphorical applications.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Jensenius, Alexander Refsum},
	month = jun,
	year = {2014},
	pages = {217--220}
}

@inproceedings{mamedes_composing_2014,
	address = {London, United Kingdom},
	title = {Composing for {DMIs} {Entoa}, a {Dedicate} {Piece} for {Intonaspacio}},
	url = {http://www.nime.org/proceedings/2014/nime2014_411.pdf},
	abstract = {Digital Musical Instruments (DMIs) have difficulties establishing themselves after their creation. A huge number of DMIs is presented every year and few of them actually remain in use. Several causes could explain this reality, among them the lack of a proper instrumental technique, inadequacy of the traditional musical notation and the non-existence of a repertoire dedicated to the instrument. In this paper we present Entoa, the first written music for Intonaspacio, a DMI we designed in our research project. We propose some strategies for mapping data from sensors to sound processing, in order to accomplish an expressive performance. Entoa is divided in five different sections that corresponds to five movements. For each, a different mapping is designed, introducing subtle alterations that progressively explore the ensemble of features of the instrument. The performer is then required to adapt his repertoire of gestures along the piece. Indications are expressed through a gestural notation, where freedom is give to performer to control certain parameters at specific moments in the music.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Mamedes, Clayton and Rodrigues, Mailis and Wanderley, Marcelo M. and Manzolli, Jônatas and Garcia, Denise H. L. and Ferreira-Lopes, Paulo},
	month = jun,
	year = {2014},
	pages = {509--512},
	file = {nime2014_411_Mamedes_Composing_for_entoa.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_411_Mamedes_Composing_for_entoa.pdf:application/pdf}
}

@inproceedings{schwarz_rich_2014,
	address = {London, United Kingdom},
	title = {Rich {Contacts}: {Corpus}-{Based} {Convolution} of {Contact} {Interaction} {Sound} for {Enhanced} {Musical} {Expression}},
	url = {http://www.nime.org/proceedings/2014/nime2014_451.pdf},
	abstract = {We propose ways of enriching the timbral potential of gestural sonic material captured via piezo or contact microphones, through latency-free convolution of the microphone signal with grains from a sound corpus. This creates a new way to combine the sonic richness of large sound corpora, easily accessible via navigation through a timbral descriptor space, with the intuitive gestural interaction with a surface, captured by any contact microphone. We use convolution to excite the grains from the corpus via the microphone input, capturing the contact interaction sounds, which allows articulation of the corpus by hitting, scratching, or strumming a surface with various parts of the hands or objects. We also show how changes of grains have to be carefully handled, how one can smoothly interpolate between neighbouring grains, and finally evaluate the system against previous attempts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Schwarz, Diemo and Tremblay, Pierre Alexandre and Harker, Alex},
	month = jun,
	year = {2014},
	pages = {247--250},
	file = {nime2014_451_Schwarz_Corpus-Based Convolution of Contact Interaction Sound for Enhanced Musical Expression.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_451_Schwarz_Corpus-Based Convolution of Contact Interaction Sound for Enhanced Musical Expression.pdf:application/pdf}
}

@inproceedings{serafin_controlling_2014,
	address = {London, United Kingdom},
	title = {Controlling {Physically} {Based} {Virtual} {Musical} {Instruments} {Using} {The} {Gloves}},
	url = {http://www.nime.org/proceedings/2014/nime2014_307.pdf},
	abstract = {In this paper we propose an empirical method to develop mapping strategies between a gestural based interface (the Gloves) and physically based sound synthesis models. An experiment was performed in order to investigate which kind of gestures listeners associate to synthesised sounds produced using physical models, corresponding to three categories of sound: sustained, iterative and impulsive. The results of the experiment show that listeners perform similar gestures when controlling sounds from the different categories. We used such gestures in order to create the mapping strategy between the Gloves and the physically based synthesis engine.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Serafin, Stefania and Trento, Stefano and Grani, Francesco and Perner-Wilson, Hannah and Madgwick, Seb and Mitchell, Tom},
	month = jun,
	year = {2014},
	pages = {521--524},
	file = {nime2014_307.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_307.pdf:application/pdf}
}

@inproceedings{tomas_tangible_2014,
	address = {London, United Kingdom},
	title = {Tangible {Scores}: {Shaping} the {Inherent} {Instrument} {Score}},
	url = {http://www.nime.org/proceedings/2014/nime2014_352.pdf},
	abstract = {Tangible Scores are a new paradigm for musical instrument design with a physical configuration inspired by graphic scores. In this paper we will focus on the design aspects of this new interface as well as on some of the related technical details. Creating an intuitive, modular and expressive instrument for textural music was the primary driving force. Following these criteria, we literally incorporated a musical score onto the surface of the instrument as a way of continuously controlling several parameters of the sound synthesis. Tangible Scores are played with both hands and they can adopt multiple physical forms. Complex and expressive sound textures can be easily played over a variety of timbres, enabling precise control in a natural manner.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Tomás, Enrique and Kaltenbrunner, Martin},
	month = jun,
	year = {2014},
	pages = {609--614},
	file = {nime2014_352.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_352.pdf:application/pdf}
}

@inproceedings{fried_cross-modal_2013,
	address = {Daejeon, Republic of Korea},
	title = {Cross-modal {Sound} {Mapping} {Using} {Deep} {Learning}},
	url = {http://nime.org/proceedings/2013/nime2013_111.pdf},
	abstract = {We present a method for automatic feature extraction and cross-modal mappingusing deep learning. Our system uses stacked autoencoders to learn a layeredfeature representation of the data. Feature vectors from two (or more)different domains are mapped to each other, effectively creating a cross-modalmapping. Our system can either run fully unsupervised, or it can use high-levellabeling to fine-tune the mapping according a user's needs. We show severalapplications for our method, mapping sound to or from images or gestures. Weevaluate system performance both in standalone inference tasks and incross-modal mappings.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Graduate School of Culture Technology, KAIST},
	author = {Fried, Ohad and Fiebrink, Rebecca},
	month = may,
	year = {2013},
	keywords = {mapping, gestural control, Deep learning, feature learning},
	pages = {531--534}
}

@inproceedings{fyans_ecological_2012,
	address = {Ann Arbor, Michigan},
	title = {Ecological considerations for participatory design of {DMIs}},
	url = {http://www.nime.org/proceedings/2012/nime2012_253.pdf},
	abstract = {A study is presented examining the participatory design of digital musical interactions. The study takes into consideration the entire ecology of digital musical interactions including the designer, performer and spectator. A new instrument is developed through iterative participatory design involving a group of performers. Across the study the evolution of creative practice and skill development in an emerging community of practice is examined and a spectator study addresses the cognition of performance and the perception of skill with the instrument. Observations are presented regarding the cognition of a novel interaction and evolving notions of skill. The design process of digital musical interactions is reflected on focusing on involvement of the spectator in design contexts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Fyans, A. Cavan and Marquez-Borbon, Adnan and Stapleton, Paul and Gurevich, Michael},
	year = {2012},
	keywords = {cognition, DMIs, participatory design, skill, spectator},
	file = {nime2012_253.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_253.pdf:application/pdf}
}

@inproceedings{savary_dirti_2012,
	address = {Ann Arbor, Michigan},
	title = {{DIRTI} —{Dirty} {Tangible} {Interfaces}},
	url = {http://www.nime.org/proceedings/2012/nime2012_212.pdf},
	abstract = {Dirty Tangible Interfaces (DIRTI) are a new concept in interface design that forgoes the dogma of repeatability in favor of a richer and more complex experience, constantly evolving, never reversible, and infinitely modifiable. We built a prototype based on granular or liquid interaction material placed in a glass dish, that is analyzed by video tracking for its 3D relief. This relief, and the dynamic changes applied to it by the user, are interpreted as activation profiles to drive corpus-based concatenative sound synthesis, allowing one or more players to mold sonic landscapes and to plow through them in an inherently collaborative, expressive, and dynamic experience.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Savary, Matthieu and Schwarz, Diemo and Pellerin, Denis},
	year = {2012},
	keywords = {Tangible interface, Corpus-based concatenative synthesis, Non-standard interaction},
	file = {nime2012_212.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_212.pdf:application/pdf}
}

@inproceedings{vigliensoni_quantitative_2012,
	address = {Ann Arbor, Michigan},
	title = {A {Quantitative} {Comparison} of {Position} {Trackers} for the {Development} of a {Touch}-less {Musical} {Interface}},
	url = {http://www.nime.org/proceedings/2012/nime2012_155.pdf},
	abstract = {This paper presents a comparison of three-dimensional (3D) position tracking systems in terms of some of their performance parameters such as static accuracy and precision, update rate, and shape of the space they sense. The underlying concepts and characteristics of position tracking tech-nologies are reviewed, and four position tracking systems (Vicon, Polhemus, Kinect, and Gametrak), based on dif-ferent technologies, are empirically compared according to their performance parameters and technical specifications. Our results show that, overall, the Vicon was the position tracker with the best performance.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Vigliensoni, Gabriel and Wanderley, Marcelo M.},
	year = {2012},
	keywords = {gestural control, comparison, Position tracker, touch-less},
	file = {nime2012_155.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_155.pdf:application/pdf}
}

@inproceedings{freed_composability_2011,
	address = {Oslo, Norway},
	title = {Composability for {Musical} {Gesture} {Signal} {Processing} using new {OSC}-based {Object} and {Functional} {Programming} {Extensions} to {Max}/{MSP}},
	url = {http://www.nime.org/proceedings/2011/nime2011_308.pdf},
	abstract = {An effective programming style for gesture signal processing is described using a new library that brings efficient run-time polymorphism, functional and instance-based object-oriented programming to Max/MSP. By introducing better support for generic programming and composability Max/MSP becomes a more productive environment for managing the growing scale and complexity of gesture sensing systems for musical instruments and interactive installations.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Freed, Adrian and MacCallum, John and Schmeder, Andrew},
	year = {2011},
	keywords = {open sound control, processing, composability, delegation, functional programming, gesture signal, max, msp, object, object-, oriented programming},
	pages = {308--311}
}

@inproceedings{marquez-borbon_designing_2011,
	address = {Oslo, Norway},
	title = {Designing {Digital} {Musical} {Interactions} in {Experimental} {Contexts}},
	url = {http://www.nime.org/proceedings/2011/nime2011_373.pdf},
	abstract = {As NIME's focus has expanded beyond the design reportswhich were pervasive in the early days to include studies andexperiments involving music control devices, we report on aparticular area of activity that has been overlooked: designsof music devices in experimental contexts. We demonstratethis is distinct from designing for artistic performances, witha unique set of novel challenges. A survey of methodologicalapproaches to experiments in NIME reveals a tendency torely on existing instruments or evaluations of new devicesdesigned for broader creative application. We present twoexamples from our own studies that reveal the merits ofdesigning purpose-built devices for experimental contexts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Marquez-Borbon, Adnan and Gurevich, Michael and Fyans, A. Cavan and Stapleton, Paul},
	year = {2011},
	keywords = {DMIs, Experiment, Instrument Design, Methodology},
	pages = {373--376}
}

@inproceedings{fyans_examining_2010,
	address = {Sydney, Australia},
	title = {Examining the {Spectator} {Experience}},
	url = {http://www.nime.org/proceedings/2010/nime2010_451.pdf},
	abstract = {Drawing on a model of spectator understanding of error inperformance in the literature, we document a qualitativeexperiment that explores the relationships between domainknowledge, mental models, intention and error recognitionby spectators of performances with electronic instruments.Participants saw two performances with contrasting instruments, with controls on their mental model and understanding of intention. Based on data from a subsequent structured interview, we identify themes in participants' judgements and understanding of performance and explanationsof their spectator experience. These reveal both elementsof similarity and difference between the two performances,instruments and between domain knowledge groups. Fromthese, we suggest and discuss implications for the design ofnovel performative interactions with technology.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fyans, A. Cavan and Gurevich, Michael and Stapleton, Paul},
	year = {2010},
	keywords = {spectator, nime10, error, intention, mental model, qualitative},
	pages = {451--454},
	file = {nime2010_451.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2010/nime2010_451.pdf:application/pdf}
}

@inproceedings{marier_sponge_2010,
	address = {Sydney, Australia},
	title = {The {Sponge} {A} {Flexible} {Interface}},
	url = {http://www.nime.org/proceedings/2010/nime2010_356.pdf},
	abstract = {The sponge is an interface that allows a clear link to beestablished between gesture and sound in electroacousticmusic. The goals in developing the sponge were to reintroduce the pleasure of playing and to improve the interaction between the composer/performer and the audience. Ithas been argued that expenditure of effort or energy is required to obtain expressive interfaces. The sponge favors anenergy-sound relationship in two ways : 1) it senses acceleration, which is closely related to energy; and 2) it is madeout of a flexible material (foam) that requires effort to besqueezed or twisted. Some of the mapping strategies usedin a performance context with the sponge are discussed.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Marier, Martin},
	year = {2010},
	keywords = {mapping, Interface, performance, electroacoustic music, expressivity},
	pages = {356--359}
}

@inproceedings{wyse_instrumentalizing_2010,
	address = {Sydney, Australia},
	title = {Instrumentalizing {Synthesis} {Models}},
	url = {http://www.nime.org/proceedings/2010/nime2010_140.pdf},
	abstract = {An important part of building interactive sound models is designing the interface and control strategy. The multidimensional structure of the gestures natural for a musical or physical interface may have little obvious relationship to the parameters that a sound synthesis algorithm exposes for control. A common situation arises when there is a nonlinear synthesis technique for which a traditional instrumental interface with quasi-independent control of pitch and expression is desired. This paper presents a semi-automatic meta-modeling tool called the Instrumentalizer for embedding arbitrary synthesis algorithms in a control structure that exposes traditional instrument controls for pitch and expression.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Wyse, Lonce and Duy, Nguyen D.},
	year = {2010},
	keywords = {parameter mapping, Musical interface, expressive control.},
	pages = {140--143},
	file = {nime2010_140.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2010/nime2010_140.pdf:application/pdf}
}

@inproceedings{cook_re-designing_2009,
	address = {Pittsburgh, PA, United States},
	title = {Re-{Designing} {Principles} for {Computer} {Music} {Controllers} : a {Case} {Study} of {SqueezeVox} {Maggie}},
	url = {http://www.nime.org/proceedings/2009/nime2009_218.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Cook, Perry R.},
	year = {2009},
	keywords = {wireless, voice synthesis, 1, hci, nime09, batteries, composed instruments, i will restate the, laptop orchestras, original 13 principles for, sensas, the original principles, to begin},
	pages = {218--221},
	file = {nime2009_218_PerryCook_Re-Designing Principles for Computer Music Controllers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_218_PerryCook_Re-Designing Principles for Computer Music Controllers.pdf:application/pdf}
}

@inproceedings{hsu_evaluating_2009,
	address = {Pittsburgh, PA, United States},
	title = {Evaluating {Interactive} {Music} {Systems} : {An} {HCI} {Approach}},
	url = {http://www.nime.org/proceedings/2009/nime2009_025.pdf},
	abstract = {In this paper, we discuss a number of issues related to the design of evaluation tests for comparing interactive music systems for improvisation. Our testing procedure covers rehearsal and performance environments, and captures the experiences of a musician/participant as well as an audience member/observer. We attempt to isolate salient components of system behavior, and test whether the musician or audience are able to discern between systems with significantly different behavioral components. We report on our experiences with our testing methodology, in comparative studies of our London and ARHS improvisation systems [1].},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Hsu, William and Sosnick, Marc},
	year = {2009},
	keywords = {human computer interaction, evaluation tests., Interactive music systems},
	pages = {25--28},
	file = {nime2009_025.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_025.pdf:application/pdf}
}

@inproceedings{schlessinger_kalichord_2009,
	address = {Pittsburgh, PA, United States},
	title = {The {Kalichord} : {A} {Physically} {Modeled} {Electro}-{Acoustic} {Plucked} {String} {Instrument}},
	url = {http://www.nime.org/proceedings/2009/nime2009_098.pdf},
	abstract = {We present the Kalichord: a small, handheld electro/acoustic instrument in which the player's right hand plucks virtual strings while his left hand uses buttons to play independent bass lines. The Kalichord uses the analog signal from plucked acoustic tines to excite a physical string model, allowing a nuanced and intuitive plucking experience. First, we catalog instruments related to the Kalichord. Then we examine the use of analog signals to excite a physical string model and discuss the expressiveness and form factors that this technique affords. We then describe the overall construction of the Kalichord and possible playing styles, and finally we consider ways we hope to improve upon the current prototype.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Schlessinger, Daniel and Smith, Julius O.},
	year = {2009},
	keywords = {physical model, accordion, electro-acoustic instruments, Kalichord, kalimba, piezo, plucked string, tine},
	pages = {98--101},
	file = {nime2009_098.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_098.pdf:application/pdf}
}

@inproceedings{bau_a20_2008,
	address = {Genoa, Italy},
	title = {The {A}20 : {Musical} {Metaphors} for {Interface} {Design}},
	url = {http://www.nime.org/proceedings/2008/nime2008_091.pdf},
	abstract = {We combine two concepts, the musical instrument as metaphorand technology probes, to explore how tangible interfaces canexploit the semantic richness of sound. Using participatorydesign methods from Human-Computer Interaction (HCI), wedesigned and tested the A20, a polyhedron-shaped, multichannel audio input/output device. The software maps soundaround the edges and responds to the user's gestural input,allowing both aural and haptic modes of interaction as well asdirect manipulation of media content. The software is designedto be very flexible and can be adapted to a wide range ofshapes. Our tests of the A20's perceptual and interactionproperties showed that users can successfully detect soundplacement, movement and haptic effects on this device. Ourparticipatory design workshops explored the possibilities of theA20 as a generative tool for the design of an extended,collaborative personal music player. The A20 helped users toenact scenarios of everyday mobile music player use and togenerate new design ideas.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bau, Olivier and Tanaka, Atau and Mackay, Wendy E.},
	year = {2008},
	keywords = {Generative design tools, Instrument building, Multi-faceted audio, Personal music devices, Tangible user interfaces, Technology probes},
	pages = {91--96},
	file = {nime2008_091.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_091.pdf:application/pdf}
}

@inproceedings{corness_performer_2008,
	address = {Genoa, Italy},
	title = {Performer {Model} : {Towards} a {Framework} for {Interactive} {Performance} {Based} on {Perceived} {Intention}},
	url = {http://www.nime.org/proceedings/2008/nime2008_265.pdf},
	abstract = {Through the developing of tools for analyzing the performerssonic and movement-based gestures, research into the systemperformer interaction has focused on the computer's ability torespond to the performer. Where as such work shows interestwithin the community in developing an interaction paradigmmodeled on the player, by focusing on the perception andreasoning of the system, this research assumes that theperformer's manner of interaction is in agreement with thiscomputational model. My study presents an alternative model ofinteraction designed for improvisatory performance centered onthe perception of the performer as understood by theories takenfrom performance practices and cognitive science.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Corness, Greg},
	year = {2008},
	keywords = {HCI, Interactive performance, Perception},
	pages = {265--268},
	file = {nime2008_265.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_265.pdf:application/pdf}
}

@inproceedings{freed_application_2008,
	address = {Genoa, Italy},
	title = {Application of new {Fiber} and {Malleable} {Materials} for {Agile} {Development} of {Augmented} {Instruments} and {Controllers}},
	url = {http://www.nime.org/proceedings/2008/nime2008_107.pdf},
	abstract = {The paper introduces new fiber and malleable materials,including piezoresistive fabric and conductive heat-shrinktubing, and shows techniques and examples of how they maybe used for rapid prototyping and agile development of musicalinstrument controllers. New implementations of well-knowndesigns are covered as well as enhancements of existingcontrollers. Finally, two new controllers are introduced that aremade possible by these recently available materials andconstruction techniques.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Freed, Adrian},
	year = {2008},
	keywords = {augmented instruments., Agile Development, Conductive fabric, conductive heatshrink tubing, Piezoresistive fabric, Rapid Prototyping},
	pages = {107--112}
}

@inproceedings{hayafuchi_musicglove_2008,
	address = {Genoa, Italy},
	title = {{MusicGlove} : {A} {Wearable} {Musical} {Controller} for {Massive} {Media} {Library}},
	url = {http://www.nime.org/proceedings/2008/nime2008_241.pdf},
	abstract = {This research aims to develop a wearable musical interfacewhich enables to control audio and video signals by usinghand gestures and human body motions. We have beendeveloping an audio-visual manipulation system that realizes tracks control, time-based operations and searching fortracks from massive music library. It aims to build an emotional and affecting musical interaction, and will providea better method of music listening to people. A sophisticated glove-like device with an acceleration sensor and several strain sensors has been developed. A realtime signalprocessing and musical control are executed as a result ofgesture recognition. We also developed a stand-alone device that performs as a musical controller and player at thesame time. In this paper, we describe the development of acompact and sophisticated sensor device, and demonstrateits performance of audio and video signals control.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Hayafuchi, Kouki and Suzuki, Kenji},
	year = {2008},
	keywords = {Gestures, Musical Interface, Music Controller, Embodied Sound Media, Body Motion},
	pages = {241--244},
	file = {nime2008_241.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_241.pdf:application/pdf}
}

@inproceedings{kiefer_hci_2008,
	address = {Genoa, Italy},
	title = {{HCI} {Methodology} {For} {Evaluating} {Musical} {Controllers} : {A} {Case} {Study}},
	url = {http://www.nime.org/proceedings/2008/nime2008_087.pdf},
	abstract = {There is small but useful body of research concerning theevaluation of musical interfaces with HCI techniques. Inthis paper, we present a case study in implementing thesetechniques; we describe a usability experiment which evaluated the Nintendo Wiimote as a musical controller, andreflect on the effectiveness of our choice of HCI methodologies in this context. The study offered some valuable results,but our picture of the Wiimote was incomplete as we lackeddata concerning the participants' instantaneous musical experience. Recent trends in HCI are leading researchers totackle this problem of evaluating user experience; we reviewsome of their work and suggest that with some adaptation itcould provide useful new tools and methodologies for computer musicians.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Kiefer, Chris and Collins, Nick and Fitzpatrick, Geraldine},
	year = {2008},
	keywords = {Evaluating Musical Interac- tion, HCI Methodology, Wiimote},
	pages = {87--90},
	file = {nime2008_087.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2008/nime2008_087.pdf:application/pdf}
}

@inproceedings{gurevich_expression_2007,
	address = {New York City, NY, United States},
	title = {Expression and {Its} {Discontents} : {Toward} an {Ecology} of {Musical} {Creation}},
	url = {http://www.nime.org/proceedings/2007/nime2007_106.pdf},
	abstract = {We describe the prevailing model of musical expression, which assumes a binary formulation of "the text" and "the act," along with its implied roles of composer and performer. We argue that this model not only excludes some contemporary aesthetic values but also limits the communicative ability of new music interfaces. As an alternative, an ecology of musical creation accounts for both a diversity of aesthetic goals and the complex interrelation of human and non-human agents. An ecological perspective on several approaches to musical creation with interactive technologies reveals an expanded, more inclusive view of artistic interaction that facilitates novel, compelling ways to use technology for music. This paper is fundamentally a call to consider the role of aesthetic values in the analysis of artistic processes and technologies.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gurevich, Michael and Treviño, Jeffrey},
	year = {2007},
	keywords = {evaluation, transparency, emotion, expressivity, aesthetic goal, communication, construct, discipline, discourse, experience, Expression, model, non-expressive},
	pages = {106--111},
	file = {nime2007_106.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2007/nime2007_106.pdf:application/pdf}
}

@inproceedings{bowers_creating_2006,
	address = {Paris, France},
	title = {Creating {Ad} {Hoc} {Instruments} with {Pin} \& {Play} \& {Perform}},
	url = {http://www.nime.org/proceedings/2006/nime2006_234.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bowers, John and Villar, Nicolas},
	year = {2006},
	keywords = {physical interfaces, music performance, Ad hoc instruments, new interfaces for musical expression., Pin\&Play},
	pages = {234--239},
	file = {2006.Bowers.Creating Ad Hoc Instruments with Pin&Play&Performnime2006_234.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/2006.Bowers.Creating Ad Hoc Instruments with Pin&Play&Performnime2006_234.pdf:application/pdf}
}

@inproceedings{dobrian_e_2006,
	address = {Paris, France},
	title = {The {E} in {NIME}: {Musical} {Expression} with {New} {Computer} {Interfaces}},
	url = {http://www.nime.org/proceedings/2006/nime2006_277.pdf},
	abstract = {Is there a distinction between New Interfaces for MusicalExpression and New Interfaces for Controlling Sound? Thisarticle begins with a brief overview of expression in musicalperformance, and examines some of the characteristics ofeffective "expressive" computer music instruments. Itbecomes apparent that sophisticated musical expressionrequires not only a good control interface but also virtuosicmastery of the instrument it controls. By studying effectiveacoustic instruments, choosing intuitive but complexgesture-sound mappings that take advantage of establishedinstrumental skills, designing intelligent characterizationsof performance gestures, and promoting long-term dedicatedpractice on a new interface, computer music instrumentdesigners can enhance the expressive quality of computermusic performance.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Dobrian, Christopher and Koppelman, Daniel},
	year = {2006},
	keywords = {performance, instrument design, Expression, virtuosity.},
	pages = {277--282},
	file = {nime2006_277.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_277.pdf:application/pdf}
}

@inproceedings{jensenius_towards_2006,
	address = {Paris, France},
	title = {Towards a {Gesture} {Description} {Interchange} {Format}},
	url = {http://www.nime.org/proceedings/2006/nime2006_176.pdf},
	abstract = {This paper presents our need for a Gesture Description Interchange Format (GDIF) for storing, retrieving and sharing information about music-related gestures. Ideally, it should be possible to store all sorts of data from various commercial and custom made controllers, motion capture and computer vision systems, as well as results from different types of gesture analysis, in a coherent and consistent way. This would make it possible to use the information with different software, platforms and devices, and also allow for sharing data between research institutions. We present some of the data types that should be included, and discuss issues which need to be resolved.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jensenius, Alexander Refsum and Kvifte, Tellef and Godøy, Rolf Inge},
	year = {2006},
	keywords = {gesture analysis, Gesture description, standards},
	pages = {176--179},
	file = {nime2006_176.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_176.pdf:application/pdf}
}

@inproceedings{marshall_vibrotactile_2006,
	address = {Paris, France},
	title = {Vibrotactile {Feedback} in {Digital} {Musical} {Instruments}},
	url = {http://www.nime.org/proceedings/2006/nime2006_226.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Marshall, Mark T. and Wanderley, Marcelo M.},
	year = {2006},
	keywords = {digital musical instruments, tactile feedback, vibro-tactile},
	pages = {226--229},
	file = {marshallnime06.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/IDMIL/marshallnime06.pdf:application/pdf;nime2006_226.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_226.pdf:application/pdf}
}

@inproceedings{richards_32kg_2006,
	address = {Paris, France},
	title = {32kg : {Performance} {Systems} for a {Post}-{Digital} {Age}},
	url = {http://www.nime.org/proceedings/2006/nime2006_283.pdf},
	abstract = {Why is a seemingly mundane issue such as airline baggageallowance of great significance in regards to the performancepractice of electronic music? This paper discusses how aperformance practice has evolved that seeks to question thebinary and corporate digital world. New 'instruments' andapproaches have emerged that explore 'dirty electronics' and'punktronics': DIY electronic instruments made from junk.These instruments are not instruments in the traditionalsense, defined by physical dimensions or by a set number ofparameters, but modular systems, constantly evolving, nevercomplete, infinitely variable and designed to be portable. Acombination of lo- and hi-fi, analogue and digital,synchronous and asynchronous devices offer new modes ofexpression. The development of these new interfaces formusical expression run side-by-side with an emerging postdigital aesthetic.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Richards, John},
	year = {2006},
	keywords = {performance, bastardisation, dirty electronics, diy, ebay, live, modular, portability, post-digital, punktronics},
	pages = {283--287}
}

@inproceedings{steiner_towards_2006,
	address = {Paris, France},
	title = {Towards a {Catalog} and {Software} {Library} of {Mapping} {Methods}},
	url = {http://www.nime.org/proceedings/2006/nime2006_106.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Steiner, Hans-Christoph},
	year = {2006},
	pages = {106--109},
	file = {nime2006_106_HCSteiner_Towards a catalog and software library of mapping methods.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/mapping/nime2006_106_HCSteiner_Towards a catalog and software library of mapping methods.pdf:application/pdf;nime2006_106_Steiner_Towards a catalog and software library of mapping methods.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/nime2006_106_Steiner_Towards a catalog and software library of mapping methods.pdf:application/pdf;nime2006_106.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_106.pdf:application/pdf;nime2006_HC_Steiner_Towards a Catalog and Software Library of Mapping Methods.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/nime2006_HC_Steiner_Towards a Catalog and Software Library of Mapping Methods.pdf:application/pdf;STEINER - Towards a catalog and software library of mapping methods.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/STEINER - Towards a catalog and software library of mapping methods.pdf:application/pdf}
}

@inproceedings{bevilacqua_mnm_2005,
	address = {Vancouver, BC, Canada},
	title = {{MnM} : a {Max}/{MSP} mapping toolbox},
	url = {http://www.nime.org/proceedings/2005/nime2005_085.pdf},
	abstract = {In this report, we describe our development on the Max/MSPtoolbox MnM dedicated to mapping between gesture andsound, and more generally to statistical and machine learningmethods. This library is built on top of the FTM library, whichenables the efficient use of matrices and other data structuresin Max/MSP. Mapping examples are described based onvarious matrix manipulations such as Single ValueDecomposition. The FTM and MnM libraries are freelyavailable.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bevilacqua, Frédéric and Müller, Rémy and Schnell, Norbert},
	year = {2005},
	keywords = {Mapping, interface design, Max/MSP., matrix},
	pages = {85--88},
	file = {nime2005_085_Bevilacqua_MnM-aMax\:MSPmappingToolbox.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2005/nime2005_085_Bevilacqua_MnM-aMax\:MSPmappingToolbox.pdf:application/pdf}
}

@inproceedings{bowers_not_2005,
	address = {Vancouver, BC, Canada},
	title = {Not {Hyper}, {Not} {Meta}, {Not} {Cyber} but {Infra}-{Instruments}},
	url = {http://www.nime.org/proceedings/2005/nime2005_005.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Bowers, John and Archer, Phil},
	year = {2005},
	keywords = {hyperinstruments, design concepts and principles., Infra-instruments, meta-instruments, virtual instruments},
	pages = {5--10},
	file = {nime2005_005_Bowers.Infra Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2005/nime2005_005_Bowers.Infra Instruments.pdf:application/pdf}
}

@inproceedings{jorda_digital_2004,
	address = {Hamamatsu, Japan},
	title = {Digital {Instruments} and {Players}: {Part} {I} – {Efficiency} and {Apprenticeship}},
	url = {http://www.nime.org/proceedings/2004/nime2004_059.pdf},
	abstract = {When envisaging new digital instruments, designers do not have to limit themselves to their sonic capabilities (which can be absolutely any), not even to their algorithmic power; they must be also especially careful about the instruments' conceptual capabilities, to the ways instruments impose or suggest to their players new ways of thinking, new ways of establishing relations, new ways of interacting, new ways of organizing time and textures; new ways, in short, of playing new musics. This article explores the dynamic relation that builds between the player and the instrument, introducing concepts such as efficiency, apprenticeship and learning curve It aims at constructing a framework in which the possibilities and the diversity of music instruments as well as the possibilities and the expressive freedom of human music performers could start being evaluated.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jordà, Sergi},
	year = {2004},
	keywords = {apprenticeship, learning curve, musical efficiency., Musical instruments design},
	pages = {59--63},
	file = {nime2004_059.Jorda.Digital Instruments and PlayersPt1.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2004/nime2004_059.Jorda.Digital Instruments and PlayersPt1.pdf:application/pdf}
}

@inproceedings{gadd_metamuse:_2002,
	address = {Dublin, Ireland},
	title = {{MetaMuse}: {Metaphors} for {Expressive} {Instruments}},
	url = {http://www.nime.org/proceedings/2002/nime2002_065.pdf},
	abstract = {We explore the role that metaphor plays in developing expressive devices by examining the MetaMuse system. MetaMuse is a prop-based system that uses the metaphor of rainfall to make the process of granular synthesis understandable. We discuss MetaMuse within a framework we call"transparency" that can be used as a predictor of the expressivity of musical devices. Metaphor depends on a literature,or cultural basis, which forms the basis for making transparent device mappings. In this context we evaluate the effect of metaphor in the MetaMuse system.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gadd, Ashley and Fels, Sidney S.},
	month = may,
	year = {2002},
	keywords = {metaphor, transparency, Expressive interface, granular synthesis., prop-based controller},
	pages = {65--70},
	file = {nime2002_065.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_065.Fels.MetaphorsForExpressiveInstruments.pdf:application/pdf}
}

@inproceedings{orio_input_2001,
	address = {Seattle, WA},
	title = {Input {Devices} for {Musical} {Expression} : {Borrowing} {Tools} from {HCI}},
	url = {http://www.nime.org/proceedings/2001/nime2001_015.pdf},
	abstract = {This paper reviews the existing literature on input device evaluation and design in human-computer interaction (HCI)and discusses possible applications of this knowledge to the design and evaluation of new interfaces for musical expression. Specifically, a set of musical tasks is suggested to allow the evaluation of different existing controllers.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Orio, Nicola and Schnell, Norbert and Wanderley, Marcelo M.},
	month = apr,
	year = {2001},
	keywords = {gestural control, interactive systems, Input device design},
	pages = {15--18},
	file = {ORIO SCHNELL WANDERLEY - Input Devices for Musical Expression.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_INSTRU/ORIO SCHNELL WANDERLEY - Input Devices for Musical Expression.pdf:application/pdf}
}

@inproceedings{wessel_problems_2001,
	address = {Seattle, WA},
	title = {Problems and {Prospects} for {Intimate} {Musical} {Control} of {Computers}},
	url = {http://www.nime.org/proceedings/2001/nime2001_011.pdf},
	abstract = {In this paper we describe our efforts towards the development of live performance computer-based musical instrumentation. Our design criteria include initial ease of use coupled with a long term potential for virtuosity,minimal and low variance latency, and clear and simple strategies for programming the relationship between gesture and musical result. We present custom controllers and unique adaptations of standard gestural interfaces, a programmable connectivity processor, a communications protocol called Open Sound Control(OSC), and a variety of metaphors for musical control. We further describe applications of our technology to a variety of real musical performances and directions for future research.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Wessel, David and Wright, Matthew},
	month = apr,
	year = {2001},
	keywords = {latency, musical, gestural controllers, signal processing, communications protocols, reactive computing},
	pages = {11--14},
	file = {nime2001_011_WesselWright_Problems and Prospects for Intimate Musical Control of Computers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/nime2001_011_WesselWright_Problems and Prospects for Intimate Musical Control of Computers.pdf:application/pdf}
}

@article{chion_musique_1977,
	title = {La musique du futur a-t-elle un avenir ?},
	volume = {4},
	language = {french},
	journal = {Cahiers recherche/musique},
	author = {Chion, Michel},
	year = {1977},
	file = {1977.Chion.la musique du futur.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Cahiers recherche\:musique/1977.Chion.la musique du futur.pdf:application/pdf}
}

@article{bonardi_preservation_2008,
	title = {The preservation, emulation, migration, and virtualization of live electronics for performing arts: {An} overview of musical and technical issues},
	volume = {1},
	issn = {15564673},
	shorttitle = {The preservation, emulation, migration, and virtualization of live electronics for performing arts},
	url = {http://portal.acm.org/citation.cfm?doid=1367080.1367086},
	doi = {10.1145/1367080.1367086},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Bonardi, Alain and Barthélemy, Jérome},
	month = jun,
	year = {2008},
	pages = {1--16},
	file = {2008.Bonardi.PreservationEmulationMigratoinVirtualizationOfLiveElectronics.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_ACM_Journal on computing and cultural heritage/2008.Bonardi.PreservationEmulationMigratoinVirtualizationOfLiveElectronics.pdf:application/pdf}
}

@book{slade_made_2006,
	address = {Cambridge, Mass},
	title = {Made to break: technology and obsolescence in {America}},
	isbn = {978-0-674-02203-4},
	shorttitle = {Made to break},
	language = {en},
	publisher = {Harvard University Press},
	author = {Slade, Giles},
	year = {2006},
	note = {OCLC: ocm62679850},
	keywords = {Product obsolescence, Technological innovations, United States},
	file = {Slade - 2006 - Made to break technology and obsolescence in Amer.pdf:/Users/vg/Zotero/storage/FVGTWKD8/Slade - 2006 - Made to break technology and obsolescence in Amer.pdf:application/pdf}
}

@article{bates_social_2012,
	title = {The {Social} {Life} of {Musical} {Instruments}},
	volume = {56},
	issn = {00141836},
	url = {https://www.jstor.org/stable/10.5406/ethnomusicology.56.3.0363},
	doi = {10.5406/ethnomusicology.56.3.0363},
	language = {en},
	number = {3},
	urldate = {2019-05-28},
	journal = {Ethnomusicology},
	author = {{Bates}},
	year = {2012},
	pages = {363},
	file = {ETM_56_3_Bates.Social_Life_of_Musical instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Ethnomusicology/ETM_56_3_Bates.Social_Life_of_Musical instruments.pdf:application/pdf}
}

@article{haine_les_2018,
	title = {Les classifications des instruments de musique en {France} de 1761 à 1819 et l’élaboration d’une terminologie organologique.},
	volume = {15},
	issn = {00351601},
	url = {https://www.jstor.org/stable/10.2307/20141602?origin=crossref},
	doi = {10.2307/20141602},
	language = {fr},
	number = {1},
	urldate = {2019-05-28},
	journal = {Musique-Images-Instruments. Revue française d'organologie et d'iconographie musicale},
	author = {Haine, Malou},
	year = {2018},
	pages = {230--245},
	file = {MII-15-Haine-Classifications.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue française d’organologie et d’iconographie musicale/MII-15-Haine-Classifications.pdf:application/pdf}
}

@article{ferguson_imagined_2013,
	title = {Imagined {Agency}: {Technology}, {Unpredictability}, and {Ambiguity}},
	volume = {32},
	issn = {0749-4467, 1477-2256},
	shorttitle = {Imagined {Agency}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07494467.2013.775810},
	doi = {10.1080/07494467.2013.775810},
	language = {en},
	number = {2-03},
	urldate = {2019-05-28},
	journal = {Contemporary Music Review},
	author = {Ferguson, John Robert},
	month = jun,
	year = {2013},
	pages = {135--149},
	file = {2013.CMR.FergusonImagined_Agency_Technology_Unpredictabily.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Contemporary Music Review/2013.CMR.FergusonImagined_Agency_Technology_Unpredictabily.pdf:application/pdf}
}

@article{magnusson_ergodynamics_2019,
	title = {Ergodynamics and a semiotics of instrumental composition},
	volume = {73},
	number = {287},
	journal = {Tempo},
	author = {Magnusson, Thor},
	year = {2019},
	pages = {41--51},
	file = {Magnusson_Tempo_v3.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Tempo/Magnusson_Tempo_v3.pdf:application/pdf}
}

@article{omodhrain_framework_2011,
	title = {A {Framework} for the {Evaluation} of {Digital} {Musical} {Instruments}},
	volume = {35},
	issn = {0148-9267, 1531-5169},
	url = {http://www.mitpressjournals.org/doi/10.1162/COMJ_a_00038},
	doi = {10.1162/COMJ_a_00038},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Computer Music Journal},
	author = {O'Modhrain, Sile},
	month = mar,
	year = {2011},
	pages = {28--42},
	file = {2011.OModhrain.FrameworkForEvaluationOfDMI.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2011.OModhrain.FrameworkForEvaluationOfDMI.pdf:application/pdf;O'Modhrain - 2011 - A Framework for the Evaluation of Digital Musical .pdf:/Users/vg/Zotero/storage/DIL4R4ZJ/O'Modhrain - 2011 - A Framework for the Evaluation of Digital Musical .pdf:application/pdf}
}

@article{buxton_artists_1997,
	title = {Artists and the art of the luthier},
	volume = {31},
	number = {1},
	journal = {ACM SIGGRAPH Computer Graphics},
	author = {Buxton, Bill},
	year = {1997},
	pages = {10--11},
	file = {Full Text:/Users/vg/Zotero/storage/SPN6M678/luthier.html:text/html}
}

@inproceedings{chadabe_limitations_2002,
	address = {Dublin, Ireland},
	title = {The {Limitations} of {Mapping} as a {Structural} {Descriptive} in {Electronic} {Instruments}},
	url = {http://www.nime.org/proceedings/2002/nime2002_038.pdf},
	abstract = {Mapping, which describes the way a performer's controls are connected to sound variables, is a useful concept when applied to the structure of electronic instruments modelled after traditional acoustic instruments. But mapping is a less useful concept when applied to the structure of complex and interactive instruments in which algorithms generate control information. This paper relates the functioning and benefits of different types of electronic instruments to the structural principles on which they are based. Structural models of various instruments will be discussed and musical examples played.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Chadabe, Joel},
	month = may,
	year = {2002},
	keywords = {mapping fly-by-wire algorithmic network interactivity instrument deterministic indeterministic},
	pages = {38--42},
	file = {CHADABE - The Limitations of Mapping as a Structural Descriptive.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/CHADABE - The Limitations of Mapping as a Structural Descriptive.pdf:application/pdf}
}

@inproceedings{schnell_introducing_2002,
	address = {Dublin, Ireland},
	title = {Introducing {Composed} {Instruments}, {Technical} and {Musicological} {Implications}},
	url = {http://www.nime.org/proceedings/2002/nime2002_156.pdf},
	abstract = {In this paper, we develop the concept of "composed instruments". We will look at this idea from two perspectives: the design of computer systems in the context of live performed music and musicological considerations. A historical context is developed. Examples will be drawn from recent compositions. Finally basic concepts from computer science will be examined for their relation ship to this concept.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Schnell, Norbert and Battier, Marc},
	month = may,
	year = {2002},
	keywords = {interaction, composed instrument, Theremin, Instruments, Martenot, MAX., musicology, streams},
	pages = {156--160},
	file = {nime2002_156_Schnell_Introducing  Composed  Instruments,  Technical  and  Musicological  Implications.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_156_Schnell_Introducing  Composed  Instruments,  Technical  and  Musicological  Implications.pdf:application/pdf}
}

@inproceedings{wessel_intimate_2002,
	address = {Dublin, Ireland},
	title = {Intimate {Musical} {Control} of {Computers} with a {Variety} of {Controllers} and {Gesture} {Mapping} {Metaphors}},
	url = {http://www.nime.org/proceedings/2002/nime2002_192.pdf},
	abstract = {In this demonstration we will show a variety of computer-based musical instruments designed for live performance. Our design criteria include initial ease of use coupled with a long term potential for virtuosity, minimal and low variance latency, and clear and simple strategies for programming the relationship between gesture and musical result. We present custom controllers and unique adaptations of standard gestural interfaces, a programmable connectivity processor, a communications protocol called Open Sound Control (OSC), and a variety of metaphors for musical control.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Wessel, David and Wright, Matthew and Schott, John},
	month = may,
	year = {2002},
	keywords = {Expressive control, Tactex, Buchla Thunder, digitizing tablets., mapping gestures to acoustic results, metaphors for musical control},
	pages = {192--194},
	file = {nime2002_192.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_192.pdf:application/pdf;nime2002_WesselWrightSchottDmo_Intimate Musical Control of Computers with a Variety of Controllers and Gesture Mapping Metaphors.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/selected/nime2002_WesselWrightSchottDmo_Intimate Musical Control of Computers with a Variety of Controllers and Gesture Mapping Metaphors.pdf:application/pdf}
}

@inproceedings{van_nort_choice_2004,
	address = {Hamamatsu, Japan},
	title = {On the {Choice} of {Mappings} {Based} on {Geometric} {Properties}},
	url = {http://www.nime.org/proceedings/2004/nime2004_087.pdf},
	abstract = {The choice of mapping strategies to effectively map controller variables to sound synthesis algorithms is examined.Specifically, we look at continuous mappings that have ageometric representation. Drawing from underlying mathematical theory, this paper presents a way to compare mapping strategies, with the goal of achieving an appropriatematch between mapping and musical performance context.This method of comparison is applied to existing techniques,while a suggestion is offered on how to integrate and extendthis work through a new implementation.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Van Nort, Doug and Wanderley, Marcelo M. and Depalle, Philippe},
	year = {2004},
	keywords = {Mapping, Interpolation, Computational Geometry, Interface Design},
	pages = {87--91}
}

@inproceedings{birnbaum_towards_2005,
	address = {Vancouver, BC, Canada},
	title = {Towards a {Dimension} {Space} for {Musical} {Devices}},
	url = {http://www.nime.org/proceedings/2005/nime2005_192.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Birnbaum, David and Fiebrink, Rebecca and Malloch, Joseph and Wanderley, Marcelo M.},
	year = {2005},
	keywords = {human-computer interaction, design space analysis, interfaces for musical expression, new},
	pages = {192--195}
}

@inproceedings{kvifte_towards_2006,
	address = {Paris, France},
	title = {Towards a {Coherent} {Terminology} and {Model} of {Instrument} {Description} and {Design}},
	url = {http://www.nime.org/proceedings/2006/nime2006_220.pdf},
	abstract = {This paper discusses the need for a framework for describing musical instruments and their design, and discusses some possible elements in such a framework. The framework is meant as an aid in the development of a coherent terminology for describing, comparing and discussing different musical instruments and musical instrument designs. Three different perspectives are presented; that of the listener, the performer, and the constructor, and various levels of descriptions are introduced.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Kvifte, Tellef and Jensenius, Alexander Refsum},
	year = {2006},
	keywords = {mapping, gestures, Musical instrument design, organology.},
	pages = {220--225},
	file = {nime2006_220_KvifteARJ_Towards a Coherent Terminology and Model of Instrument Description and Design.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2006/nime2006_220_KvifteARJ_Towards a Coherent Terminology and Model of Instrument Description and Design.pdf:application/pdf}
}

@inproceedings{fraietta_open_2008,
	address = {Genoa, Italy},
	title = {Open {Sound} {Control} : {Constraints} and {Limitations}},
	url = {http://www.nime.org/proceedings/2008/nime2008_019.pdf},
	abstract = {Open Sound Control (OSC) is being used successfully as amessaging protocol among many computers, gesturalcontrollers and multimedia systems. Although OSC hasaddressed some of the shortcomings of MIDI, OSC cannotdeliver on its promises as a real-time communication protocolfor constrained embedded systems. This paper will examinesome of the advantages but also dispel some of the mythsconcerning OSC. The paper will also describe how some of thebest features of OSC can be used to develop a lightweightprotocol that is microcontroller friendly.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fraietta, Angelo},
	year = {2008},
	keywords = {open sound control, osc, a, nime08, data transmission protocols, gestural controllers, has been implemented as, midi},
	pages = {19--23}
}

@inproceedings{fyans_where_2009,
	address = {Pittsburgh, PA, USA},
	title = {Where {Did} {It} {All} {Go} {Wrong} ? {A} {Model} of {Error} {From} the {Spectator}'s {Perspective}},
	url = {http://www.nime.org/proceedings/2009/nime2009_171.pdf},
	abstract = {The development of new interfaces for musical expressionhas created a need to study how spectators comprehend newperformance technologies and practices. As part of a largerproject examining how interactions with technology can becommunicated with the spectator, we relate our model ofspectator understanding of error to the NIME discourse surrounding transparency, mapping, skill and success.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Fyans, A. Cavan and Gurevich, Michael and Stapleton, Paul},
	year = {2009},
	keywords = {performance, skill, design, HCI, transparency},
	pages = {171--172},
	file = {nime2009_171.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_171.pdf:application/pdf}
}

@inproceedings{gurevich_designing_2009,
	address = {Pittsburgh, PA, United States},
	title = {Designing for {Style} in {New} {Musical} {Interactions}},
	url = {http://www.nime.org/proceedings/2009/nime2009_213.pdf},
	abstract = {In this paper we discuss the concept of style, focusing in particular on methods of designing new instruments that facilitate the cultivation and recognition of style. We distinguishbetween style and structure of an interaction and discuss thesignificance of this formulation within the context of NIME.Two workshops that were conducted to explore style in interaction design are described, from which we identify elements of style that can inform and influence the design process. From these, we suggest steps toward designing forstyle in new musical interactions.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Gurevich, Michael and Stapleton, Paul and Bennett, Peter},
	year = {2009},
	keywords = {expression, skill, structure, style, virtuosity},
	pages = {213--217},
	file = {nime2009_213.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2009/nime2009_213.pdf:application/pdf}
}

@inproceedings{frounberg_glass_2010,
	address = {Sydney, Australia},
	title = {Glass {Instruments} – {From} {Pitch} to {Timbre}},
	url = {http://www.nime.org/proceedings/2010/nime2010_287.pdf},
	abstract = {The paper reports on the development of prototypes of glassinstruments. The focus has been on developing acousticinstruments specifically designed for electronic treatment,and where timbral qualities have had priority over pitch.The paper starts with a brief historical overview of glassinstruments and their artistic use. Then follows an overviewof the glass blowing process. Finally the musical use of theinstruments is discussed.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Frounberg, Ivar and Innervik, Kjell Tore and Jensenius, Alexander R.},
	year = {2010},
	keywords = {performance practice, nime, nime10, glass instruments},
	pages = {287--290},
	file = {nime2010_287.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2010/nime2010_287.pdf:application/pdf}
}

@inproceedings{jensenius_evaluating_2010,
	address = {Sydney, Australia},
	title = {Evaluating the {Subjective} {Effects} of {Microphone} {Placement} on {Glass} {Instruments}},
	url = {http://www.nime.org/proceedings/2010/nime2010_208.pdf},
	abstract = {We report on a study of perceptual and acoustic featuresrelated to the placement of microphones around a custommade glass instrument. Different microphone setups weretested: above, inside and outside the instrument and at different distances. The sounds were evaluated by an expertperformer, and further qualitative and quantitative analyses have been carried out. Preference was given to therecordings from microphones placed close to the rim of theinstrument, either from the inside or the outside.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Jensenius, Alexander R. and Innervik, Kjell Tore and Frounberg, Ivar},
	year = {2010},
	keywords = {glass instruments, microphone placement, sound analysis},
	pages = {208--211},
	file = {nime2010_208.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2010/nime2010_208.pdf:application/pdf}
}

@inproceedings{lee_real-time_2012,
	address = {Ann Arbor, Michigan},
	title = {Real-{Time} {Music} {Notation}, {Collaborative} {Improvisation}, and {Laptop} {Ensembles}},
	url = {http://www.nime.org/proceedings/2012/nime2012_62.pdf},
	abstract = {This paper describes recent extensions to LOLC, a text-based environment for collaborative improvisation for laptop ensembles, which integrate acoustic instrumental musicians into the environment. Laptop musicians author short commands to create, transform, and share pre-composed musical fragments, and the resulting notation is digitally displayed, in real time, to instrumental musicians to sight-read in performance. The paper describes the background and motivations of the project, outlines the design of the original LOLC environment and describes its new real-time notation components in detail, and explains the use of these new components in a musical composition, SGLC, by one of the authors.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Lee, Sang Won and Freeman, Jason and Collela, Andrew},
	year = {2012},
	file = {nime2012_62_Freeman Real-Time Music Notation Collaborative Improvisation and Laptop Ensembles.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_62_Freeman Real-Time Music Notation Collaborative Improvisation and Laptop Ensembles.pdf:application/pdf}
}

@inproceedings{schwarz_sound_2012,
	address = {Ann Arbor, Michigan},
	title = {The {Sound} {Space} as {Musical} {Instrument}: {Playing} {Corpus}-{Based} {Concatenative} {Synthesis}},
	url = {http://www.nime.org/proceedings/2012/nime2012_120.pdf},
	abstract = {Corpus-based concatenative synthesis is a fairly recent sound synthesis method, based on descriptor analysis of any number of existing or live-recorded sounds, and synthesis by selection of sound segments from the database matching given sound characteristics. It is well described in the literature, but has been rarely examined for its capacity as a new interface for musical expression. The interesting outcome of such an examination is that the actual instrument is the space of sound characteristics, through which the performer navigates with gestures captured by various input devices. We will take a look at different types of interaction modes and controllers (positional, inertial, audio analysis) and the gestures they afford, and provide a critical assessment of their musical and expressive capabilities, based on several years of musical experience, performing with the CataRT system for real-time CBCS.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Schwarz, Diemo},
	year = {2012},
	keywords = {gesture, CataRT, corpus-based concatenative synthesis},
	file = {nime2012_120.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2012/nime2012_120.pdf:application/pdf}
}

@inproceedings{collins_semiconducting_2013,
	title = {Semiconducting – {Making} {Music} {After} the {Transistor}},
	abstract = {Why does ‘Computer Music’ sound different from ‘Electronic Music’? The author examines several traits that distinguish hardware from software in terms of their application in music composition and performance. He discusses the often subtle influence of these differences on various aspects of the creative process, and presents a number of inferences as to the ‘intrinsic’ suitability of hardware and software for different musical tasks. His observations are based on several decades of experience as a composer and performer, and in close engagement with the music of his mentors and peers.},
	author = {Collins, Nicolas},
	year = {2013},
	file = {Collins_semiconducting.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Collins, Nicolas/Collins_semiconducting.pdf:application/pdf}
}

@inproceedings{berthaut_wubbles:_2014,
	address = {London, United Kingdom},
	title = {Wubbles: {A} {Collaborative} {Ephemeral} {Musical} {Instrument}},
	url = {http://www.nime.org/proceedings/2014/nime2014_334.pdf},
	abstract = {This paper presents a collaborative digital musical instrument that uses the ephemeral and physical properties of soap bubbles to explore the complexity layers and oscillating parameters of electronic (bass) music. This instrument, called Wubbles, aims at encouraging both individual and collaborative musical manipulations.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Berthaut, Florent and Knibbe, Jarrod},
	month = jun,
	year = {2014},
	pages = {499--500},
	file = {nime2014_334.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_334.pdf:application/pdf}
}

@inproceedings{mays_notation_2014,
	address = {London, United Kingdom},
	title = {A {Notation} {System} for the {Karlax} {Controller}},
	url = {http://www.nime.org/proceedings/2014/nime2014_509.pdf},
	abstract = {In this paper we expose the need to go beyond the composer/performer model of electronic instrument design and programming to encourage the transmission of compositions and the creation of a repertory via notation of repeatable performance practice. Drawing on 4 years of practice using the Karlax controller (Da Fact) as a base for new digital musical instruments, we present our notation system in detail and cite some mapping strategies and examples from to pieces in a growing repertory of chamber music compositions for electronic and acoustic instruments},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Mays, Tom and Faber, Francis},
	month = jun,
	year = {2014},
	pages = {553--556},
	file = {nime2014_509_Mays_Notation system for the Karlax.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_509_Mays_Notation system for the Karlax.pdf:application/pdf}
}

@inproceedings{tubb_divergent_2014,
	address = {London, United Kingdom},
	title = {The {Divergent} {Interface}: {Supporting} {Creative} {Exploration} of {Parameter} {Spaces}},
	url = {http://www.nime.org/proceedings/2014/nime2014_415.pdf},
	abstract = {This paper outlines a theoretical framework for creative technology based on two contrasting processes: divergent exploration and convergent optimisation. We claim that these two cases require different gesture-to-parameter mapping properties. Results are presented from a user experiment that motivates this theory. The experiment was conducted using a publicly available iPad app: “Sonic Zoom”. Participants were encouraged to conduct an open ended exploration of synthesis timbre using a combination of two different interfaces. The first was a standard interface with ten sliders, hypothesised to be suited to the “convergent” stage of creation. The second was a mapping of the entire 10-D combinatorial space to a 2-D surface using a space filling curve. This novel interface was intended to support the “divergent” aspect of creativity. The paths of around 250 users through both 2-D and 10-D space were logged and analysed. Both the interaction data and questionnaire results show that the different interfaces tended to be used for different aspects of sound creation, and a combination of these two navigation styles was deemed to be more useful than either individually. The study indicates that the predictable, separate parameters found in most music technology are more appropriate for convergent tasks.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Tubb, Robert and Dixon, Simon},
	month = jun,
	year = {2014},
	pages = {227--232},
	file = {nime2014_415.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2014/nime2014_415.pdf:application/pdf}
}

@inproceedings{marley_gestroviser:_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Gestroviser: {Toward} {Collaborative} {Agency} in {Digital} {Musical} {Instruments}.},
	url = {http://www.nime.org/proceedings/2015/nime2015_287.pdf},
	abstract = {This paper describes a software extension to the Reactable entitled Gestroviser that was developed to explore musician machine collaboration at the control signal level. The system functions by sampling a performers input, processing or reshaping this sampled input, and then repeatedly replaying it. The degree to which the sampled control signal is processed during replay is adjustable in real-time by the manipulation of a continuous finger slider function. The reshaping algorithm uses stochastic methods commonly used for MIDI note generation from a provided dataset. The reshaped signal therefore varies in an unpredictable manner. In this way the Gestroviser is a device to capture, reshape and replay an instrumental gesture. We describe the result of initial user testing of the system and discuss possible further development.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Marley, William and Ward, Nicholas},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {140--143},
	file = {Marley and Ward - 2015 - Gestroviser Toward Collaborative Agency in Digita.pdf:/Users/vg/Zotero/storage/LWU259U8/Marley and Ward - 2015 - Gestroviser Toward Collaborative Agency in Digita.pdf:application/pdf}
}

@inproceedings{gurevich_discovering_2017,
	address = {Copenhagen, Denmark},
	title = {Discovering {Instruments} in {Scores}: {A} {Repertoire}-{Driven} {Approach} to {Designing} {New} {Interfaces} for {Musical} {Expression}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0031.pdf},
	abstract = {This paper situates NIME practice with respect to models of social interaction among human agents. It argues that the conventional model of composer-performer-listener, and the underlying mid-20th century metaphor of music as communication upon which it relies, cannot reflect the richness of interaction and possibility afforded by interactive digital technologies. Building on Paul Lansky's vision of an expanded and dynamic social network, an alternative, ecological view of music-making is presented, in which meaning emerges not from "messages" communicated between individuals, but instead from the "noise" that arises through the uncertainty in their interactions. However, in our tendency in NIME to collapse the various roles in this network into a single individual, we place the increased potential afforded by digital systems at risk. Using examples from the author's NIME practices, the paper uses a practice-based methodology to describe approaches to designing instruments that respond to the technologies that form the interfaces of the network, which can include scores and stylistic conventions. In doing so, the paper demonstrates that a repertoire\&\#8212;a seemingly anachronistic concept\&\#8212;and a corresponding repertoire-driven approach to creating NIMEs can in fact be a catalyst for invention and creativity.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Gurevich, Michael},
	year = {2017},
	pages = {163--168},
	file = {Gurevich - 2017 - Discovering Instruments in Scores A Repertoire-Dr.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2017/Gurevich - 2017 - Discovering Instruments in Scores A Repertoire-Dr.pdf:application/pdf}
}

@book{seve_instrument_2013,
	edition = {Le Seuil},
	series = {L'{Ordre} philosophique},
	title = {L'instrument de musique: une étude philosophique},
	language = {french},
	publisher = {Le Seuil},
	author = {Sève, Bernard},
	month = mar,
	year = {2013}
}

@article{ostertag_why_1998,
	title = {Why computer music sucks},
	volume = {5},
	journal = {Resonance},
	author = {Ostertag, Bob},
	year = {1998},
	pages = {4--5}
}

@incollection{beaudouin-lafon_moins_1999,
	edition = {Hermes Science Publications},
	title = {Moins d'interface pour plus d'interaction},
	booktitle = {Interfaces homme-machine et création musicale},
	author = {Beaudouin-Lafon, Michel},
	year = {1999},
	pages = {123--141}
}

@inproceedings{vertegaal_towards_1996,
	title = {Towards a musician's cockpit: {Transducers}, feedback and musical function},
	volume = {96},
	booktitle = {{ICMC}},
	author = {Vertegaal, Roel and Ungvary, Tamas and Kieslinger, Michael},
	year = {1996},
	pages = {308--311},
	file = {Vertegaal_TowardAMusiciansCockpit.pdf:/Users/vg/vg.PROJETS/2013.PANAM/BIBLIO/Pitch_systems/Vertegaal_TowardAMusiciansCockpit.pdf:application/pdf}
}

@book{godoy_musical_2010,
	title = {Musical gestures: {Sound}, movement, and meaning},
	publisher = {Routledge},
	author = {Godøy, Rolf Inge and Leman, Marc},
	year = {2010}
}

@inproceedings{di_scipio_towards_1997,
	title = {Towards a critical theory of (music) technology},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Di Scipio, Agostino},
	year = {1997},
	pages = {62--65},
	file = {1997.ICMC.DiScipio.Towards a critical theory of (music) technology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1997/1997.ICMC.DiScipio.Towards a critical theory of (music) technology.pdf:application/pdf}
}

@incollection{jensenius_musical_2010,
	title = {Musical gestures. {Concepts} and methods in research},
	language = {en},
	booktitle = {Musical {Gestures}. {Sound}, movement, and meaning},
	publisher = {Routledge},
	author = {Jensenius, Alexander R and Wanderley, Marcelo M. and Godøy, Rolf Inge and Leman, Marc},
	year = {2010},
	pages = {13--35},
	file = {Jensenius_2010e.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Godoy\; Rolf Inge/MusicalGestures.Jensenius.pdf:application/pdf}
}

@incollection{risset_evolution_1999,
	title = {Evolution des outils de création sonore in {Interfaces} homme-machine et création musicale},
	booktitle = {Interfaces homme-machine et création musicale},
	publisher = {Hermès},
	author = {Risset, Jean-Claude},
	year = {1999}
}

@article{tresch_toward_2013,
	title = {Toward a new organology: instruments of music and science},
	volume = {28},
	number = {1},
	journal = {Osiris},
	author = {Tresch, John and Dolan, Emily I},
	year = {2013},
	pages = {278--298},
	file = {2013.Tresch-Dolan.Toward a New Organology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OSIRIS/2013.Tresch-Dolan.Toward a New Organology.pdf:application/pdf}
}

@article{moody_physics_2009,
	title = {The “physics” of notations: toward a scientific basis for constructing visual notations in software engineering},
	volume = {35},
	number = {6},
	journal = {IEEE Transactions on software engineering},
	author = {Moody, Daniel},
	year = {2009},
	pages = {756--779},
	file = {physics_of_notations.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_IEEE/physics_of_notations.pdf:application/pdf}
}

@book{tufte_visual_2001,
	title = {The visual display of quantitative information},
	volume = {2},
	publisher = {Graphics press Cheshire, CT},
	author = {Tufte, Edward R},
	year = {2001},
	file = {Tufte_2001_The visual display of quantitative information.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Tufte_2001_The visual display of quantitative information.pdf:application/pdf}
}

@incollection{pinch_why_2001,
	title = {Why you go to a music store to buy a synthesizer: path dependence and the social construction of technology},
	language = {En},
	booktitle = {Path dependence and creation},
	publisher = {Psychology Press},
	author = {Pinch, Trevor J},
	editor = {Garud, Raghu and Karnoe, Peter},
	year = {2001},
	pages = {381--400}
}

@article{gurevich_digital_2011,
	title = {Digital {Musical} {Interactions}: {Performer}–system relationships and their perception by spectators},
	volume = {16},
	issn = {1355-7718, 1469-8153},
	shorttitle = {Digital {Musical} {Interactions}},
	url = {https://www.cambridge.org/core/product/identifier/S1355771811000112/type/journal_article},
	doi = {10.1017/S1355771811000112},
	language = {en},
	number = {2},
	urldate = {2019-06-17},
	journal = {Organised Sound},
	author = {Gurevich, Michael and Cavan Fyans, A.},
	month = aug,
	year = {2011},
	pages = {166--175},
	file = {Organised Sound - Digital Musical Interactions Performer_system relationshi.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2011/Organised Sound - Digital Musical Interactions Performer_system relationshi.pdf:application/pdf}
}

@article{stuart_object_2003,
	title = {The object of performance: {Aural} performativity in contemporary laptop music},
	volume = {22},
	number = {4},
	journal = {Contemporary Music Review},
	author = {Stuart, Caleb},
	year = {2003},
	pages = {59--65},
	file = {Stuart_2003_The object of performance.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Stuart_2003_The object of performance.pdf:application/pdf}
}

@article{cadoz_geste_1994,
	title = {Le geste canal de communication homme/machine: la communication" instrumentale"},
	volume = {13},
	number = {1},
	journal = {Technique et science informatiques},
	author = {Cadoz, Claude},
	year = {1994},
	pages = {31--61},
	file = {CADOZ_LeGestreCanalDeCommunicationHommeMachine.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/1994.CADOZ_LeGesteCanalDeCommunicationHommeMachine.pdf:application/pdf}
}

@book{stravinsky_igor_1936,
	title = {Igor {Stravinsky}. {An} {Autobiography}.},
	publisher = {Simon And Schuster, Inc.},
	author = {Stravinsky, Igor},
	year = {1936}
}

@incollection{bhagwati_notational_2013,
	title = {Notational perspective and comprovisation},
	booktitle = {Sound \& {Score}. {Essays} on {Sound}, {Score} and {Notation}},
	author = {Bhagwati, Sandeep},
	year = {2013},
	pages = {165--177}
}

@book{bayle_musique_1993,
	title = {Musique acousmatique: propositions... positions},
	publisher = {INA-GRM, Buchet-Chastel},
	author = {Bayle, François},
	year = {1993}
}

@incollection{couprie_eanalysis:_2016,
	title = {{EAnalysis}: developing a sound-based music analytical tool},
	booktitle = {Expanding the {Horizon} of {Electroacoustic} {Music} {Analysis}},
	publisher = {Cambridge University Press},
	author = {Couprie, Pierre},
	year = {2016},
	pages = {170--194}
}

@inproceedings{fober_environment_2012,
	address = {Université de Stanford, Californie, USA},
	title = {An environment for the design of live music scores},
	booktitle = {Proceedings of the {Linux} {Audio} {Conference}, {CCRMA}, {Stanford} {University}, {California}, {US}},
	author = {Fober, Dominique and Orlarey, Yann and Letz, Stephane},
	year = {2012},
	pages = {47--54}
}

@inproceedings{favreau_lacousmographe_2010,
	title = {L’acousmographe 3},
	booktitle = {Journées d’{Informatique} {Musicale} ({JIM} 2010)},
	author = {Favreau, Emmanuel and Geslin, Yann and Lefèvre, Adrien},
	year = {2010}
}

@inproceedings{hope_screen_2011,
	address = {Huddersfield, UK},
	title = {Screen {Scores}: {New} {Media} {Music} {Manuscripts}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Computing}},
	author = {Hope, Cat and Vickery, Lindsay},
	year = {2011},
	file = {2011.Hope-Vickery_Screen Scores_ New Media Music Manuscripts.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/2011/2011.Hope-Vickery_Screen Scores_ New Media Music Manuscripts.pdf:application/pdf}
}

@inproceedings{hope_decibel_2015,
	address = {Paris, France},
	title = {The decibel scoreplayer-a digital tool for reading graphic notation},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Hope, Cat and Vickery, Lindsay and Wyatt, Aaron and James, Stuart},
	year = {2015},
	file = {2015_VickeryHope-DecibelScorePlayer.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2015/2015_VickeryHope-DecibelScorePlayer.pdf:application/pdf}
}

@inproceedings{maestri_notation_2016,
	address = {Cambridge, U.K.},
	title = {Notation as {Temporal} {Instrument}},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation}},
	author = {Maestri, Eric},
	year = {2016},
	file = {Maestri_NotationAsTemporalInstrument.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/2016/Maestri_NotationAsTemporalInstrument.pdf:application/pdf}
}

@article{magnusson_algorithms_2011,
	title = {Algorithms as scores: {Coding} live music},
	journal = {Leonardo Music Journal},
	author = {Magnusson, Thor},
	year = {2011},
	pages = {19--23},
	file = {Magnusson_Leonardo11_Algorithms as Scores_Coding Live Music.pdf:/Users/vg/Documents/_PERSO/THESE/BIBLIO/_AUTEURS/Magnusson, Thor/Magnusson_Leonardo11_Algorithms as Scores_Coding Live Music.pdf:application/pdf}
}

@article{delalande_les_1996,
	title = {Les {Unités} {Sémiotiques} {Temporelles}-Éléments nouveaux d’analyse musicale},
	journal = {Marseille: Edition MIM},
	author = {Delalande, François and Formosa, M and Frémiot, M and Gobin, P and Malbosc, P and Mandelbrojt, J and Pedler, E},
	year = {1996}
}

@book{schaeffer_traite_1966,
	series = {Pierres vives},
	title = {Traité des objets musicaux},
	publisher = {Le Seuil},
	author = {Schaeffer, Pierre},
	year = {1966}
}

@inproceedings{smith_atomic_2015,
	title = {An atomic approach to animated music notation},
	booktitle = {Proc. {Int}. {Conf}. {On} {New} {Tools} for {Music} {Notation} and {Representation}},
	author = {Smith, Ryan Ross},
	year = {2015},
	file = {2015.RossSmith-AtomicAMN.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2015/2015.RossSmith-AtomicAMN.pdf:application/pdf}
}

@phdthesis{chapiro_globally-asynchronous_1984,
	address = {Stanford, CA},
	title = {Globally-{Asynchronous} {Locally}-{Synchronous} {Systems}.},
	school = {Université de Stanford},
	author = {Chapiro, Daniel M.},
	year = {1984},
	file = {Chapiro_1984_Globally-Asynchronous Locally-Synchronous Systems.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Chapiro_1984_Globally-Asynchronous Locally-Synchronous Systems.pdf:application/pdf}
}

@inproceedings{freed_dynamic_2011,
	title = {Dynamic, {Instance}-based, object-oriented programming in {Max}/{MSP} using open sound control message delegation.},
	booktitle = {{ICMC}},
	author = {Freed, Adrian and MacCallum, John and Schmeder, Andrew},
	year = {2011}
}

@inproceedings{goudard_dynamic_2011,
	title = {Dynamic {Intermediate} {Models} for audiographic synthesis},
	copyright = {All rights reserved},
	booktitle = {8th {Sound} and {Music} {Computing} {Conference}},
	publisher = {Padova University Press},
	author = {Goudard, Vincent and Genevois, Hugues and Ghomi, Emilien and Doval, Boris},
	year = {2011},
	pages = {486},
	file = {Goudard_DynamicIntermediateModels.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_SMC/2011/Goudard_DynamicIntermediateModels.pdf:application/pdf}
}

@inproceedings{kaltenbrunner_tuio:_2005,
	title = {{TUIO}: {A} protocol for table-top tangible user interfaces},
	booktitle = {Proc. of the {The} 6th {Int}’l {Workshop} on {Gesture} in {Human}-{Computer} {Interaction} and {Simulation}},
	author = {Kaltenbrunner, Martin and Bovermann, Till and Bencina, Ross and Costanza, Enrico and {others}},
	year = {2005},
	pages = {1--5}
}

@article{mcmillen_zipi_1994,
	title = {The {ZIPI} music parameter description language},
	volume = {18},
	number = {4},
	journal = {Computer Music Journal},
	author = {McMillen, Keith and Wessel, David L and Wright, Matthew},
	year = {1994},
	pages = {52--73}
}

@article{association_complete_1996,
	title = {The complete {MIDI} 1.0 detailed specification},
	journal = {Los Angeles, CA, The MIDI Manufacturers Association},
	author = {Association, MIDI Manufacturers and {others}},
	year = {1996}
}

@article{moore_dysfunctions_1988,
	title = {The dysfunctions of {MIDI}},
	volume = {12},
	number = {1},
	journal = {Computer music journal},
	author = {Moore, F Richard},
	year = {1988},
	pages = {19--28}
}

@inproceedings{rovan_instrumental_1997,
	title = {Instrumental gestural mapping strategies as expressivity determinants in computer music performance},
	booktitle = {Kansei, {The} {Technology} of {Emotion}. {Proceedings} of the {AIMI} {International} {Workshop}},
	publisher = {Citeseer},
	author = {Rovan, Joseph Butch and Wanderley, Marcelo M and Dubnov, Shlomo and Depalle, Philippe},
	year = {1997},
	pages = {68--73},
	file = {ROVAN WANDERLEY - Instrumental gestural mapping strategies as expressivity determinants.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RW_MAPPING/ROVAN WANDERLEY - Instrumental gestural mapping strategies as expressivity determinants.pdf:application/pdf}
}

@book{selfridge-field_beyond_1997,
	title = {Beyond {MIDI}: {The} {Handbook} of {Musical} {Codes}},
	publisher = {The MIT Press},
	author = {Selfridge-Field, Eleanor},
	year = {1997}
}

@book{bovermann_musical_2017,
	title = {Musical {Instruments} in the 21st {Century}},
	isbn = {978-981-10-2950-9},
	publisher = {Springer},
	author = {Bovermann, Till and de Campo, Alberto and Egermann, Hauke and Hardjowirogo, Sarah-Indriyati and Weinzierl, Stefan},
	year = {2017},
	file = {Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Bovermann, Till/Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:application/pdf}
}

@inproceedings{wright_open_1997,
	title = {Open {SoundControl}: {A} {New} {Protocol} for {Communicating} with {Sound} {Synthesizers}},
	booktitle = {{ICMC}},
	author = {Wright, Matthew and Freed, Adrian and {others}},
	year = {1997},
	file = {1997.Wright.Open SoundControl.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1997/1997.Wright.Open SoundControl.pdf:application/pdf}
}

@inproceedings{kiefer_live_2019,
	address = {Media Lab, Madrid, Espagne},
	title = {Live coding machine learning and machine listening: a survey on the design of languages and environments for live coding.},
	booktitle = {Proceedings of the {International} {Conference} on {Live} {Coding}},
	author = {Kiefer, Chris and Magnusson, Thor},
	month = jan,
	year = {2019}
}

@inproceedings{baguyos_contemporary_2014,
	address = {Athènes, Grèce},
	title = {Contemporary {Practices} in the {Performance} and {Sustainability} of {Computer} {Music} {Repertoire}.},
	url = {http://dblp.uni-trier.de/db/conf/icmc/icmc2014.html#Baguyos14},
	booktitle = {{ICMC}},
	publisher = {Michigan Publishing},
	author = {Baguyos, Jeremy C.},
	year = {2014},
	keywords = {dblp}
}

@book{buci-glucksmann_esthetique_2003,
	address = {Paris},
	title = {Esthétique de l'éphémère},
	isbn = {978-2-7186-0622-4},
	language = {fr},
	publisher = {Galilée},
	author = {Buci-Glucksmann, Christine},
	year = {2003}
}

@article{couprie_meta-instrument:_2018,
	title = {Le {Méta}-{Instrument}: genèse et évolution d’un nouvel instrument.},
	volume = {17},
	journal = {COUPRIE, Pierre. Le Méta-Instrument: genèse et évolution d’un nouvel instrument. Musique-Images-Instruments. Revue française d'organologie et d'iconographie musicale,},
	author = {Couprie, Pierre},
	year = {2018},
	pages = {230--245}
}

@book{derrida_lecriture_2014,
	address = {Paris},
	title = {L'écriture et la différence},
	isbn = {978-2-7578-4171-6},
	publisher = {Éd. Points},
	author = {Derrida, Jacques},
	year = {2014}
}

@book{deleuze_mille_1980,
	address = {Paris},
	title = {Mille plateaux},
	isbn = {978-2-7073-0307-3},
	publisher = {Éditions de minuit},
	author = {Deleuze, Gilles},
	year = {1980},
	file = {Gilles Deleuze, Félix Guattari-Mille plateaux-Editions de Minuit (1980).pdf:/Users/vg/Documents/_BIBLIO/PHILOSOPHY/Deleuze,Gilles/Gilles Deleuze, Félix Guattari-Mille plateaux-Editions de Minuit (1980).pdf:application/pdf}
}

@article{dudas_comprovisation:_2010,
	title = {"{Comprovisation}": {The} various facets of composed improvisation within interactive performance systems},
	volume = {20},
	abstract = {This article discusses the balance between composition and improvisation with respect to interactive performance using electronic and computer-based music systems. The author uses his own experience in this domain in the roles of both collaborator and composer as a point of reference to look at general trends in "composed improvisation" within the electronic and computer music community. Specifically, the intention is to uncover the limits and limitations of improvisation and its relationship to both composition and "composed instruments" within the world of interactive electronic musical performance. [ABSTRACT FROM AUTHOR] Copyright of Leonardo Music Journal is the property of MIT Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
	journal = {Leonardo Music Journal},
	author = {Dudas, Richard},
	year = {2010},
	doi = {10.1162/LMJ_a_00009},
	pages = {29--31}
}

@inproceedings{goudard_john_2018,
	address = {Montreal, Canada},
	title = {John, the {Semi}-{Conductor}: {A} {Tool} for {Comprovisation}},
	copyright = {All rights reserved},
	isbn = {978-1-5251-0551-7},
	url = {http://www.tenor-conference.org/proceedings/2018/06_Goudard_tenor18.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {Technologies} for {Music} {Notation} and {Representation} – {TENOR}'18},
	publisher = {Concordia University},
	author = {Goudard, Vincent},
	editor = {Bhagwati, Sandeep and Bresson, Jean},
	year = {2018},
	pages = {43--49}
}

@article{hadjeres_deepbach:_2016,
	title = {{DeepBach}: a {Steerable} {Model} for {Bach} chorales generation},
	volume = {abs/1612.01010},
	url = {http://arxiv.org/abs/1612.01010},
	journal = {CoRR},
	author = {Hadjeres, Gaëtan and Pachet, François},
	year = {2016}
}

@book{hugill_digital_2019,
	address = {New York London},
	title = {The digital musician},
	isbn = {978-1-138-56962-1},
	publisher = {Routledge},
	author = {Hugill, Andrew},
	year = {2019}
}

@article{magnusson_epistemic_2009,
	title = {Of {Epistemic} {Tools}: musical instruments as cognitive extensions},
	volume = {14},
	doi = {10.1017/S1355771809000272},
	number = {2},
	journal = {Organised Sound},
	author = {Magnusson, Thor},
	year = {2009},
	pages = {168--176}
}

@book{duchamp_notes_2008,
	address = {Paris},
	title = {Notes},
	isbn = {978-2-08-121741-6},
	publisher = {Flammarion},
	author = {Duchamp, Marcel},
	year = {2008}
}

@book{savouret_introduction_2010,
	address = {Lyon},
	title = {Introduction à un solfège de l'audible : l'improvisation libre comme outil pratique},
	isbn = {978-2-914373-73-9},
	publisher = {Symétrie},
	author = {Savouret, Alain},
	year = {2010}
}

@misc{sebestik_ecoute_1992,
	type = {Documentaire},
	title = {Écoute},
	publisher = {Arte Editions},
	author = {Sebestik, Miroslav},
	year = {1992}
}

@book{stiegler_for_2010,
	address = {Cambridge Malden, MA},
	title = {For a new critique of political economy},
	isbn = {978-0-7456-4803-3},
	publisher = {Polity},
	author = {Stiegler, Bernard},
	year = {2010}
}

@article{torre_hands:_2016,
	title = {The {Hands}: {The} {Making} of a {Digital} {Musical} {Instrument}},
	volume = {40},
	url = {https://doi.org/10.1162/COMJ_a_00356},
	doi = {10.1162/COMJ_a_00356},
	abstract = {Michel Waisvisz's The Hands is one of the most famous and long-lasting research projects in the literature of digital music instruments. Consisting of a pair of data gloves and exhibited for the first time in 1984, The Hands is a pioneering work in digital devices for performing live music. It is a work that engaged Waisvisz for almost a quarter of a century and, in turn, has inspired many generations of music technologists and performers of live music. Despite being often cited in the relevant literature, however, the documentation concerning the sensor architecture, design, mapping strategies, and development of these data gloves is sparse. In this article, we aim to fill this gap by offering a detailed history behind the development of The Hands. The information contained in this article was retrieved and collated by searching the STEIM archive, interviewing close collaborators of Waisvisz, and browsing through the paper documentation found in his personal folders and office.},
	number = {2},
	journal = {Computer Music Journal},
	author = {Torre, Giuseppe and Andersen, Kristina and Baldé, Frank},
	year = {2016},
	pages = {22--34}
}

@article{wessel_timbre_1979,
	title = {Timbre {Space} as a {Musical} {Control} {Structure}},
	volume = {3},
	issn = {01489267},
	url = {https://www.jstor.org/stable/3680283?origin=crossref},
	doi = {10.2307/3680283},
	language = {en},
	number = {2},
	urldate = {2019-06-25},
	journal = {Computer Music Journal},
	author = {Wessel, David L.},
	month = jun,
	year = {1979},
	pages = {45},
	file = {Wessel - 1979 - Timbre Space as a Musical Control Structure.pdf:/Users/vg/Zotero/storage/MGNJUAC5/Wessel - 1979 - Timbre Space as a Musical Control Structure.pdf:application/pdf}
}

@inproceedings{risset_sound_2014,
	address = {Athènes, Grèce},
	title = {Sound and {Music} {Computing} {Meets} {Philosophy} (keynote)},
	booktitle = {Proceedings {ICMC}{\textbar}{SMC}{\textbar}2014},
	publisher = {A. Georgaki and G. Kouroupetroglou (Eds.)},
	author = {Risset, Jean-Claude},
	year = {2014}
}

@article{collins_why_2008,
	title = {Why {Live}?: {Performance} in the {Age} of {Digital} {Reproduction}},
	volume = {18},
	journal = {Leonardo Music Journal},
	author = {Collins, Nicolas},
	month = jan,
	year = {2008},
	pages = {7--8}
}

@inproceedings{bascou_gmu_2005,
	title = {Gmu, a flexible granular synthesis environment in max/msp},
	booktitle = {Proceedings of the {Sound} and {Music} {Computing} {Conference} ({SMC}’05), {Salerno}, {Italy}},
	author = {Bascou, Charles and Pottier, Laurent},
	year = {2005},
	file = {2005.Bascou.GMU.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_SMC/2005/2005.Bascou.GMU.pdf:application/pdf}
}

@article{gabor_acoustical_1947,
	title = {Acoustical {Quanta} and the {Theory} of {Hearing}},
	volume = {159},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/159591a0},
	doi = {10.1038/159591a0},
	abstract = {IN popular expositions of wave mechanics, acoustical illustrations have been used by several authors, with particular success by Lande1. In a recent paper on the “Theory of Communication”2 I have taken the opposite course. Acoustical phenomena are discussed by mathematical methods closely related to those of quantum theory. While in physical acoustics a new formal approach to old problems cannot be expected to reveal much that is not already known, the position in subjective acoustics is rather different. In fact, the new methods have already proved their heuristic value, and can be expected to throw more light on the theory of hearing. In my original paper the point of view was mainly that of communication engineering ; in the following survey I have emphasized those features which may be of interest to physicists and to physiologists.},
	number = {4044},
	journal = {Nature},
	author = {GABOR, D.},
	month = may,
	year = {1947},
	pages = {591--594},
	file = {GaborTheoryQuanta.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Nature/GaborTheoryQuanta.pdf:application/pdf}
}

@book{leppert_sight_1993,
	title = {The sight of sound: {Music}, representation, and the history of the body},
	publisher = {Univ of California Press},
	author = {Leppert, Richard},
	year = {1993}
}

@article{risset_son_1992,
	title = {Le son numérique: une acoustique affranchie de la mécanique?},
	volume = {2},
	number = {C1},
	journal = {Le Journal de Physique IV},
	author = {Risset, J},
	year = {1992},
	pages = {C1--3},
	file = {Risset_Son numérique affranchi de la mécanique?.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Journal de Physique/Risset_Son numérique affranchi de la mécanique?.pdf:application/pdf}
}

@book{cage_silence:_1961,
	title = {Silence: {Lectures} and {Writings}},
	publisher = {Wesleyan University Press},
	author = {Cage, John},
	year = {1961}
}

@book{small_musicking:_1998,
	title = {Musicking: {The} meanings of performing and listening},
	publisher = {Wesleyan University Press},
	author = {Small, Christopher},
	year = {1998}
}

@inproceedings{risset_propos_2010,
	title = {A propos d'interdisciplinarité-informatique musicale: synthèse, traitement, perception; musicologie et {STIC}; oeuvre musicale et mixité},
	booktitle = {Journées d'{Informatique} {Musicale}},
	author = {Risset, Jean-Claude},
	year = {2010}
}

@book{magnusson_sonic_2019,
	title = {Sonic writing: technologies of material, symbolic, and signal inscriptions},
	publisher = {Bloomsbury Academic},
	author = {Magnusson, Thor},
	year = {2019}
}

@book{cage_radio_2015,
	address = {Paris},
	title = {Radio happenings : enregistrés à {Wbai}, {New} {York}, juillet 1966-janvier 1967},
	isbn = {979-10-304-0041-0},
	publisher = {Éditions Allia},
	author = {Cage, John},
	year = {2015}
}

@book{berliner_thinking_2009,
	title = {Thinking in jazz: {The} infinite art of improvisation},
	publisher = {University of Chicago Press},
	author = {Berliner, Paul F},
	year = {2009}
}

@article{delalande_geste_1988,
	title = {Le {Geste}, outil d'analyse: quelques enseignements d'une recherche sur la gestique de {Glenn} {Gould}},
	volume = {10},
	journal = {Analyse musicale},
	author = {Delalande, François},
	year = {1988},
	pages = {43--46}
}

@incollection{wanderley_controgestuel_1999,
	address = {Paris},
	title = {Contrôle gestuel de la synthèse sonore},
	language = {fr},
	booktitle = {Interfaces homme-machine et création musicale},
	publisher = {HERMES Science Publications},
	author = {Wanderley, Marcelo M and Depalle, Philippe},
	year = {1999},
	keywords = {Mapping, Contrôle gestuel de la synthèse sonore, Gestes, Interaction homme-machine, Nouveaux instruments},
	pages = {145--163},
	annote = {cote interne IRCAM: Wanderley99c},
	file = {Wanderley-Depalle_ControleGestuelDeLaSyntheseSonore.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Vinet, Hugues/Wanderley-Depalle_ControleGestuelDeLaSyntheseSonore.pdf:application/pdf}
}

@incollection{cadoz_gesture_2000,
	address = {Paris},
	title = {Gesture - {Music}},
	url = {https://hal.archives-ouvertes.fr/hal-01105543},
	booktitle = {Trends in {Gestural} {Control} of {Music}},
	publisher = {IRCAM, Centre Pompidou},
	author = {Cadoz, Claude and Wanderley, Marcelo M.},
	editor = {Wanderley, Marcelo M and Battier, Marc},
	month = mar,
	year = {2000},
	keywords = {gesture, Gesture typologies, Instrumental gesture},
	annote = {cote interne IRCAM: Cadoz00a},
	file = {00.cadoz_wanderley_gesture_music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Wanderley, Marcello/00.cadoz_wanderley_gesture_music.pdf:application/pdf}
}

@phdthesis{gibet_codage_1987,
	type = {{PhD} {Thesis}},
	title = {Codage, représentation et traitement du geste instrumental. {Application} à la synthèse de sons musicaux par simulation de mécanismes instrumentaux},
	url = {https://hal.archives-ouvertes.fr/tel-01267452/document},
	author = {Gibet, Sylvie},
	year = {1987},
	file = {1987.PhD.Gibet.GesteInstrumental.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/1987.PhD.Gibet.GesteInstrumental.pdf:application/pdf}
}

@inproceedings{godoy_exploring_2006,
	address = {Leeds, UK.},
	title = {Exploring music-related gestures by sound-tracing: {A} preliminary study},
	booktitle = {Proceedings of the {COST}287-{ConGAS} 2nd {International} {Symposium} on {Gesture} {Interfaces} for {Multimedia} {Systems}},
	author = {Godøy, Rolf Inge and Haga, Egil and Jensenius, Alexander Refsum},
	year = {2006},
	pages = {27--33},
	file = {Godxy_2006b_Exploring Music-Related Gestures by Sound-Tracing.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ConGAS/Godxy_2006b_Exploring Music-Related Gestures by Sound-Tracing.pdf:application/pdf}
}

@inproceedings{godoy_playing_2005,
	title = {Playing “air instruments”: mimicry of sound-producing gestures by novices and experts},
	booktitle = {International {Gesture} {Workshop}},
	publisher = {Springer},
	author = {Godøy, Rolf Inge and Haga, Egil and Jensenius, Alexander Refsum},
	year = {2005},
	pages = {256--267},
	file = {Godxy_2006a_Playing Air Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_International Gesture Workshop/Godxy_2006a_Playing Air Instruments.pdf:application/pdf}
}

@inproceedings{hunt_importance_2002,
	address = {Dublin, Ireland},
	title = {The importance of {Parameter} {Mapping} in {Electronic} {Instrument} {Design}},
	url = {http://www.nime.org/proceedings/2002/nime2002_088.pdf},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Hunt, Andy D. and Wanderley, Marcelo M. and Paradis, Matthew},
	month = may,
	year = {2002},
	keywords = {human-computer interaction, mapping strategies, electronic instruments and t, electronic musical instruments, h e},
	pages = {88--93},
	file = {nime2002_088_Hunt_Wanderley_TheImportanceOfParameterMappingInElectronicInstrumentDesign.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2002/nime2002_088_Hunt_Wanderley_TheImportanceOfParameterMappingInElectronicInstrumentDesign.pdf:application/pdf}
}

@incollection{emerson_mapping_2017,
	title = {Mapping, causality and the perception of instrumentality: {Theoretical} and empirical approaches to the audience’s experience of digital musical instruments},
	booktitle = {Musical instruments in the 21st {Century}},
	publisher = {Springer},
	author = {Emerson, Gina and Egermann, Hauke},
	year = {2017},
	pages = {363--370},
	file = {Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Bovermann, Till/Till Bovermann, Alberto de Campo, Hauke Egermann, Sarah-Indriyati Hardjowirogo, Stefan Weinzierl (eds.)-Musical Instruments in the 21st Century_ Identities, Configurations, Practices-Springer Singapor.pdf:application/pdf}
}

@article{conard_new_2009,
	title = {New flutes document the earliest musical tradition in southwestern {Germany}},
	volume = {460},
	number = {7256},
	journal = {Nature},
	author = {Conard, Nicholas J and Malina, Maria and Münzel, Susanne C},
	year = {2009},
	pages = {737}
}

@book{miranda_new_2006,
	title = {New digital musical instruments: control and interaction beyond the keyboard},
	volume = {21},
	publisher = {AR Editions, Inc.},
	author = {Miranda, Eduardo Reck and Wanderley, Marcelo M},
	year = {2006}
}

@incollection{mulder_towards_2000,
	address = {Paris},
	title = {Towards a choice of gestural constraints for instrumental performers.},
	booktitle = {Trends in {Gestural} {Control} of {Music}},
	publisher = {IRCAM, Centre Pompidou},
	author = {Mulder, Axel},
	editor = {Wanderley, Marcelo M and Battier, Marc},
	month = mar,
	year = {2000},
	keywords = {gesture, Gesture typologies, Instrumental gesture},
	file = {Towards_a_choice_of_gestural_constraints_for_instr.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Wanderley, Marcello/Towards_a_choice_of_gestural_constraints_for_instr.pdf:application/pdf}
}

@inproceedings{cadoz_instrumental_1988,
	address = {Cologne, Germany},
	title = {Instrumental {Gesture} and {Musical} {Composition}},
	url = {https://hal.archives-ouvertes.fr/hal-00491738},
	booktitle = {{ICMC} 1988 - {International} {Computer} {Music} {Conference}},
	author = {Cadoz, Claude},
	month = feb,
	year = {1988},
	keywords = {Gestural Interface, Real-time, Gesture Capture},
	pages = {1--12},
	annote = {http://computermusic.org/},
	file = {1988.Cadoz.Instrumental gesture and musical composition.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1988/1988.Cadoz.Instrumental gesture and musical composition.pdf:application/pdf}
}

@inproceedings{zhang_adaptive_2019,
	address = {Porto-Alegre, Brézil},
	title = {Adaptive {Multimodal} {Music} {Learning} via {Interactive}-haptic {Instrument}},
	abstract = {Haptic interfaces have untapped the sense of touch to assist multimodal music learning. We have recently seen various improvements of interface design on tactile feedback and force guidance aiming to make instrument learning more effective. However, most interfaces are still quite static; they cannot yet sense the learning progress and adjust the tutoring strategy accordingly. To solve this problem, we contribute an adaptive haptic interface based on the latest design of haptic flute. We first adopted a clutch mechanism to enable the interface to turn on and off the haptic control flexibly in real time. The interactive tutor is then able to follow human performances and apply the “teacher force” only when the software instructs so. Finally, we incorporated the adaptive interface with a step-by-step dynamic learning strategy. Experimental results showed that dynamic learning dramatically outperforms static learning, which boosts the learning rate by 45.3\% and shrinks the forgetting chance by 86\%.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Zhang, Yian and Li, Yinmiao and Chin, Daniel and Xia, Gus},
	month = jun,
	year = {2019}
}

@inproceedings{wanderley_non-obvious_1999,
	address = {Berlin, Heidelberg},
	title = {Non-obvious {Performer} {Gestures} in {Instrumental} {Music}},
	isbn = {978-3-540-46616-1},
	abstract = {This paper deals with the gestural language of instrumentalists playing wind instruments. It discusses the role of non-obvious performer gestures that may nevertheless influence the final sound produced by the acoustic instrument. These gestures have not commonly been considered in sound synthesis, although they are an integral part of the instrumentalist's full gestural language. The structure of this paper will be based on an analysis of these non-obvious gestures followed by some comments on how to best classify them according to existing research on gesture reviewed in the introduction; finally, the influence of these gestures on the sound produced by the instrument will be studied and measurement and simulation results presented.},
	booktitle = {Gesture-{Based} {Communication} in {Human}-{Computer} {Interaction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Wanderley, Marcelo M.},
	editor = {Braffort, Annelies and Gherbi, Rachid and Gibet, Sylvie and Teil, Daniel and Richardson, James},
	year = {1999},
	pages = {37--48},
	file = {1999.Wanderley.NonObviousPerformerGestures.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/1999/1999.Wanderley.NonObviousPerformerGestures.pdf:application/pdf}
}

@inproceedings{zattra_les_2013,
	title = {Les origines du nom de {RIM} ({Réalisateur} en informatique musicale)},
	booktitle = {Actes des {Journées} d’informatique musicale},
	author = {Zattra, Laura},
	year = {2013}
}

@phdthesis{dalessandro_realtime_2009,
	title = {Realtime and {Accurate} {Musical} {Control} of {Expression} in {Voice} {Synthesis}},
	author = {d’Alessandro, Nicolas},
	year = {2009},
	file = {2009.PhD.Nicolasd’Alessandro_ControlExpression in Voice Synthesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2009.PhD.Nicolasd’Alessandro_ControlExpression in Voice Synthesis.pdf:application/pdf}
}

@book{boulez_penser_1987,
	title = {Penser la musique aujourd'hui},
	publisher = {Gallimard},
	author = {Boulez, Pierre},
	year = {1987},
	file = {Pierre Boulez-Penser la musique aujourd'hui-Gallimard (1987).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Boulez, Pierre/Pierre Boulez-Penser la musique aujourd'hui-Gallimard (1987).pdf:application/pdf}
}

@book{leroi-gourhan_geste_1964,
	address = {Paris},
	title = {Le geste et la parole},
	isbn = {978-2-226-02324-7},
	publisher = {Albin Michel},
	author = {Leroi-Gourhan, André},
	year = {1964}
}

@article{nia_evolution_2015,
	title = {The evolution of air resonance power efficiency in the violin and its ancestors},
	volume = {471},
	number = {2175},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Nia, Hadi T and Jain, Ankita D and Liu, Yuming and Alam, Mohammad-Reza and Barnas, Roman and Makris, Nicholas C},
	year = {2015},
	pages = {20140905}
}

@article{bricout_les_2011,
	title = {Les interfaces musicales: la question des «instruments aphones»},
	number = {11},
	journal = {Methodos. Savoirs et textes},
	author = {Bricout, Romain},
	year = {2011},
	file = {BRICOUT_Les interfaces musicales  la question des « instruments aphones ».pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Methodos/BRICOUT_Les interfaces musicales  la question des « instruments aphones ».pdf:application/pdf}
}

@inproceedings{wanderley_gestural_2001,
	title = {Gestural control of music},
	booktitle = {International {Workshop} {Human} {Supervision} and {Control} in {Engineering} and {Music}},
	publisher = {Citeseer},
	author = {Wanderley, Marcelo M},
	year = {2001},
	pages = {632--644},
	file = {Wanderley_GesturalControlOfMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_InternationalWorkshopHumanSupervisionAndControlInEngineeringAndMusic/Wanderley_GesturalControlOfMusic.pdf:application/pdf}
}

@article{bown_understanding_2009,
	title = {Understanding interaction in contemporary digital music: from instruments to behavioural objects},
	volume = {14},
	number = {2},
	journal = {Organised Sound},
	author = {Bown, Oliver and Eldridge, Alice and McCormack, Jon},
	year = {2009},
	pages = {188--196},
	file = {OrganisedSound2009.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2009/OrganisedSound2009.pdf:application/pdf}
}

@article{di_scipio_sound_2003,
	title = {‘{Sound} is the interface’: from interactive to ecosystemic signal processing},
	volume = {8},
	number = {3},
	journal = {Organised Sound},
	author = {Di Scipio, Agostino},
	year = {2003},
	pages = {269--277},
	file = {Sound_is_the_interface_From_interactive_to_ecosy.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2003/Sound_is_the_interface_From_interactive_to_ecosy.pdf:application/pdf}
}

@inproceedings{mumma_creative_1967,
	title = {Creative aspects of live-performance electronic music technology},
	booktitle = {Audio {Engineering} {Society} {Convention} 33},
	publisher = {Audio Engineering Society},
	author = {Mumma, Gordon},
	year = {1967},
	file = {mumma-1967.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_IEEE/mumma-1967.pdf:application/pdf}
}

@article{bin_hands_2017,
	title = {Hands where we can see them! investigating the impact of gesture size on audience perception},
	author = {Bin, S. M. Astrid and Bryan-Kinns, Nick and McPherson, A and {others}},
	year = {2017}
}

@article{tsay_sight_2013,
	title = {Sight over sound in the judgment of music performance},
	volume = {110},
	number = {36},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Tsay, Chia-Jung},
	year = {2013},
	pages = {14580--14585}
}

@article{jorda_instruments_2004,
	title = {Instruments and players: {Some} thoughts on digital lutherie},
	volume = {33},
	url = {https://repositori.upf.edu/bitstream/handle/10230/41667/Jorda_new_inst.pdf?sequence=1&isAllowed=y},
	number = {3},
	journal = {Journal of New Music Research},
	author = {Jordà, Sergi},
	year = {2004},
	pages = {321--341},
	file = {2004.Jorda.Instruments and Players- Some Thoughts on Digital Lutherie.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JNMR_JournalOfNewMusicResearch/2004.Jorda.Instruments and Players- Some Thoughts on Digital Lutherie.pdf:application/pdf}
}

@inproceedings{collins_relating_2002,
	address = {Hallam University, Sheffield, England, UK.},
	title = {Relating superhuman virtuosity to human performance},
	url = {http://www.iodesign.free-online.co.uk/maxis/maxis2002.html},
	booktitle = {Proceedings of {MAXIS}},
	author = {Collins, Nick},
	year = {2002},
	pages = {12--14},
	file = {2002.NickCollins.RelatingSuperhumanVirtuosity.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_MAXIS/2002.NickCollins.RelatingSuperhumanVirtuosity.pdf:application/pdf}
}

@phdthesis{bacot_geste_2017,
	type = {{PhD} {Thesis}},
	title = {Geste et instrument dans la musique électronique: organologie des pratiques de création contemporaines},
	school = {Paris, EHESS},
	author = {Bacot, Baptiste},
	year = {2017},
	file = {Bacot_2017_Geste et instrument dans la musique électronique.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/Bacot_2017_Geste et instrument dans la musique électronique.pdf:application/pdf}
}

@incollection{giavitto_du_2014,
	address = {Paris},
	edition = {Hermann},
	title = {Du temps écrit au temps produit en informatique musicale},
	language = {fr},
	booktitle = {Produire le temps},
	author = {Giavitto, Jean-Louis},
	year = {2014},
	pages = {73--105},
	file = {19-Dutempscritautempsproduit.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Vinet, Hugues/19-Dutempscritautempsproduit.pdf:application/pdf}
}

@book{eco_oeuvre_2015,
	address = {Paris},
	title = {L'oeuvre ouverte},
	isbn = {978-2-7578-5017-6},
	publisher = {Points},
	author = {Eco, Umberto},
	translator = {Roux de Bézieux, Chantal and Boucourechliev, André},
	year = {2015},
	note = {édition italienne : 1962}
}

@inproceedings{goudard_ephemeral_2019,
	address = {Porto Alegre, Brazil},
	title = {Ephemeral instruments},
	copyright = {All rights reserved},
	url = {http://www.nime.org/proceedings/2019/nime2019_paper067.pdf},
	abstract = {This article questions the notion of ephemerality of digital musical instruments (DMI). Longevity is generally regarded as a valuable quality that good design criteria should help to achieve. However, the nature of the tools, of the performance conditions and of the music itself may lead to think of ephemerality as an intrinsic modality of the existence of DMIs. In particular, the conditions of contemporary musical production suggest that contextual adaptations of instrumental devices beyond the monolithic unity of classical instruments should be considered. The first two parts of this article analyse various reasons to reassess the issue of longevity and ephemerality. The last two sections attempt to propose an articulation of these two aspects to inform both the design of the DMI and their learning.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {UFRGS},
	author = {Goudard, Vincent},
	editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
	month = jun,
	year = {2019},
	pages = {349--354}
}

@book{guerin_philosophie_2018,
	title = {Philosophie du geste},
	publisher = {Éditions Actes Sud},
	author = {Guérin, Michel},
	year = {2018}
}

@article{imberty_mouvement_2013,
	title = {Mouvement, geste et figure: la musique ancrée dans le corps},
	journal = {S. Kogler, S. \& J.-P. Olive (Éd.), Expression et geste musical},
	author = {Imberty, Michel},
	year = {2013},
	pages = {25--36}
}

@book{olive_expression_2013,
	title = {Expression et geste musical},
	author = {Olive, Jean Paul and Kogler, Susanne},
	year = {2013}
}

@incollection{genevois_geste_1999,
	title = {Geste et pensée musicale : de l'outil à l'instrument},
	url = {https://hal.archives-ouvertes.fr/hal-00160720},
	booktitle = {Les nouveaux gestes de la musique},
	publisher = {Parenthèses},
	author = {Genevois, Hugues},
	year = {1999},
	pages = {25}
}

@article{shannon_mathematical_1948,
	title = {A mathematical theory of communication},
	volume = {27},
	number = {3},
	journal = {Bell system technical journal},
	author = {Shannon, Claude Elwood},
	year = {1948},
	pages = {379--423}
}

@article{stiegler_circuit_2004,
	title = {Le circuit du désir musical : {L}’interprète, le compositeur, l’auditeur — organes et instruments},
	volume = {15},
	doi = {https://doi.org/10.7202/902340ar},
	number = {1},
	journal = {Circuit: Musiques contemporaines},
	author = {Stiegler, Bernard and Donin, Nicolas},
	year = {2004},
	pages = {41--56},
	file = {Stiegler_CircuitDuDesirMusical.pdf:/Users/vg/Documents/_BIBLIO/PHILOSOPHY/Stiegler, Bernard/Stiegler_CircuitDuDesirMusical.pdf:application/pdf}
}

@book{auroux_revolution_1994,
	series = {Philosophie et langage},
	title = {La révolution technologique de la grammatisation: introduction à l'histoire des sciences du langage},
	isbn = {978-2-87009-565-2},
	url = {https://halshs.archives-ouvertes.fr/halshs-00529159},
	publisher = {Mardaga},
	author = {Auroux, Sylvain},
	year = {1994},
	lccn = {95109400}
}

@book{merleau-ponty_loeil_1964,
	title = {L'Œil et {L}'{Esprit}},
	publisher = {Gallimard},
	author = {Merleau-Ponty, Maurice},
	year = {1964}
}

@inproceedings{timsit-berthier_les_2004,
	title = {Les {Unités} {Sémiotiques} {Temporelles} ({UST}) {Un} nouvel outil d'analyse musicale. {Description} et approche biosémiotique.},
	booktitle = {Description et approche biosemiotique [{United} temporal semiotics—a novel method of musical analysis. {Description} and biosemiotic approach]. {Colloque} de {Rochebrune}, {January}},
	author = {Timsit-Berthier, M and Bootz, Ph and Favory, J and Formosa, M and Mandelbrojt, J and Paillard, J and Pro'dhomme, L and Frémoit, M},
	year = {2004},
	pages = {26--30},
	file = {ust-janvier04.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_TOPICS/UST/ust-janvier04.pdf:application/pdf}
}

@incollection{iazzetta_meaning_2000,
	address = {Paris},
	title = {Meaning in musical gesture},
	booktitle = {Trends in gestural control of music},
	publisher = {IRCAM, Centre Pompidou},
	author = {Iazzetta, Fernando},
	editor = {Wanderley, Marcelo M and Battier, Marc},
	year = {2000},
	pages = {259--268}
}

@incollection{kurtenbach_gestures_1990,
	title = {Gestures in {Human}-{Computer} {Communication}},
	booktitle = {The art of human-computer interface design},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Kurtenbach, Gordon and Hulteen, Eric A},
	editor = {Laurel, Brenda and Mountford, S. Joy},
	year = {1990},
	pages = {309--317}
}

@incollection{cadoz_musique_1999,
	title = {Musique, geste, technologie},
	url = {https://hal.archives-ouvertes.fr/hal-01083792},
	booktitle = {Les nouveaux gestes de la musique},
	publisher = {Editions Parenthèses},
	author = {Cadoz, Claude},
	editor = {Vivo, Hugues Genevois et Raphaël de},
	year = {1999},
	pages = {47--92}
}

@phdthesis{schnell_playing_2013,
	address = {Graz, Austria},
	title = {Playing (with) {Sound}-{Of} the {Animation} of {Digitized} {Sounds} and their {Reenactment} by {Playful} {Scenarios} in the {Design} of {Interactive} {Audio} {Applications}},
	school = {Institute of Electronic Music and Acoustics, University of Music and Performing Arts},
	author = {Schnell, Norbert},
	year = {2013},
	file = {2013.PhD.Schnell.Reenactment.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2013.PhD.Schnell.Reenactment.pdf:application/pdf}
}

@article{dolan_toward_2012,
	title = {Toward a {Musicology} of {Interfaces}},
	volume = {5},
	journal = {Keyboard Perspectives},
	author = {Dolan, Emily I},
	year = {2012},
	pages = {1--12},
	file = {2012-dolan_-_toward_a_musicology_of_interfaces_kp5.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/KeyboardPerspectives/2012-dolan_-_toward_a_musicology_of_interfaces_kp5.pdf:application/pdf}
}

@inproceedings{winkler_making_1995,
	address = {Banff Centre for the Arts, Banff, Canada},
	title = {Making {Motion} {Musical}: {Gesture} {Mapping} {Strategies} for {Interactive} {Computer} {Music}},
	abstract = {The increase in sophistication of new devices that allow gesture and movement to be translated into computer data holds great promise for interactive composition, dance, and creating responsive music in virtual reality systems. Data describing human motion can produce musically satisfying results by their impact on sound and musical processes.
This paper will take a general look at the use of physical gesture data as primary compositional constraints in interactive music systems. Theoretical concepts for the interpretation and evaluation of these data will be discussed. Finally, these devices and techniques will be shown be viable in multimedia applications.},
	booktitle = {Proceedings of the 1995 {International} {Computer} {Music} {Conference}},
	author = {Winkler, Todd},
	year = {1995},
	file = {1995.Winkler-MakingMotionMusical_gestureMappingStrategiesForInteractiveComputerMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1995/1995.Winkler-MakingMotionMusical_gestureMappingStrategiesForInteractiveComputerMusic.pdf:application/pdf}
}

@inproceedings{cadoz_simuler_1990,
	title = {Simuler pour connaître, {Connaître} pour simuler},
	booktitle = {Colloque {Modèles} {Physiques}, {Création} {Musicale} et {Ordinateurs}–{Grenoble}},
	author = {Cadoz, Claude},
	year = {1990},
	file = {Cad94_Conf_Modeles-physiques-1990.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_REPORTS/Cadoz, Claude/Cad94_Conf_Modeles-physiques-1990.pdf:application/pdf}
}

@inproceedings{wanderley_choice_2000,
	title = {On the {Choice} of {Transducer} {Technologies} for {Specific} {Musical} {Functions}.},
	booktitle = {{ICMC}},
	author = {Wanderley, Marcelo M and Viollet, Jean-Philippe and Isart, Fabrice and Rodet, Xavier},
	year = {2000},
	file = {2002.Wanderley.OnTheChoiceOfTransducers.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/2002/2002.Wanderley.OnTheChoiceOfTransducers.pdf:application/pdf}
}

@book{mazzola_topos_2018,
	title = {The {Topos} of {Music} {III}: {Gestures}},
	publisher = {Springer},
	author = {Mazzola, Guerino and Guitart, René and Ho, Jocelyn and Lubet, Alex and Mannone, Maria and Rahaim, Matt and Thalmann, Florian},
	year = {2018},
	file = {[Computational Music Science] Guerino Mazzola - The Topos of Music III_ Gestures .pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Mazzola, Guerino/[Computational Music Science] Guerino Mazzola - The Topos of Music III_ Gestures .pdf:application/pdf}
}

@book{csikszentmihalyi_optimal_1992,
	title = {Optimal experience: {Psychological} studies of flow in consciousness},
	publisher = {Cambridge university press},
	author = {Csikszentmihalyi, Mihaly and Csikszentmihalyi, Isabella Selega},
	year = {1992}
}

@article{wegner_apparent_1999,
	title = {Apparent mental causation: {Sources} of the experience of will.},
	volume = {54},
	number = {7},
	journal = {American psychologist},
	author = {Wegner, Daniel M and Wheatley, Thalia},
	year = {1999},
	pages = {480},
	file = {wegner20199920apparent20mental20causation.20sources20of20the20experience20of20will.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_AmericanPsychologist/wegner20199920apparent20mental20causation.20sources20of20the20experience20of20will.pdf:application/pdf}
}

@book{deleuze_francis_1981,
	address = {Paris},
	title = {Francis {Bacon}, {Logique} de la sensation},
	publisher = {Editions de la Différence},
	author = {Deleuze, Gilles},
	year = {1981},
	file = {Francis Bacon - Logique de la sensation - Deleuze, Gilles.pdf:/Users/vg/Documents/_BIBLIO/PHILOSOPHY/Deleuze,Gilles/Francis Bacon - Logique de la sensation - Deleuze, Gilles.pdf:application/pdf}
}

@article{cadoz_synthese_1981,
	title = {Synthèse musicale par simulation des mécanismes instrumentaux, transducteurs gestuels rétroactifs pour l'étude du jeu instrumental},
	volume = {4},
	url = {https://hal.archives-ouvertes.fr/hal-00878815},
	number = {59},
	journal = {Revue d'acoustique},
	author = {Cadoz, Claude and Luciani, Annie and Florens, Jean-Loup},
	year = {1981},
	pages = {279--292},
	annote = {Vibrations - environnement sonore. 14e année. Publié sous l'égide du GALF (Groupement des Acousticiens de Langue Française)},
	file = {CLF81_Rev_Acoustique-OCR.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue d'acoustique/CLF81_Rev_Acoustique-OCR.pdf:application/pdf}
}

@book{hatten_interpreting_2004,
	title = {Interpreting musical gestures, topics, and tropes: {Mozart}, {Beethoven}, {Schubert}},
	publisher = {Indiana University Press},
	author = {Hatten, Robert S},
	year = {2004},
	file = {(Musical meaning and interpretation.) Beethoven, Ludwig van_ Hatten, Robert S._ Mozart, Wolfgang Amadeus_ Schubert, Franz - Interpreting musical gestures, topics, and tropes _ Mozart, Beethoven, Schub.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Hatten, Robert/(Musical meaning and interpretation.) Beethoven, Ludwig van_ Hatten, Robert S._ Mozart, Wolfgang Amadeus_ Schubert, Franz - Interpreting musical gestures, topics, and tropes _ Mozart, Beethoven, Schub.pdf:application/pdf}
}

@article{croft_theses_2007,
	title = {Theses on liveness},
	volume = {12},
	number = {1},
	journal = {Organised Sound},
	author = {Croft, John},
	year = {2007},
	pages = {59--66},
	file = {2007.Croft.Theses_on_liveness.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2007/2007.Croft.Theses_on_liveness.pdf:application/pdf}
}

@article{berdahl_feedback_2012,
	title = {Feedback control of acoustic musical instruments: {Collocated} control using physical analogs},
	volume = {131},
	number = {1},
	journal = {The journal of the acoustical society of america},
	author = {Berdahl, Edgar and Smith III, Julius O and Niemeyer, Günter},
	year = {2012},
	pages = {963--973},
	file = {2012LBerdahl.Feedback_Control_Acoustic_Musical_Instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JASA_JournalAcousticSocietyOfAmerica/2012LBerdahl.Feedback_Control_Acoustic_Musical_Instruments.pdf:application/pdf}
}

@book{genevois_les_1999,
	address = {Marseille},
	edition = {Editions Paenthèses},
	series = {Collection eupalinos},
	title = {Les nouveaux gestes de la musique},
	editor = {Genevois, Hugues and De Vivo, Raphaël},
	year = {1999}
}

@book{wanderley_trends_2000,
	address = {Paris},
	title = {Trends in gestural control of music},
	publisher = {IRCAM, Centre Pompidou},
	editor = {Wanderley, Marcelo and Battier, Marc},
	year = {2000}
}

@book{castellengo_ecoute_2015,
	title = {Ecoute musicale et acoustique},
	publisher = {Eyrolles},
	author = {Castellengo, Michèle},
	collaborator = {Liénard, Jean-Sylvain and Bloch, Georges},
	year = {2015}
}

@book{frances_perception_1984,
	address = {Paris},
	title = {La perception de la musique (2ème ed.)},
	volume = {14},
	publisher = {Vrin},
	author = {Francès, Robert},
	year = {1984}
}

@inproceedings{gilbert_influence_2006,
	title = {Influence de la température sur la justesse d’un instrument à vent},
	booktitle = {Proceedings of {Congres} {Français} d’{Acoustique} 2006, {Tours}},
	author = {Gilbert, Joël and Ruiz, LM Leboso and Gougeon, Samuel},
	year = {2006}
}

@article{benford_performing_2010,
	title = {Performing {Musical} {Interaction}: {Lessons} from the {Study} of {Extended} {Theatrical} {Performances}},
	volume = {34},
	url = {https://doi.org/10.1162/COMJ_a_00025},
	doi = {10.1162/COMJ_a_00025},
	number = {4},
	journal = {Computer Music Journal},
	author = {Benford, Steve},
	year = {2010},
	pages = {49--61},
	file = {comj_a_00025.Benford.Performing MusicalInteraction.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2010/34.4-HCI/comj_a_00025.Benford.Performing MusicalInteraction.pdf:application/pdf}
}

@inproceedings{raboisson_experience_2017,
	address = {Paris, France},
	series = {Journées d'informatique musicale},
	title = {Une expérience de captation et d'analyse de l'interprétation acousmatique},
	url = {https://hal.archives-ouvertes.fr/hal-01525481},
	booktitle = {Journées d'informatique musicale},
	publisher = {Collegium Music{\textbackslash}a e},
	author = {Raboisson, Nathanaëlle and Couprie, Pierre},
	editor = {Couprie, Pierre and Davy-Rigaux, Cécile and Genevois, Hugues and Liao, Lin-Ni and Malt, Mikhail and Mifune, Marie-France},
	month = may,
	year = {2017},
	keywords = {Acousmonium, Analyse de l'interprétation, Digital musicology, Musique acousmatique, Performance studies, Représentation visuelle},
	file = {2017.RaboissonCouprie.CaptationEtAnalyseInterpretationAcousmatique.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_JIM_Journees_d'Informatique_Musicale/2017/2017.RaboissonCouprie.CaptationEtAnalyseInterpretationAcousmatique.pdf:application/pdf}
}

@phdthesis{mooney_sound_2006,
	type = {{PhD} {Thesis}},
	title = {Sound diffusion systems for the live performance of electroacoustic music},
	school = {Citeseer},
	author = {Mooney, James R},
	year = {2006},
	file = {2006.Mooney.SoundDiffusionSystemsForTheLivePerformanceOfElectroacousticMusic.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2006.Mooney.SoundDiffusionSystemsForTheLivePerformanceOfElectroacousticMusic.pdf:application/pdf}
}

@incollection{graybill_whose_2016,
	series = {{SEMPRE} {Studies} in {The} {Psychology} of {Music}},
	title = {Whose {Gestures}? {Chamber} {Music} and the {Construction} of {Permanent} {Agents}},
	language = {En},
	booktitle = {New {Perspectives} on {Music} and {Gesture}},
	publisher = {Routledge},
	editor = {Graybill, Roger and Gritten, Anthony and King, Elaine},
	year = {2016},
	pages = {247--268}
}

@inproceedings{tanaka_mobile_2004,
	address = {Hamamatsu, Japan},
	title = {Mobile {Music} {Making}},
	url = {http://www.nime.org/proceedings/2004/nime2004_154.pdf},
	abstract = {We present a system for collaborative musical creation onmobile wireless networks. The work extends on simple peerto-peer file sharing systems towards ad-hoc mobility andstreaming. It extends upon music listening from a passiveact to a proactive, participative activity. The system consistsof a network based interactive music engine and a portablerendering player. It serves as a platform for experiments onstudying the sense of agency in collaborative creativeprocess, and requirements for fostering musical satisfactionin remote collaboration.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Tanaka, Atau},
	year = {2004},
	keywords = {mobile music, peer-to-peer, wireless ad-hoc networks},
	pages = {154--156}
}

@inproceedings{schramm_polyphonic_2018,
	address = {Blacksburg, Virginia, USA},
	title = {A polyphonic pitch tracking embedded system for rapid instrument augmentation},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0027.pdf},
	abstract = {This paper presents a system for easily augmenting polyphonic pitched instruments. The entire system is designed to run on a low-cost embedded computer, suitable for live performance and easy to customise for different use cases. The core of the system implements real-time spectrum factorisation, decomposing polyphonic audio input signals into music note activations. New instruments can be easily added to the system with the help of custom spectral template dictionaries. Instrument augmentation is achieved by replacing or mixing the instrument's original sounds with a large variety of synthetic or sampled sounds, which follow the polyphonic pitch activations.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Schramm, Rodrigo and Visi, Federico and Brasil, André and Johann, Marcelo O.},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	pages = {120--125},
	file = {nime2018_paper0027_Schramm_PolyphonicPitchTracking.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2018/nime2018_paper0027_Schramm_PolyphonicPitchTracking.pdf:application/pdf}
}

@inproceedings{young_qualitative_2017,
	address = {Copenhagen, Denmark},
	title = {A {Qualitative} {Analysis} of {Haptic} {Feedback} in {Music} {Focused} {Exercises}},
	url = {http://www.nime.org/proceedings/2017/nime2017_paper0038.pdf},
	abstract = {We present the findings of a pilot-study that analysed the role of haptic feedback in a musical context. To examine the role of haptics in Digital Musical Instrument (DMI) design an experiment was formulated to measure the users’ perception of device usability across four separate feedback stages: fully haptic (force and tactile combined), constant force only, vibrotactile only, and no feedback. The study was piloted over extended periods with the intention of exploring the application and integration of DMIs in real-world musical contexts. Applying a music orientated analysis of this type enabled the investigative process to not only take place over a comprehensive period, but allowed for the exploration of DMI integration in everyday compositional practices. As with any investigation that involves creativity, it was important that the participants did not feel rushed or restricted. That is, they were given sufficient time to explore and assess the different feedback types without constraint. This provided an accurate and representational set of qualitative data for validating the participants’ experience with the different feedback types they were presented with.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Aalborg University Copenhagen},
	author = {Young, Gareth and Murphy, Dave and Weeter, Jeffrey},
	year = {2017},
	pages = {204--209}
}

@inproceedings{berthaut_rouages:_2013,
	address = {Daejeon, Republic of Korea},
	title = {Rouages: {Revealing} the {Mechanisms} of {Digital} {Musical} {Instruments} to the {Audience}},
	url = {http://nime.org/proceedings/2013/nime2013_51.pdf},
	abstract = {Digital musical instruments bring new possibilities for musical performance.They are also more complex for the audience to understand, due to the diversityof their components and the magical aspect of the musicians' actions whencompared to acoustic instruments. This complexity results in a loss of livenessand possibly a poor experience for the audience. Our approach, called Rouages,is based on a mixed-reality display system and a 3D visualization application.It reveals the mechanisms of digital musical instruments by amplifyingmusicians' gestures with virtual extensions of the sensors, by representingthe sound components with 3D shapes and specific behaviors and by showing theimpact ofmusicians gestures on these components. We believe that Rouages opens up newperspectives to help instrument makers and musicians improve audienceexperience with their digital musical instruments.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Graduate School of Culture Technology, KAIST},
	author = {Berthaut, Florent and Marshall, Mark T. and Subramanian, Sriram and Hachet, Martin},
	month = may,
	year = {2013},
	keywords = {3D interface, digital musical instruments, mappings, mixed-reality, rouages},
	pages = {164--169},
	file = {nime2013_51.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_NIME_New_Interfaces_for_Musical_Expression/per year/2013/nime2013_51.pdf:application/pdf}
}

@inproceedings{barrett_creating_2015,
	address = {Baton Rouge, Louisiana, USA},
	title = {Creating tangible spatial-musical images from physical performance gestures},
	url = {http://www.nime.org/proceedings/2015/nime2015_216.pdf},
	abstract = {Electroacoustic music has a longstanding relationship with gesture and space. This paper marks the start of a project investigating acousmatic spatial imagery, real gestural behaviour and ultimately the formation of tangible acousmatic images. These concepts are explored experimentally using motion tracking in a source-sound recording context, interactive parameter-mapping sonification in three-dimensional high-order ambisonics, composition and performance. The spatio-musical role of physical actions in relation to instrument excitation is used as a point of departure for embodying physical spatial gestures in the creative process. The work draws on how imagery for music is closely linked with imagery for music-related actions.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Louisiana State University},
	author = {Barrett, Natasha},
	editor = {Berdahl, Edgar and Allison, Jesse},
	month = may,
	year = {2015},
	pages = {191--194}
}

@book{theberge_any_1997,
	title = {Any {Sound} {You} {Can} {Imagine}: {Making} {Music} / {Consuming} {Technology}},
	isbn = {0-8195-6309-9},
	url = {https://www.xarg.org/ref/a/0819563099/},
	publisher = {Wesleyan University Press},
	author = {Théberge, Paul},
	month = may,
	year = {1997}
}

@book{deleuze_deux_2003,
	title = {Deux régimes de fous. {Textes} et entretiens 1975-1995 ({Paradoxe}) ({French} {Edition})},
	isbn = {2-7073-1834-5},
	url = {https://www.xarg.org/ref/a/B01A725Q4A/},
	publisher = {Minuit},
	author = {Deleuze, Gilles},
	month = oct,
	year = {2003},
	file = {Gilles Deleuze - Deux regimes de fous-Minuit (2003).pdf:/Users/vg/Documents/_BIBLIO/PHILOSOPHY/Deleuze,Gilles/Gilles Deleuze - Deux regimes de fous-Minuit (2003).pdf:application/pdf}
}

@book{chadabe_electric_1996,
	title = {Electric {Sound}: {The} {Past} and {Promise} of {Electronic} {Music}},
	isbn = {0-13-303231-0},
	url = {https://www.xarg.org/ref/a/0133032310/},
	publisher = {Pearson},
	author = {Chadabe, Joel},
	month = nov,
	year = {1996},
	file = {CHADABE - The Limitations of Mapping as a Structural Descriptive.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Chadabe, Joel/CHADABE - The Limitations of Mapping as a Structural Descriptive.pdf:application/pdf}
}

@inproceedings{michon_nuance_2016,
	title = {Nuance : {Adding} multi-touch force detection to the {iPad}},
	volume = {31},
	booktitle = {Proceedings of the {Sound} and {Music} {Computing} {Conference} ({SMC}-16), {Hamburg}, {Germany}},
	author = {Michon, Romain and Smith, Julius O and Chafe, Chris and Wright, Matthew and Wang, Ge},
	year = {2016},
	file = {2016.Michon.Nuance.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_SMC/2016/2016.Michon.Nuance.pdf:application/pdf}
}

@inproceedings{puckette_infuriating_2011,
	title = {Infuriating nonlinear reverberator},
	booktitle = {{ICMC}},
	author = {Puckette, Miller},
	year = {2011}
}

@inproceedings{michon_faust_2018,
	address = {Mainz, Germany},
	title = {The faust physical modeling library: a modular playground for the digital luthier},
	url = {https://hal.archives-ouvertes.fr/hal-02158706},
	booktitle = {International {Faust} {Conference}},
	author = {Michon, Romain and Smith, Julius and Chafe, Chris and Wang, Ge and Wright, Matthew},
	year = {2018},
	keywords = {DSP, ecosystem, FAUST}
}

@article{apo33_lorchestre_2003,
	title = {L’orchestre au xxie siècle},
	url = {https://journals.openedition.org/volume/2330},
	doi = {10.4000/volume.2330},
	language = {fr},
	number = {2 : 1},
	urldate = {2019-08-01},
	journal = {Volume !},
	author = {APO33},
	year = {2003},
	pages = {43--67}
}

@book{collins_handmade_2006,
	address = {New-York},
	title = {Handmade {Electronic} {Music} — the art of hardware hacking ({First} {Edition})},
	isbn = {0-415-97591-3},
	publisher = {Routledge},
	author = {Collins, Nicolas},
	month = apr,
	year = {2006},
	file = {NicolasCollins_Handmade electronic music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Collins, Nicolas/NicolasCollins_Handmade electronic music.pdf:application/pdf}
}

@inproceedings{wang_chuck_2003,
	title = {{ChucK} : {A} {Concurrent}, {On}-the-fly, {Audio} {Programming} {Language}},
	booktitle = {{ICMC}},
	author = {Wang, Ge and Cook, Perry R.},
	year = {2003}
}

@inproceedings{mclean_tidalpattern_2010,
	title = {Tidal–pattern language for the live coding of music},
	booktitle = {Proceedings of the 7th sound and music computing conference},
	author = {McLean, Alex and Wiggins, Geraint},
	year = {2010}
}

@inproceedings{blackwell_programming_2005,
	title = {The {Programming} {Language} as a {Musical} {Instrument}.},
	booktitle = {Proceeding of {PPIG}},
	author = {Blackwell, Alan F and Collins, Nick},
	year = {2005},
	pages = {11},
	file = {NickCollins.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_PPIG/NickCollins.pdf:application/pdf}
}

@inproceedings{berdahl_introduction_2012,
	title = {An introduction to the {Synth}-{A}-{Modeler} compiler: {Modular} and open-source sound synthesis using physical models},
	booktitle = {Proceedings of the {Linux} {Audio} {Conference}},
	author = {Berdahl, Edgar and Smith III, J},
	year = {2012}
}

@article{overholt_advancements_2011,
	title = {Advancements in {Actuated} {Musical} {Instruments}},
	volume = {16},
	doi = {10.1017/S1355771811000100},
	number = {2},
	journal = {Organised Sound},
	author = {Overholt, Dan and Berdahl, Edgar and Hamilton, Robert},
	year = {2011},
	pages = {154--165},
	file = {2011.Overholt.Advancements in Actuated MusicalInstruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_OS_OrganisedSound/2011/2011.Overholt.Advancements in Actuated MusicalInstruments.pdf:application/pdf}
}

@article{machover_hyperinstruments_1991,
	title = {Hyperinstruments : {A} composer’s approach to the evolution of intelligent musical instruments},
	journal = {Organized Sound},
	author = {Machover, Tod},
	year = {1991},
	pages = {67--76}
}

@article{doornbusch_computer_2004,
	title = {Computer sound synthesis in 1951: the music of {CSIRAC}},
	volume = {28},
	number = {1},
	journal = {Computer Music Journal},
	author = {Doornbusch, Paul},
	year = {2004},
	pages = {10--25}
}

@book{friedman_free_1990,
	title = {Free to choose: {A} personal statement},
	publisher = {Houghton Mifflin Harcourt},
	author = {Friedman, Milton and Friedman, Rose},
	year = {1990}
}

@book{read_i_1958,
	title = {I, pencil},
	volume = {8},
	number = {12},
	publisher = {Freeman},
	author = {Read, Leonard E},
	year = {1958}
}

@inproceedings{lee_real-time_1991,
	title = {Real-time neural network processing of gestural and acoustic signals},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	publisher = {International Computer Music Association},
	author = {Lee, Michael and Freed, Adrian and Wessel, David},
	year = {1991},
	pages = {277--277},
	file = {1991.Lee.RealTimeNeuralNeetwork.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1991/1991.Lee.RealTimeNeuralNeetwork.pdf:application/pdf}
}

@phdthesis{fiebrink_real-time_2011,
	address = {Princeton, NJ, USA},
	title = {Real-time {Human} {Interaction} with {Supervised} {Learning} {Algorithms} for {Music} {Composition} and {Performance}},
	school = {Princeton University},
	author = {Fiebrink, Rebecca},
	month = jan,
	year = {2011}
}

@article{zicarelli_communicating_1991,
	title = {Communicating with meaningless numbers},
	volume = {15},
	number = {4},
	journal = {Computer Music Journal},
	author = {Zicarelli, David},
	year = {1991},
	pages = {74--77}
}

@article{mulder_mapping_1997,
	title = {Mapping virtual object manipulation to sound variation},
	volume = {1997},
	number = {122 (1997-MUS-023)},
	journal = {IPSJ Sig Notes},
	author = {Mulder, Axel GE and Fels, S Sidney and Mase, Kenji},
	year = {1997},
	pages = {63--68}
}

@article{wanderley_mapping_2002,
	title = {Mapping strategies in real-time computer music},
	volume = {7},
	number = {2},
	journal = {Organised Sound},
	author = {Wanderley, Marcelo M},
	year = {2002},
	pages = {83--84}
}

@article{momeni_dynamic_2006,
	title = {Dynamic independent mapping layers for concurrent control of audio and video synthesis},
	volume = {30},
	number = {1},
	journal = {Computer Music Journal},
	author = {Momeni, Ali and Henry, Cyrille},
	year = {2006},
	pages = {49--66},
	file = {comj.2006.30.1.49.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2006/comj.2006.30.1.49.pdf:application/pdf}
}

@inproceedings{malloch_libmapper:library_2013,
	title = {Libmapper:(a library for connecting things)},
	booktitle = {{CHI}'13 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Malloch, Joseph and Sinclair, Stephen and Wanderley, Marcelo M},
	year = {2013},
	pages = {3087--3090}
}

@article{malloch_generalized_2018,
	title = {Generalized {Multi}-{Instance} {Control} {Mapping} for {Interactive} {Media} {Systems}},
	volume = {25},
	number = {1},
	journal = {IEEE MultiMedia},
	author = {Malloch, Joseph and Sinclair, Stephen and Wanderley, Marcelo M},
	year = {2018},
	pages = {39--50}
}

@phdthesis{francoise_motion-sound_2015,
	type = {Theses},
	title = {Motion-{Sound} {Mapping} by {Demonstration}},
	url = {https://hal.sorbonne-universite.fr/tel-01161965},
	school = {UPMC},
	author = {Françoise, Jules},
	month = mar,
	year = {2015},
	keywords = {Mapping, interaction, music, machine learning, Hidden Markov Models, Gesture Recognition, HCI, sound, HMM, sound design, apprentissage automatique, design sonore, Gaussian Mixture Models, GMM, Mapping by Demonstration, mapping par démonstration, modèles de markov cachés, musique},
	file = {2015.JulesFRANCOISE.Motion-Sound mapping by demonstration.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2015.JulesFRANCOISE.Motion-Sound mapping by demonstration.pdf:application/pdf}
}

@article{caramiaux_mapping_2014,
	title = {Mapping {Through} {Listening}},
	volume = {38},
	url = {https://doi.org/10.1162/COMJ_a_00255},
	doi = {10.1162/COMJ_a_00255},
	abstract = {Gesture-to-sound mapping is generally defined as the association between gestural and sound parameters. This article describes an approach that brings forward the perception–action loop as a fundamental design principle for gesture–sound mapping in digital music instrument. Our approach considers the processes of listening as the foundation—and the first step—in the design of action–sound relationships. In this design process, the relationship between action and sound is derived from actions that can be perceived in the sound. Building on previous work on listening modes and gestural descriptions, we propose to distinguish between three mapping strategies: instantaneous, temporal, and metaphorical. Our approach makes use of machine-learning techniques for building prototypes, from digital music instruments to interactive installations. Four different examples of scenarios and prototypes are described and discussed.},
	number = {3},
	journal = {Computer Music Journal},
	author = {Caramiaux, Baptiste and Françoise, Jules and Schnell, Norbert and Bevilacqua, Frédéric},
	year = {2014},
	pages = {34--48},
	file = {comj_a_00255.2014.Caramiaux.Mapping Through Listening.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2019/comj_a_00255.2014.Caramiaux.Mapping Through Listening.pdf:application/pdf}
}

@phdthesis{jorda_digital_2005,
	type = {{PhD} {Thesis}},
	title = {Digital {Lutherie} {Crafting} musical computers for new musics’ performance and improvisation},
	abstract = {This is a dissertation about performing music with computers, and about constructing the tools that will facilitate playing and improvising with these computers. The primary aim of this research is to construct a theoretical framework that could serve in evaluating the potential, the possibilities and the diversity of new digital musical instruments, with the hope that these ideas may inspire and assist the construction of new and powerful instruments with which perform and listen to wonderful new and previously unheard music.{\textless}br /{\textgreater} {\textless}br /{\textgreater} Computer-based interactive music systems date back to the late 1960s, initially involving computer-controlled analog synthesizers in concerts or installations. The use of real-time algorithmic composition spread in the 1970s with the work of composers and performers such as David Behrman, Joel Chadabe, Salvatore Martirano, Gordon Mumma or Laurie Spiegel. However the most rapid period of growth probably occurred during the mid 1980s with the MIDI standardization and, subsequently, with the advent of data-flow graphical programming languages such as Max, which made the design and implementation of custom interactive systems simpler than ever before. In spite of this, nearly four decades after the works of these pioneers, the design of computer-based music instruments, and computer music performance and improvisation in general, still seem immature multidisciplinary areas in which knowledge does not behave in incremental and accumulative ways, resulting in the permanent ’reinvention of the wheel’.{\textless}br /{\textgreater} {\textless}br /{\textgreater} New digital instrument design is a broad field, encompassing highly technological areas (e.g. electronics and sensor technology, sound synthesis and processing techniques, software engineering, etc.), and disciplines related to the study of human behavior (e.g. psychology, physiology, ergonomics and human-computer interaction components, etc.). Much of this focused research attempts to solve independent parts of the problem an approach essential to achieve any progress in this field. However, as this dissertation will show, it is also clearly insufficient. I believe an approach dedicated to the integrated understanding of the whole is the key to achieving fruitful results. Integral studies and approaches, which consider not only ergonomic or technological but also psychological, philosophical, conceptual, musicological, historical and above all, musical issues, even if non-systematic by definition, are necessary for genuine progress.{\textless}br /{\textgreater} {\textless}br /{\textgreater} Putting forward the idea that a digital instrument is a conceptual whole, independent of its potential components and features (e.g. the ways it is controlled or its sonic or musical output tendencies), we will investigate the essence and the potential highlights of new digital instruments, the new musical models and the new music making paradigms they can convey. {\textless}br /{\textgreater} {\textless}br /{\textgreater} This dissertation begins with the assumption that better new musical instruments based on computers can only be conceived by exploring three parallel paths {\textless}p{\textgreater} \&nbsp; {\textless}/p{\textgreater} {\textless}ul{\textgreater} {\textless}li{\textgreater} identifying the quintessence of new digital instruments; what they can bring of really original to the act of music performance; how can they redefine it; {\textless}/li{\textgreater} {\textless}li{\textgreater} identifying the drawbacks or obsolescences of traditional instruments; what limitations or problems could be eliminated, improved or solved; {\textless}/li{\textgreater} {\textless}li{\textgreater} without forgetting the essential generic assets of traditional instruments; those qualities that should never be forgotten nor discarded.{\textless}/li{\textgreater} {\textless}/ul{\textgreater} {\textless}p{\textgreater} The identification of these points is the primary aim of this thesis. There is a complex interconnected relationship between the tasks of imagining, designing and crafting musical computers, and performing and improvising with them. This relationship can only be understood as a permanent work in progress. This thesis comes from my own experience of fifteen years as a luthier-improviser. Therefore the dissertation is both theoretical (or conceptual) and experimental in approach, although the experiments it documents span years, even decades. To better organize this, the thesis is divided in three parts. {\textless}br /{\textgreater} {\textless}br /{\textgreater} Part I progressively enlightens the aforementioned three fundamental exploration paths. This is achieved by introducing the new possibilities offered by digital instruments, in addition to providing a thorough overview of current know-how and of the technical and conceptual frameworks in which new instrument designers and researchers are currently working on. Several taxonomies that will help us in developing a more synthetic and clear overview of the whole subject, are also presented. This first part concludes in chapter seven, presenting the first fundamental contribution of this dissertation; a theoretical framework for the evaluation of the expressive possibilities new digital musical instruments can offer to their performers. {\textless}br /{\textgreater} {\textless}br /{\textgreater} Part II describes in depth seven musical instruments, the implementations of my journeys into Digital Lutherie, developed during the previous decade. Since all seven are conceptually very different, each of them serves to illustrate several paradigms introduced in Part I. Presented in chronological order, these music instrument also help to clarify and understand of the path that has led me to the conception of the framework previously introduced. {\textless}br /{\textgreater} {\textless}br /{\textgreater} Part III incorporates the teachings and conclusions resulting from this evolutionary journey, and present the final milestone of this dissertation the presentation of possible solutions to better accomplish the goals presented at the end of the part I. Finally this dissertation concludes with what could be considered ’my digital lutherie decalogue’ which synthesizes most of the ideas introduced in the thesis. As a postlude, I offer the reacTable* to be presented as future work. The reacTable* is a digital instrument which constitutes the first one conceived from scratch, that takes into account all the concepts introduced in this thesis, the culmination thus far of my journey into Digital Lutherie {\textless}/p{\textgreater}},
	school = {Universitat Pompeu Fabra},
	author = {Jordà, Sergi},
	year = {2005},
	file = {Jorda-Sergi-PhD-2005_Digital Lutherie- Crafting musical computers for new musics' performance and improvisation.pdf:/Users/vg/Documents/_PERSO/THESE/BIBLIO/_AUTEURS/Jorda, Sergi/Jorda-Sergi-PhD-2005_Digital Lutherie- Crafting musical computers for new musics' performance and improvisation.pdf:application/pdf}
}

@inproceedings{goudard_modeintermediaire_2012,
	address = {Mons, Belgique},
	title = {Un modèle intermédiaire dynamique génératif basé sur l'automate cellulaire du jeu de la vie},
	copyright = {All rights reserved},
	url = {https://hal.archives-ouvertes.fr/hal-01073213},
	booktitle = {Actes des {Journées} d'{Informatique} {Musicale}},
	publisher = {Université de Mons},
	author = {Goudard, Vincent and Doval, Boris and Genevois, Hugues},
	editor = {Dutoit, Thierry and Todoroff, Todor and d'Alessandro, Nicolas},
	month = may,
	year = {2012},
	keywords = {computer music, informatique musicale},
	pages = {163}
}

@article{dabby_musical_1996,
	title = {Musical variations from a chaotic mapping},
	volume = {6},
	number = {2},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Dabby, Diana S},
	year = {1996},
	pages = {95--107}
}

@article{buxton_multi-touch_2007,
	title = {Multi-touch systems that {I} have known and loved},
	volume = {56},
	journal = {Microsoft Research},
	author = {Buxton, Bill and {others}},
	year = {2007},
	pages = {1--11}
}

@inproceedings{oney_implementing_2019,
	title = {Implementing {Multi}-{Touch} {Gestures} with {Touch} {Groups} and {Cross} {Events}},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Oney, Steve and Krosnick, Rebecca and Brandt, Joel and Myers, Brad},
	year = {2019},
	pages = {355}
}

@inproceedings{xiao_t-voks_2019,
	address = {Porto Alegre, Brazil},
	title = {T-{Voks} : the {Singing} and {Speaking} {Theremin}},
	url = {http://www.nime.org/proceedings/2019/nime2019_paper022.pdf},
	abstract = {T-Voks is an augmented theremin that controls Voks, a performative singing synthesizer. Originally developed for control with a graphic tablet interface, Voks allows for real-time pitch and time scaling, vocal effort modification and syllable sequencing for pre-recorded voice utterances. For T-Voks the theremin’s frequency antenna modifies the output pitch of the target utterance while the amplitude antenna controls not only volume as usual but also voice quality and vocal effort. Syllabic sequencing is handled by an additional pressure sensor attached to the player’s volume-control hand. This paper presents the system architecture of T-Voks, the preparation procedure for a song, playing gestures, and practice techniques, along with musical and poetic examples across four different languages and styles.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {UFRGS},
	author = {Xiao, Xiao and Locqueville, Grégoire and d'Alessandro, Christophe and Doval, Boris},
	editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
	month = jun,
	year = {2019},
	pages = {110--115}
}

@inproceedings{troyer_mondrian_2019,
	address = {Porto Alegre, Brazil},
	title = {From {Mondrian} to {Modular} {Synth}: {Rendering} {NIME} using {Generative} {Adversarial} {Networks}},
	url = {http://www.nime.org/proceedings/2019/nime2019_paper052.pdf},
	abstract = {This paper explores the potential of image-to-image translation techniques in aiding the design of new hardware-based musical interfaces such as MIDI keyboard, grid-based controller, drum machine, and analog modular synthesizers. We collected an extensive image database of such interfaces and implemented image-to-image translation techniques using variants of Generative Adversarial Networks. The created models learn the mapping between input and output images using a training set of either paired or unpaired images. We qualitatively assess the visual outcomes based on three image-to-image translation models: reconstructing interfaces from edge maps, and collection style transfers based on two image sets: visuals of mosaic tile patterns and geometric abstract two-dimensional arts. This paper aims to demonstrate that synthesizing interface layouts based on image-to-image translation techniques can yield insights for researchers, musicians, music technology industrial designers, and the broader NIME community.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {UFRGS},
	author = {Troyer, Akito Van and Kleinberger, Rebecca},
	editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
	month = jun,
	year = {2019},
	pages = {272--277}
}

@inproceedings{pardue_separating_2019,
	address = {Porto Alegre, Brazil},
	title = {Separating sound from source: sonic transformation of the violin through electrodynamic pickups and acoustic actuation},
	url = {http://www.nime.org/proceedings/2019/nime2019_paper053.pdf},
	abstract = {When designing an augmented acoustic instrument, it is often of interest to retain an instrument's sound quality and nuanced response while leveraging the richness of digital synthesis. Digital audio has traditionally been generated through speakers, separating sound generation from the instrument itself, or by adding an actuator within the instrument's resonating body, imparting new sounds along with the original. We offer a third option, isolating the playing interface from the actuated resonating body, allowing us to rewrite the relationship between performance action and sound result while retaining the general form and feel of the acoustic instrument. We present a hybrid acoustic-electronic violin based on a stick-body electric violin and an electrodynamic polyphonic pick-up capturing individual string displacements. A conventional violin body acts as the resonator, actuated using digitally altered audio of the string inputs. By attaching the electric violin above the body with acoustic isolation, we retain the physical playing experience of a normal violin along with some of the acoustic filtering and radiation of a traditional build. We propose the use of the hybrid instrument with digitally automated pitch and tone correction to make an easy violin for use as a potential motivational tool for beginning violinists.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {UFRGS},
	author = {Pardue, Laurel and Buys, Kurijn and Overholt, Dan and McPherson, Andrew P. and Edinger, Michael},
	editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
	month = jun,
	year = {2019},
	pages = {278--283}
}

@incollection{haury_petite_1999,
	series = {Collection eupalinos},
	title = {Petite histoire illustrée de l’interface clavier},
	language = {fr},
	booktitle = {Les nouveaux gestes de la musique},
	publisher = {Editions Parenthèses},
	author = {Haury, Jean},
	editor = {Genevois, Hugues and De Vivo, Raphaël},
	year = {1999},
	pages = {93--110},
	file = {1999.Haury.Petite histoire illustrée de l'interface clavier.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Genevois, Hugues/1999.Haury.Petite histoire illustrée de l'interface clavier.pdf:application/pdf}
}

@article{kojs_notating_2011,
	title = {Notating action-based music},
	journal = {Leonardo Music Journal},
	author = {Kojs, Juraj},
	year = {2011},
	pages = {65--72},
	file = {2011_Kojs-Notating Action-Based Music.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_LMJ_LeonardoMusicJournal/2011_Kojs-Notating Action-Based Music.pdf:application/pdf}
}

@inproceedings{maestri_notation_2015,
	address = {Paris, France},
	title = {Notation as instrument: from representation to enaction},
	url = {https://halshs.archives-ouvertes.fr/halshs-01644074},
	booktitle = {{TENOR} 2015. {International} conference on technologies for music notation and representation},
	publisher = {Dominique Fober, Pierre Couprie},
	author = {Maestri, Eric and Antoniadis, Pavlos},
	month = may,
	year = {2015},
	file = {2015.MAESTRI_ANTONIADIS_Notation_as_instrument.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_TENOR/2015/2015.MAESTRI_ANTONIADIS_Notation_as_instrument.pdf:application/pdf}
}

@inproceedings{antoniadis_gesture_2014,
	address = {Berlin, Germany},
	title = {Gesture cutting through textual complexity: {Towards} a tool for online gestural analysis and control of complex piano notation processing},
	url = {https://hal.archives-ouvertes.fr/hal-02158741},
	booktitle = {Conference on {Interdisciplinary} {Musicology}},
	author = {Antoniadis, Pavlos and Bevilacqua, Frédéric and Fober, Dominique},
	year = {2014}
}

@book{nattiez_musicologie_1987,
	title = {Musicologie générale et sémiologie},
	publisher = {C. Bourgois},
	author = {Nattiez, Jean-Jacques},
	year = {1987}
}

@book{mclean_oxford_2018,
	title = {The {Oxford} handbook of algorithmic music},
	isbn = {978-0-19-022699-2},
	language = {En},
	publisher = {Oxford University Press},
	editor = {McLean, Alex and Dean, Roger T.},
	year = {2018}
}

@article{clay_preface_2010,
	title = {Preface : {Virtual} {Scores} and {Real}-{Time} {Playing}},
	volume = {29},
	url = {https://doi.org/10.1080/07494467.2010.509587},
	doi = {10.1080/07494467.2010.509587},
	number = {1},
	journal = {Contemporary Music Review},
	author = {Clay, Arthur and Freeman, Jason},
	year = {2010},
	pages = {1--1}
}

@article{rebelo_notating_2010,
	title = {Notating the unpredictable},
	volume = {29},
	number = {1},
	journal = {Contemporary Music Review},
	author = {Rebelo, Pedro},
	year = {2010},
	pages = {17--27},
	file = {rebelo2010.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Contemporary Music Review/2010/Virtual scores and realtime playing/rebelo2010.pdf:application/pdf}
}

@inproceedings{siu_shapeshift_2018,
	title = {Shapeshift : 2D spatial manipulation and self-actuation of tabletop shape displays for tangible and haptic interaction},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Siu, Alexa F and Gonzalez, Eric J and Yuan, Shenli and Ginsberg, Jason B and Follmer, Sean},
	year = {2018},
	pages = {291}
}

@inproceedings{follmer_inform_2013,
	title = {{inFORM} : dynamic physical affordances and constraints through shape and object actuation.},
	volume = {13},
	booktitle = {Uist},
	author = {Follmer, Sean and Leithinger, Daniel and Olwal, Alex and Hogge, Akimitsu and Ishii, Hiroshi},
	year = {2013},
	pages = {417--426}
}

@inproceedings{collins_bbcut_2002,
	title = {The {BBCut} {Library}},
	url = {http://hdl.handle.net/2027/spo.bbp2372.2002.064},
	booktitle = {Proceedings of the 2002 {International} {Computer} {Music} {Conference}, {ICMC} 2002, {Gothenburg}, {Sweden}, {September} 16-21, 2002},
	author = {Collins, Nick},
	year = {2002}
}

@article{ames_statistics_1990,
	title = {Statistics and {Compositional} {Balance}},
	volume = {28},
	issn = {00316016},
	url = {http://www.jstor.org/stable/833345},
	number = {1},
	journal = {Perspectives of New Music},
	author = {Ames, Charles},
	year = {1990},
	pages = {80--111}
}

@article{patino-lakatos_paradigmes_2019,
	title = {Paradigmes et expériences pour une sémiotisation des sensations vibrotactiles},
	volume = {13},
	issn = {1875-0672},
	url = {http://www.sciencedirect.com/science/article/pii/S1875067218301433},
	doi = {https://doi.org/10.1016/j.alter.2019.03.002},
	abstract = {Résumé La perception des vibrations est une composante essentielle de l’expérience du sujet pour l’appréhension de son environnement. Cet article présente une réflexion conceptuelle sur les conditions de possibilité de l’expérience des vibrations dans le champ de la musique, au croisement des médiations corporelles, psychosociales, technologiques et sémiotiques. Prenant appui sur trois expériences exploratoires, cette étude vise à articuler une approche psychologique et sémiotique de l’expérience sensorielle avec les avancées scientifiques et technologiques répertoriées dans les domaines de l’acoustique et de la musique. Les vibrations sont étudiées en tant que « retour sensoriel » et « canal d’information » potentiel pour la communication intersubjective dans l’expérience musicale partagée, par des personnes valides et en situation de handicap perceptif. La pratique musicale revêt un caractère exemplaire et généralisable sous certains aspects à toute activité exigeante du quotidien, dans une situation individuelle ou collective. The perception of vibrations is an essential component of the subject's experience for the apprehension of his environment. This article presents a conceptual reflection on the conditions of possibility of the experience of vibrations in the field of music, at the intersection of bodily, psychosocial, technological and semiotic mediations. Based on three exploratory experiences, this study aims to articulate a psychological and semiotic approach to sensory experience with scientific and technological advances in the fields of acoustics and music. Vibrations are studied as a potential “sensory feedback” and “information channel” for intersubjective communication in the shared musical experience by disabled and non-disabled people. The musical practice has an exemplary character and generalizable in certain aspects to any demanding activity of everyday life, in an individual or collective situation.},
	number = {3},
	journal = {Alter},
	author = {Patiño-Lakatos, Gabriela and Navarret, Benoît and Genevois, Hugues},
	year = {2019},
	keywords = {Perception, Interprétation musicale, Music performance, Retour sensoriel, Semiosis, Sémiotique, Sensory feedback, Vibrations},
	pages = {155 -- 167}
}

@inproceedings{birnbaum_systematic_2007,
	title = {A {Systematic} {Approach} to {Musical} vibrotactile feedback.},
	abstract = {This paper presents a new approach to the integration of vibrotactile feedback into digital musical instruments. A design strategy for musical vibrotactile systems is developed based on stimulator properties and neurophysiological studies of vibrotactile perception. A software vibration synthesizer driven by perceptual sound features extracted from audio feedback has been created based on these concepts. This framework will help to simplify integration of vibrotactile feedback into instrument designs by deﬁning high-order tactile invariants, avoiding the need to explicitly specify low-level vibration stimulus parameters.},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Birnbaum, David and Wanderley, Marcelo M},
	year = {2007},
	file = {BirnbaumWanderley_SystematicApproachToMusicalVibrotatileFeedback.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/2007/BirnbaumWanderley_SystematicApproachToMusicalVibrotatileFeedback.pdf:application/pdf}
}

@article{heikkila_discovering_2011,
	title = {Discovering novel computer music techniques by exploring the space of short computer programs},
	volume = {abs/1112.1368},
	url = {http://arxiv.org/abs/1112.1368},
	journal = {CoRR},
	author = {Heikkilä, Ville-Matias},
	year = {2011}
}

@book{couturier_utilisation_2004,
	title = {Utilisation avancée d'interfaces graphiques dans le contrôle gestuel de processus sonores},
	url = {https://hal.archives-ouvertes.fr/hal-00088635},
	author = {Couturier, Jean-Michel},
	year = {2004},
	annote = {Université de la Méditerranée - Aix-Marseille II},
	file = {2004.PhD.Couturier.Utilisation avancée d’interfaces graphiques.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2004.PhD.Couturier.Utilisation avancée d’interfaces graphiques.pdf:application/pdf}
}

@inproceedings{feugere_chorus_2011,
	address = {Vancouver, Canada},
	title = {Chorus {Digitalis}: polyphonic gestural singing},
	url = {https://hal.archives-ouvertes.fr/hal-02151340},
	booktitle = {1st {International} {Workshop} on {Performative} {Speech} and {Singing} {Synthesis} ({P}3S 2011)},
	author = {Feugère, Lionel and Le Beux, Sylvain and D'Alessandro, Christophe},
	month = mar,
	year = {2011},
	keywords = {Gestural Control, electronic music, Singing Synthesis, virtual choir}
}

@inproceedings{yu_tuic_2011,
	title = {{TUIC} : enabling tangible interaction on capacitive multi-touch displays},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yu, Neng-Hao and Chan, Li-Wei and Lau, Seng Yong and Tsai, Sung-Sheng and Hsiao, I-Chun and Tsai, Dian-Je and Hsiao, Fang-I and Cheng, Lung-Pan and Chen, Mike and Huang, Polly and {others}},
	year = {2011},
	pages = {2995--3004}
}

@inproceedings{rekimoto_datatiles_2001,
	title = {{DataTiles} : a modular platform for mixed physical and graphical interactions},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems},
	publisher = {ACM},
	author = {Rekimoto, Jun and Ullmer, Brygg and Oba, Haruo},
	year = {2001},
	pages = {269--276}
}

@incollection{donnarumma_biophysical_2017,
	title = {On {Biophysical} {Music}},
	booktitle = {Guide to {Unconventional} {Computing} for {Music}},
	publisher = {Springer},
	author = {Donnarumma, Marco},
	year = {2017},
	pages = {63--83}
}

@article{stoppa_wearable_2014,
	title = {Wearable electronics and smart textiles: a critical review},
	volume = {14},
	number = {7},
	journal = {sensors},
	author = {Stoppa, Matteo and Chiolerio, Alessandro},
	year = {2014},
	pages = {11957--11992}
}

@inproceedings{marshall_sensor_2009,
	title = {Sensor {Choice} for {Parameter} {Modulations} in {Digital} {Musical} {Instruments}: {Empirical} {Evidence} from {Pitch} {Modulation}},
	author = {Marshall, Mark T. and Hartshorn, Max and Wanderley, Marcelo M. and Levitin, Daniel J.},
	year = {2009}
}

@inproceedings{hollinger_evaluation_2006,
	title = {Evaluation of commercial force-sensing resistors},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}, {Paris}, {France}},
	author = {Hollinger, Avrum and Wanderley, Marcelo M},
	year = {2006},
	pages = {4--8}
}

@article{wanderley_evaluation_2002,
	title = {Evaluation of input devices for musical expression: {Borrowing} tools from hci},
	volume = {26},
	number = {3},
	journal = {Computer Music Journal},
	author = {Wanderley, Marcelo Mortensen and Orio, Nicola},
	year = {2002},
	pages = {62--76},
	file = {2002.Wanderley.Evaluation of Input Devices for Musical Expression.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_CMJ_ComputerMusicJournal/2002/2002.Wanderley.Evaluation of Input Devices for Musical Expression.pdf:application/pdf}
}

@article{medeiros_comprehensive_2014,
	title = {A comprehensive review of sensors and instrumentation methods in devices for musical expression},
	volume = {14},
	number = {8},
	journal = {Sensors},
	author = {Medeiros, Carolina and Wanderley, Marcelo},
	year = {2014},
	pages = {13556--13591}
}

@incollection{malloch_design_2019,
	title = {A design {WorkBench} for interactive music systems},
	booktitle = {New {Directions} in {Music} and {Human}-{Computer} {Interaction}},
	publisher = {Springer},
	author = {Malloch, Joseph and Garcia, Jérémie and Wanderley, Marcelo M and Mackay, Wendy E and Beaudouin-Lafon, Michel and Huot, Stéphane},
	year = {2019},
	pages = {23--40},
	file = {Malloch_et_al_MIDWAY_Design_workbench_AV.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/New Directions in Music and Human-Computer Interaction/Malloch_et_al_MIDWAY_Design_workbench_AV.pdf:application/pdf}
}

@inproceedings{dey_distributed_2001,
	title = {Distributed and disappearing user interfaces in ubiquitous computing},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.1832&rep=rep1&type=pdf},
	booktitle = {{CHI}'01 extended abstracts on {Human} factors in computing systems},
	publisher = {ACM},
	author = {Dey, Anind K and Ljungstrand, Peter and Schmidt, Albrecht},
	year = {2001},
	pages = {487--488}
}

@article{hui_towards_2017,
	title = {Towards disappearing user interfaces for ubiquitous computing: human enhancement from sixth sense to super senses},
	volume = {8},
	url = {https://link.springer.com/content/pdf/10.1007%2Fs12652-016-0409-9.pdf},
	number = {3},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Hui, Terence KL and Sherratt, R Simon},
	year = {2017},
	pages = {449--465}
}

@article{weiser_computer_1991,
	title = {The {Computer} for the 21 st {Century}},
	volume = {265},
	number = {3},
	journal = {Scientific american},
	author = {Weiser, Mark},
	year = {1991},
	pages = {94--105}
}

@book{leman_embodied_2008,
	title = {Embodied music cognition and mediation technology},
	publisher = {Mit Press},
	author = {Leman, Marc},
	year = {2008},
	file = {Embodied-Music-Cognition-and-Mediation-Technology.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Leman, Marc/Embodied-Music-Cognition-and-Mediation-Technology.pdf:application/pdf}
}

@article{ryan_remarks_1991,
	title = {Some remarks on musical instrument design at {STEIM}},
	volume = {6},
	number = {1},
	journal = {Contemporary music review},
	author = {Ryan, Joel},
	year = {1991},
	pages = {3--17},
	file = {1991.Ryan.Some_remarks_on_musical_instrument_desig.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Contemporary Music Review/1991/1991.Ryan.Some_remarks_on_musical_instrument_desig.pdf:application/pdf}
}

@article{donnarumma_muscular_2013,
	title = {Muscular {Interactions} {Combining} {EMG} and {MMG} sensing for musical practice},
	author = {Donnarumma, Marco and Caramiaux, Baptiste and Tanaka, Atau},
	year = {2013}
}

@article{tanaka_body_2019,
	title = {The body as musical instrument},
	journal = {The Oxford Handbook of Music and the Body},
	author = {Tanaka, Atau and Donnarumma, Marco},
	year = {2019},
	pages = {79}
}

@book{kim_oxford_2019,
	title = {The {Oxford} {Handbook} of {Music} and the {Body}},
	publisher = {Oxford University Press},
	author = {Kim, Youn and Gilman, Sander L},
	year = {2019}
}

@incollection{bevilacqua_gesture_2011,
	title = {Gesture capture: {Paradigms} in interactive music/dance systems},
	volume = {183},
	booktitle = {Emerging {Bodies}: {The} {Performance} of {Worldmaking} in {Dance} and {Choreography}},
	publisher = {transcript Verlag},
	author = {Bevilacqua, Frédéric and Schnell, Norbert and Fdili Alaoui, Sarah},
	editor = {Klein, Gabriele and Noeth, Sandra},
	year = {2011},
	pages = {183--193}
}

@inproceedings{zappi_design_2014,
	title = {Design and use of a hackable digital instrument},
	booktitle = {Proceedings of the {International} {Conference} on {Live} {Interfaces}},
	author = {Zappi, Victor and McPherson, Andrew},
	year = {2014}
}

@article{noll_cepstrum_1967,
	title = {Cepstrum pitch determination},
	volume = {41},
	number = {2},
	journal = {The journal of the acoustical society of America},
	author = {Noll, A Michael},
	year = {1967},
	pages = {293--309}
}

@inproceedings{boersma_accurate_1993,
	title = {Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound},
	volume = {17},
	booktitle = {Proceedings of the institute of phonetic sciences},
	publisher = {Amsterdam},
	author = {Boersma, Paul},
	year = {1993},
	pages = {97--110}
}

@article{pardue_low-cost_2015,
	title = {A low-cost real-time tracking system for violin},
	volume = {44},
	number = {4},
	journal = {Journal of New Music Research},
	author = {Pardue, Laurel S and Harte, Christopher and McPherson, Andrew P},
	year = {2015},
	pages = {305--323}
}

@article{de_cheveigne_yin_2002,
	title = {{YIN}, a fundamental frequency estimator for speech and music},
	volume = {111},
	number = {4},
	journal = {The Journal of the Acoustical Society of America},
	author = {De Cheveigné, Alain and Kawahara, Hideki},
	year = {2002},
	pages = {1917--1930}
}

@inproceedings{magnusson_ergomimesis_2018,
	title = {Ergomimesis : towards a language describing instrumental transductions},
	booktitle = {Proceedings: {ICLI} 2018, 4th {International} {Conference} on {Live} {Interfaces}. {Inspiration}, {Performance}, {Emancipation}.},
	publisher = {Universidade do Porto},
	author = {Magnusson, Thor},
	year = {2018},
	pages = {78--85},
	file = {2018.Magnusson.Ergomimesis.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICLI/2018/2018.Magnusson.Ergomimesis.pdf:application/pdf}
}

@article{meurisse_active_2015,
	title = {An active mute for the trombone},
	volume = {138},
	url = {https://doi.org/10.1121/1.4936901},
	doi = {10.1121/1.4936901},
	number = {6},
	journal = {The Journal of the Acoustical Society of America},
	author = {Meurisse, Thibaut and Mamou-Mani, Adrien and Caussé, René and Sluchin, Benny and Sharp, David B.},
	year = {2015},
	pages = {3539--3548},
	file = {2015.Meurisse.ActiveMuteForTrimbone.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JASA_JournalAcousticSocietyOfAmerica/2015.Meurisse.ActiveMuteForTrimbone.pdf:application/pdf}
}

@article{benacchio_mode_2015,
	title = {Mode tuning of a simplified string instrument using time-dimensionless state-derivative control},
	volume = {334},
	issn = {0022-460X},
	url = {http://www.sciencedirect.com/science/article/pii/S0022460X14007160},
	doi = {https://doi.org/10.1016/j.jsv.2014.09.003},
	abstract = {In recent years, there has been a growing interest in smart structures, particularly in the field of musical acoustics. Control methods, initially developed to reduce vibration and damage, can be a good way to shift modal parameters of a structure in order to modify its dynamic response. This study focuses on smart musical instruments and aims to modify their radiated sound. This is achieved by controlling the modal parameters of the soundboard of a simplified string instrument. A method combining a pole placement algorithm and a time-dimensionless state-derivative control is used and quickly compared to a usual state control method. Then the effect of the mode tuning on the coupling between the string and the soundboard is experimentally studied. Controlling two vibration modes of the soundboard, its acoustic response and the damping of the third partial of the sound are modified. Finally these effects are listened in the radiated sound.},
	journal = {Journal of Sound and Vibration},
	author = {Benacchio, Simon and Chomette, Baptiste and Mamou-Mani, Adrien and Finel, Victor},
	year = {2015},
	pages = {178 -- 189},
	file = {2014.Benacchio.ModeTuningOfSimplifiedStringInstrument.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JSVI_JournalOfSoundAndVibration/2014.Benacchio.ModeTuningOfSimplifiedStringInstrument.pdf:application/pdf}
}

@inproceedings{benacchio_active_2013,
	title = {Active control of string instruments using {Xenomai}},
	booktitle = {Proc. of the {Fifteenth} real-{Time} linux {Workshop}},
	author = {Benacchio, Simon and Piéchaud, Robert and Mamou-Mani, Adrien and Chomette, B and Finel, V},
	year = {2013},
	pages = {133--141}
}

@inproceedings{boutin_modal_2012,
	address = {Nantes, France},
	title = {A modal method adapted to the active control of a xylophone bar},
	url = {https://hal.archives-ouvertes.fr/hal-00811148},
	booktitle = {Acoustics 2012},
	author = {BOUTIN, Henri and BESNAINOU, Charles},
	editor = {d'Acoustique, Société Française},
	month = apr,
	year = {2012},
	keywords = {DSP, active control, peaks of resonance, xylophone bar},
	file = {2012.Boutin.ModalMethodActiveControlXylophone.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_Acoustics/2012.Boutin.ModalMethodActiveControlXylophone.pdf:application/pdf}
}

@phdthesis{boutin_active_2011,
	type = {Theses},
	title = {Active control methods of musical instruments. {Cases} of the xylophone bar and the violin.},
	url = {https://hal.archives-ouvertes.fr/tel-01369165},
	school = {UPMC - Université Paris 6 Pierre et Marie Curie},
	author = {Boutin, Henri},
	month = nov,
	year = {2011},
	keywords = {Violin, Bending modes, Bridge Hill, Contrôle actif Modal, Flexion, Modal active control, PVDF transducer, Transducteur PVDF, Violon, Xylophone, Xylophone bar}
}

@inproceedings{muller_minimal_2019,
	address = {Birmingham, Royaume-Uni},
	title = {A minimal passive model of the operational amplifier: application to sallen-key analog filters},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Digital} {Audio} {Effects}},
	author = {Müller, Remy and Hélie, Thomas},
	year = {2019}
}

@inproceedings{muller_power-balanced_2018,
	address = {Aveiro, Portugal},
	title = {Power-{Balanced} {Modelling} {Of} {Circuits} {As} {Skew} {Gradient} {Systems}},
	url = {http://dafx2018.web.ua.pt/papers/DAFx2018_paper_13.pdf},
	booktitle = {Proceedings of the 21stInternational {Conference} on {Digital} {Audio} {Effects} (},
	author = {Muller, Rémy and Hélie, Thomas},
	year = {2018}
}

@article{wijnand_controactif_2019,
	title = {Contrôle actif des modes axisymétriques d'un tom: {Système} {Hamiltonien} à {Ports} et perspectives},
	author = {Wijnand, Marc and d'Andréa-Novel, Brigitte and Fabre, Benoît and Hélie, Thomas and Rosier, Lionel and Roze, David},
	year = {2019}
}

@inproceedings{muller_trajectory_2017,
	address = {Edinburgh, Royaume-Uni},
	title = {Trajectory anti-aliasing on guaranteed-passive simulation of nonlinear physical systems},
	url = {https://hal.archives-ouvertes.fr/hal-01550618/document},
	abstract = {This article is concerned with the accurate simulation of passivenonlinear dynamical systems with a particular attention paid onaliasing reduction in the pass-band. The approach is based on thecombination of Port-Hamiltonian Systems, continuous-time state-space trajectories reconstruction and exact continuous-time anti-aliasing filter realization. The proposed framework is applied ona nonlinear LC oscillator circuit to study the effectiveness of themethod.},
	booktitle = {Proceedings of the 20thInternational {Conference} on {Digital} {Audio} {Effects}},
	author = {Müller, Remy and Hélie, Thomas},
	year = {2017}
}

@article{falaize_passive_2018,
	title = {Passive modelling of the electrodynamic loudspeaker: from the {Thiele}-{Small} model to nonlinear {Port}-{Hamiltonian} {Systems}},
	author = {Falaize, Antoine and Hélie, Thomas},
	year = {2018}
}

@inproceedings{bader_self-actuated_2015,
	address = {Bamberg, Germany},
	series = {Human-{Computer} {Interaction} – {INTERACT} 2015},
	title = {Self-{Actuated} {Displays} for {Vertical} {Surfaces}},
	volume = {LNCS-9299},
	url = {https://hal.inria.fr/hal-01610769},
	doi = {10.1007/978-3-319-22723-8_23},
	booktitle = {15th {Human}-{Computer} {Interaction} ({INTERACT})},
	author = {Bader, Patrick and Schwind, Valentin and Pohl, Norman and Henze, Niels and Wolf, Katrin and Schneegass, Stefan and Schmidt, Albrecht},
	month = sep,
	year = {2015},
	keywords = {Mobile, Display, Self-actuated, Vertical surface},
	pages = {282--299}
}

@book{omodhrain_playing_2001,
	title = {Playing by feel: incorporating haptic feedback into computer-based musical instruments},
	publisher = {Stanford University},
	author = {O'Modhrain, Maura Sile},
	year = {2001}
}

@inproceedings{follmer_inform_2013-1,
	title = {{inFORM} : dynamic physical affordances and constraints through shape and object actuation.},
	volume = {13},
	booktitle = {Uist},
	author = {Follmer, Sean and Leithinger, Daniel and Olwal, Alex and Hogge, Akimitsu and Ishii, Hiroshi},
	year = {2013},
	pages = {417--426}
}

@inproceedings{sinclair_touchmover_2013,
	title = {{TouchMover} : actuated 3D touchscreen with haptic feedback},
	booktitle = {Proceedings of the 2013 {ACM} international conference on {Interactive} tabletops and surfaces},
	publisher = {ACM},
	author = {Sinclair, Mike and Pahud, Michel and Benko, Hrvoje},
	year = {2013},
	pages = {287--296}
}

@article{fitts_information_1954,
	title = {The information capacity of the human motor system in controlling the amplitude of movement.},
	volume = {47},
	number = {6},
	journal = {Journal of experimental psychology},
	author = {Fitts, Paul M},
	year = {1954},
	pages = {381}
}

@book{bregman_auditory_1994,
	title = {Auditory scene analysis: {The} perceptual organization of sound},
	publisher = {MIT press},
	author = {Bregman, Albert S},
	year = {1994},
	file = {Albert S. Bregman - Auditory Scene Analysis_ The Perceptual Organization of Sound-The MIT Press (1994).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Bregman, Albert/Albert S. Bregman - Auditory Scene Analysis_ The Perceptual Organization of Sound-The MIT Press (1994).pdf:application/pdf}
}

@book{deutsch_psychology_2013,
	title = {Psychology of music},
	publisher = {Elsevier},
	author = {Deutsch, Diana},
	year = {2013},
	file = {Diana Deutsch (Auth.) - The Psychology of Music (2013).pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Deutsch, Diana/Diana Deutsch (Auth.) - The Psychology of Music (2013).pdf:application/pdf}
}

@inproceedings{janin_multi-scale_2013,
	address = {Stockholm, Sweden},
	title = {Multi-scale design of interactive music systems : the {libTuiles} experiment},
	url = {https://hal.archives-ouvertes.fr/hal-00813313},
	booktitle = {{SMC} 2013},
	author = {Janin, David and Berthaut, Florent and Desainte-Catherine, Myriam},
	editor = {Bresin, Roberto},
	year = {2013},
	keywords = {Music modeling, music system, tiled signal algebra},
	pages = {123--129},
	file = {2013.Janin.libTuile.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_SMC/2013/2013.Janin.libTuile.pdf:application/pdf}
}

@article{desainte-catherine_interactive_2005,
	title = {Interactive scores: {A} model for specifying temporal relations between interactive and static events},
	volume = {34},
	url = {https://hal.archives-ouvertes.fr/file/index/docid/307925/filename/mdc-aa05.pdf},
	number = {4},
	journal = {Journal of New Music Research},
	author = {Desainte-Catherine, Myriam and Allombert, Antoine},
	year = {2005},
	pages = {361--374},
	file = {2005.Allombert.InteractiveScores.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_JNMR_JournalOfNewMusicResearch/2005.Allombert.InteractiveScores.pdf:application/pdf}
}

@inproceedings{de_la_hogue_jamoma_2011,
	title = {Jamoma {Modular}: une librairie {C}++ dediee au developpement d’applications modulaires pour la creation},
	url = {http://jamoma.org/publications/attachments/JIM11-JamomaModular-FR.pdf},
	language = {fr},
	booktitle = {Actes des {Journées} d'{Informatique} {Musicale}},
	author = {De La Hogue, Théo and Rabin, Julien and Garnier, Laurent},
	year = {2011}
}

@article{miranda_i-berlioz:_2019,
	title = {i-{Berlioz}: {Towards} {Interactive} {Computer}-{Aided} {Orchestration} with {Temporal} {Control}},
	url = {http://www.ijmsta.com/Vol_1_1_Papers/IJMSTA_Paper_3.pdf},
	author = {Miranda, ER and Antoine, A and Celerier, JM and Desainte-Catherine, M},
	year = {2019}
}

@inproceedings{celerier_ossia:_2015,
	address = {Paris, France},
	title = {{OSSIA}: {Towards} a unified interface for scoring time and interaction},
	url = {https://hal.archives-ouvertes.fr/hal-01245957},
	booktitle = {{TENOR}2015},
	author = {Celerier, Jean-Michaël and Baltazar, Pascal and Bossut, Clément and Vuaille, Nicolas and Couturier, Jean-Michel and Desainte-Catherine, Myriam},
	month = may,
	year = {2015}
}

@inproceedings{desainte-catherine_time_2002,
	title = {Time {Modeling} for {Musical} {Composition}},
	booktitle = {{FSDK}'02, {Proceedings} of the 1st {International} {Conference} on {Fuzzy} {Systems} and {Knowledge} {Discovery}: {Computational} {Intelligence} for the {E}-{Age}, 2 {Volumes}, {November} 18-22, 2002, {Orchid} {Country} {Club}, {Singapore}},
	author = {Desainte-Catherine, Myriam and Beurivé, Anthony},
	year = {2002},
	pages = {394--400}
}

@inproceedings{beurive_logiciel_2000,
	title = {Un  logiciel  de  composition  musicale combinant un modèle spectral, des structures hiérarchiques  et  des  contraintes.},
	booktitle = {Actes des {Journées} d'{Informatique} {Musicale}},
	author = {Beurivé, Anthony},
	year = {2000}
}

@inproceedings{alaoui_movement_2012,
	title = {Movement qualities as interaction modality},
	url = {http://saralaoui.com/wp-content/uploads/2015/08/alaoui2012movement.pdf},
	booktitle = {Proceedings of the {Designing} {Interactive} {Systems} {Conference}},
	publisher = {ACM},
	author = {Alaoui, Sarah Fdili and Caramiaux, Baptiste and Serrano, Marcos and Bevilacqua, Frédéric},
	year = {2012},
	pages = {761--769},
	file = {alaoui2012movement.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_DIS_DesigningInteractiveSystems/2012/alaoui2012movement.pdf:application/pdf}
}

@inproceedings{silang_maranan_designing_2014,
	title = {Designing for movement: evaluating computational models using {LMA} effort qualities},
	url = {http://saralaoui.com/wp-content/uploads/2015/08/CHI2014_LabanEffortDetectPaper-ter-1.pdf},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Silang Maranan, Diego and Fdili Alaoui, Sarah and Schiphorst, Thecla and Pasquier, Philippe and Subyen, Pattarawut and Bartram, Lyn},
	year = {2014},
	pages = {991--1000},
	file = {CHI2014_LabanEffortDetectPaper-ter-1.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/2014/CHI2014_LabanEffortDetectPaper-ter-1.pdf:application/pdf}
}

@article{alaoui_interactive_2015,
	title = {Interactive visuals as metaphors for dance movement qualities},
	volume = {5},
	number = {3},
	journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
	author = {Alaoui, Sarah Fdili and Bevilacqua, Frederic and Jacquemin, Christian},
	year = {2015},
	pages = {13},
	file = {Fdilialaoui-TIIS2015.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_ACM_TiiS/2015/Fdilialaoui-TIIS2015.pdf:application/pdf}
}

@inproceedings{hsueh_understanding_2019,
	title = {Understanding {Kinaesthetic} {Creativity} in {Dance}},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Hsueh, Stacy and Alaoui, Sarah Fdili and Mackay, Wendy E},
	year = {2019},
	pages = {511},
	file = {Hsueh-et-al-CHI2019.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/2019/Hsueh-et-al-CHI2019.pdf:application/pdf}
}

@article{sonami_my_2006,
	title = {On my work},
	volume = {25},
	url = {https://doi.org/10.1080/07494460600990877},
	doi = {10.1080/07494460600990877},
	number = {5-6},
	journal = {Contemporary Music Review},
	author = {Sonami, Laetitia},
	year = {2006},
	pages = {613--614}
}

@inproceedings{goudard_playing_2014,
	address = {Athènes, Greece},
	title = {On the playing of monodic pitch in digital music instruments},
	copyright = {All rights reserved},
	url = {https://hal.archives-ouvertes.fr/hal-01073240},
	booktitle = {{ICMC}/{SMC} 2014},
	publisher = {National and Kapodistrian University of Athens},
	author = {Goudard, Vincent and Genevois, Hugues and Feugère, Lionel},
	editor = {Georgaki, Anastasia and Kouroupetroglou, Giorgos},
	month = sep,
	year = {2014},
	keywords = {computer music, informatique musicale, organologie, organology},
	pages = {1418}
}

@article{verillo_vibration_1991,
	title = {Vibration sensing in humans},
	volume = {9},
	number = {3},
	journal = {Music Perception},
	author = {Verillo, Ronald T},
	year = {1991},
	pages = {281--302},
	file = {1992.Verrillo. Vibration Sensation in Humans.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_MusicPerception/1992.Verrillo. Vibration Sensation in Humans.pdf:application/pdf}
}

@article{bongers_tactual_1998,
	title = {Tactual display of sound properties in electronic musical instruments},
	volume = {18},
	doi = {https://doi.org/10.1016/S0141-9382(98)00013-4},
	number = {3},
	journal = {Displays},
	author = {Bongers, Bert},
	year = {1998},
	pages = {129--133},
	file = {1998.bongers.tactileDisplays.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_ElsevierDisplays/1998.bongers.tactileDisplays.pdf:application/pdf}
}

@incollection{rovan_typology_2000,
	address = {Paris},
	title = {Typology of tactile sounds and their synthesis in gesture-driven computer music performance},
	url = {http://cim.mcgill.ca/~haptic/pub/BR-VH-IRCAM-00.pdf},
	abstract = {In this paper we outline the fundamentals for a tactile feedback system to be used in  conjunction  with open-air  computer   music  performance  devices.  Some underlying physiological and perceptual mechanisms  ofhaptics are examined, some currently  available  open-air  controllers are  reviewed,  and previous  technologiesand experiments regarding haptic/tactile feedback are surveyed. Our VR/TX system is proposed as  a solutionfor adding tactile feedback   to   open-air controllers;   experiments   show   that   the   VR/TX   vibrotactilestimulators provide invaluable  perceptually-significant  tactile  feedback when used  in  conjunction  with  anopen-air music controller. A  typology  of  tactile sound  events  is  also described,  as  well  as  the  notion  of  atactile simulation event (TSE).},
	language = {En},
	booktitle = {Trends in gestural control of music},
	publisher = {IRCAM, Centre Pompidou},
	author = {Rovan, Joseph and Hayward, Vincent},
	editor = {Wanderley, Marcelo M and Battier, Marc},
	year = {2000},
	pages = {297--320},
	file = {2000.Rovan.Typology of tactile sounds.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_BOOKS/Wanderley, Marcello/2000.Rovan.Typology of tactile sounds.pdf:application/pdf}
}

@inproceedings{bongers_tactile_1997,
	address = {London, UK},
	title = {Tactile display in electronic musical instruments},
	volume = {1997},
	url = {https://digital-library.theiet.org/content/conferences/10.1049/ic_19970086},
	doi = {10.1049/ic:19970086},
	abstract = {Unlike acoustical instruments, electronic musical instruments display a synthetic sound source, which in fact can only be heard and not felt. Tactually displaying attributes of the sound (e.g., pitch, volume envelope, timbre) enables the performer to improve muscular control. Several technologies for enhancing tactual display of the sound source, as well as ways of control will be described. For example, input devices such as gloves and gesture trackers and other technologies were adapted from virtual reality research. These developments led to the realisation that the link between sound source and its “feel” was missing. For instance, a sharp sound should have a clearly tangible threshold, and a dull sound a more soft feel.},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {{IEE} {Colloquium} on {Developments} in {Tactile} {Displays}},
	publisher = {IEE},
	author = {Bongers, Bert},
	year = {1997},
	pages = {7--7},
	file = {1997.Bongers.Tactile display in electronic musical instruments.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_ElsevierDisplays/1997.Bongers.Tactile display in electronic musical instruments.pdf:application/pdf}
}

@inproceedings{chafe_tactile_1993,
	title = {Tactile audio feedback},
	url = {https://ccrma.stanford.edu/~cc/pub/pdf/tacAudioFb.pdf},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	publisher = {INTERNATIONAL COMPUTER MUSIC ACCOCIATION},
	author = {Chafe, Chris},
	year = {1993},
	pages = {76--76},
	file = {1993.Chafe.TactileAudioFeedback.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_ICMC_International_Computer_Music_Conference/1993/1993.Chafe.TactileAudioFeedback.pdf:application/pdf}
}

@article{cadoz_fondement_1978,
	title = {Fondement d'une démarche de recherche informatique/musique},
	url = {https://hal.archives-ouvertes.fr/file/index/docid/878818/filename/CF78_Revue_Accoustique.pdf},
	number = {45},
	journal = {Revue d'acoustique},
	author = {Cadoz, Claude and Florens, Jean-Loup},
	year = {1978},
	pages = {86--101},
	file = {1978.CadozFlorens.FondementDemarcheRechercheInformatiqueMusicale.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Revue d'acoustique/1978.CadozFlorens.FondementDemarcheRechercheInformatiqueMusicale.pdf:application/pdf}
}

@inproceedings{luciani_modelisation_1984,
	title = {Modélisation et animation gestuelle d'objets: le systéme {ANIMA}},
	booktitle = {1° {Colloque} {Image}: traitement, synthèse, technologies et applications, {FRA}, 1984},
	publisher = {GRETSI, Groupe d’Etudes du Traitement du Signal et des Images},
	author = {LUCIANI, Anasthasie and Cadoz, Claude},
	year = {1984}
}

@inproceedings{oney_implementing_2019-1,
	address = {New York, NY, USA},
	series = {{CHI} '19},
	title = {Implementing {Multi}-{Touch} {Gestures} with {Touch} {Groups} and {Cross} {Events}},
	isbn = {978-1-4503-5970-2},
	url = {http://doi.acm.org/10.1145/3290605.3300585},
	doi = {10.1145/3290605.3300585},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Oney, Steve and Krosnick, Rebecca and Brandt, Joel and Myers, Brad},
	year = {2019},
	note = {event-place: Glasgow, Scotland Uk},
	keywords = {multi-touch, programming, frameworks, software development},
	pages = {355:1--355:12},
	file = {touchstate.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/2019/touchstate.pdf:application/pdf}
}

@book{hegarty_noise_2007,
	title = {Noise {Music}: {A} {History}},
	isbn = {0-8264-1727-2},
	url = {https://www.xarg.org/ref/a/0826417272/},
	publisher = {Continuum},
	author = {Hegarty, Paul},
	month = aug,
	year = {2007}
}

@phdthesis{benhaim_aux_2018,
	type = {{PhD} {Thesis}},
	title = {Aux marges du bruit. {Une} étude de la musique noise et du {Do} it {Yourself}},
	author = {Benhaim, Sarah},
	year = {2018},
	file = {2018.PhD.Sarah_Benhaim.Noise.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2018.PhD.Sarah_Benhaim.Noise.pdf:application/pdf}
}

@phdthesis{fdili_alaoui_dance_2012,
	type = {Theses},
	title = {Dance {Gesture} {Analysis} and {Visual} {Feedback} based on {Physical} {Models} : {Contributions} of {Movement} {Qualities} in {Whole} {Body} {Interaction}},
	url = {https://tel.archives-ouvertes.fr/tel-00805519},
	school = {Université Paris Sud - Paris XI},
	author = {Fdili Alaoui, Sarah},
	month = dec,
	year = {2012},
	keywords = {Gesture recognition, Gesture analysis, Analyse de gestes, Art-science, Augmented performance, Dance gesture, Expérience utilisateur, Expressive gesture, Geste dansé, Geste expressif, Interaction du corps entier, Interaction techniques, Mass-springs systems, Modèles masses-ressorts, Movement qualities, Performance augmentée, Qualités de mouvement, Reconnaissance de gestes, Retours visuels par modèles physiques, Techniques d'interaction, User experience, Visuals feedback based on physical models, Whole body interaction},
	file = {2012.PhD.FdiliAlaoui.AnalyseDuGesteDanse.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2012.PhD.FdiliAlaoui.AnalyseDuGesteDanse.pdf:application/pdf}
}

@article{geoffroy_geste_2006,
	title = {Le geste dans l’oeuvre musicale, la musique et le mouvement},
	url = {http://archive.grame.fr/Recherche/Rencontres/Ressources/RMPD/RMPD2006/pdf2006/geoffroy-v3.pdf},
	urldate = {2019-09-25},
	journal = {Rencontres musicales pluridisciplinaires},
	author = {Geoffroy, Jean},
	year = {2006},
	pages = {15--26},
	file = {2006.Geoffroy.Le geste dans l’oeuvre musicale la musique et le mouvement.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_RecontresMusicalesPluridisciplinaires/2006/2006.Geoffroy.Le geste dans l’oeuvre musicale la musique et le mouvement.pdf:application/pdf}
}

@article{rime_gesture_1991,
	title = {Gesture and speech.},
	author = {Rimé, Bernard and Schiaratura, Loris},
	year = {1991}
}

@incollection{rime_gesture_1991-1,
	address = {Paris,  France},
	series = {Studies in emotion \& social interaction.},
	title = {Gesture and speech.},
	isbn = {0-521-36388-8 (Hardcover); 0-521-36700-X (Paperback)},
	abstract = {examine the function of gestural motor activity during speech / after reviewing the literature, their own research, and the problem of the classification of hand gestures, they conclude that gestures are inextricably linked to verbal encoding processes (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	booktitle = {Fundamentals of nonverbal behavior.},
	publisher = {Editions de la Maison des Sciences de l'Homme},
	author = {Rimé, Bernard and Schiaratura, Loris},
	year = {1991},
	keywords = {*Gestures, Oral Communication},
	pages = {239--281}
}

@article{pelachaud_studies_2009,
	title = {Studies on gesture expressivity for a virtual agent},
	volume = {51},
	doi = {10.1016/j.specom.2008.04.009},
	journal = {Speech Communication},
	author = {Pelachaud, Catherine},
	year = {2009},
	pages = {630--639},
	file = {Studies_on_gesture_expressivity_for_a_virtual_agen.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_SpeechCommunication/Studies_on_gesture_expressivity_for_a_virtual_agen.pdf:application/pdf}
}

@article{gallaher_individual_1992,
	title = {Individual differences in nonverbal behavior: {Dimensions} of style.},
	volume = {63},
	number = {1},
	journal = {Journal of personality and social psychology},
	author = {Gallaher, Peggy E},
	year = {1992},
	pages = {133}
}

@article{jodlowski_geste_2006,
	title = {Le {Geste} question de composition},
	volume = {2},
	url = {http://www.pierrejodlowski.fr/site/index.php?post/2011},
	language = {fr},
	journal = {L'inouï, revue de l'Ircam},
	author = {Jodlowski, Pierre},
	year = {2006}
}

@inproceedings{reeves_designing_2005,
	title = {Designing the spectator experience},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems},
	publisher = {ACM},
	author = {Reeves, Stuart and Benford, Steve and O'Malley, Claire and Fraser, Mike},
	year = {2005},
	pages = {741--750},
	file = {2005.Reeves.designing spectators exprience.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/2005/2005.Reeves.designing spectators exprience.pdf:application/pdf}
}

@book{benjamin_loeuvre_2013,
	title = {L'œuvre d'art à l'époque de sa reproductibilité technique},
	publisher = {Éditions Payot},
	author = {Benjamin, Walter},
	year = {2013},
	note = {(Première édition du texte final : 1939)}
}

@inproceedings{cadoz_synthese_1983,
	title = {Synthèse sonore par modélisation mécanique de l'instrument: le langage {CORDIS}},
	author = {Cadoz, Claude and Luciani, Annie and Florens, Jean-Loup},
	year = {1983}
}

@article{macdonald_visual_1978,
	title = {Visual influences on speech perception processes},
	volume = {24},
	number = {3},
	journal = {Perception \& Psychophysics},
	author = {MacDonald, John and McGurk, Harry},
	year = {1978},
	pages = {253--257}
}

@article{mcgurk_hearing_1976,
	title = {Hearing lips and seeing voices},
	volume = {264},
	number = {5588},
	journal = {Nature},
	author = {McGurk, Harry and MacDonald, John},
	year = {1976},
	pages = {746}
}

@book{bachelard_air_1943,
	address = {Paris},
	title = {L'{Air} {Et} {Les} {Songes}: {Essai} {Sur} l'{Imagination} {Du} {Mouvement}},
	publisher = {José Corti},
	author = {Bachelard, Gaston},
	year = {1943}
}

@inproceedings{fiebrink_wekinator:_2010,
	title = {The {Wekinator}: a system for real-time, interactive machine learning in music},
	booktitle = {Proceedings of {The} {Eleventh} {International} {Society} for {Music} {Information} {Retrieval} {Conference} ({ISMIR} 2010)({Utrecht})},
	author = {Fiebrink, Rebecca and Cook, Perry R},
	year = {2010}
}

@inproceedings{assayag_omax_2006,
	title = {Omax brothers: a dynamic yopology of agents for improvization learning},
	booktitle = {Proceedings of the 1st {ACM} workshop on {Audio} and music computing multimedia},
	publisher = {ACM},
	author = {Assayag, Gérard and Bloch, Georges and Chemillier, Marc and Cont, Arshia and Dubnov, Shlomo},
	year = {2006},
	pages = {125--132}
}

@article{pachet_continuator:_2003,
	title = {The continuator: {Musical} interaction with style},
	volume = {32},
	number = {3},
	journal = {Journal of New Music Research},
	author = {Pachet, Francois},
	year = {2003},
	pages = {333--341}
}

@article{picard_chine:_1991,
	title = {Chine: le xiao, ou souffle sonorisé},
	url = {https://journals.openedition.org/ethnomusicologie/639},
	number = {4},
	journal = {Cahiers d’ethnomusicologie. Anciennement Cahiers de musiques traditionnelles},
	author = {Picard, François},
	year = {1991},
	pages = {17--26}
}

@book{during_quelque_1994,
	title = {Quelque chose se passe: le sens de la tradition dans l'{Orient} musical},
	publisher = {Verdier},
	author = {During, Jean},
	year = {1994}
}

@article{emerson_gesture-sound_2018,
	title = {Gesture-sound causality from the audience’s perspective: {Investigating} the aesthetic experience of performances with digital musical instruments.},
	volume = {12},
	number = {1},
	journal = {Psychology of Aesthetics, Creativity, and the Arts},
	author = {Emerson, Gina and Egermann, Hauke},
	year = {2018},
	pages = {96}
}

@book{michotte_perception_2017,
	title = {The perception of causality},
	publisher = {Routledge},
	author = {Michotte, Albert},
	year = {2017}
}

@inproceedings{marshall_deception_2010,
	title = {Deception and magic in collaborative interaction},
	url = {http://www.cs.nott.ac.uk/~pszjm2/uploads/2010/04/marshall-chi-deception.pdf},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Marshall, Joe and Benford, Steve and Pridmore, Tony},
	year = {2010},
	pages = {567--576},
	file = {2010.Marshall.DeceptionAndMagicInCollaborativeInteraction.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_CONFERENCES/_CHI_ComputerHumanInteraction/2010/2010.Marshall.DeceptionAndMagicInCollaborativeInteraction.pdf:application/pdf}
}

@book{kendon_gesture:_2004,
	title = {Gesture: {Visible} action as utterance},
	publisher = {Cambridge University Press},
	author = {Kendon, Adam},
	year = {2004}
}

@book{merleau-ponty_phenomenologie_1976,
	title = {Phenomenologie de la perception},
	isbn = {2-07-029337-8},
	url = {https://www.xarg.org/ref/a/2070293378/},
	publisher = {Gallimard},
	author = {Merleau-Ponty, Maurice},
	month = may,
	year = {1976}
}

@article{vines_music_2011,
	title = {Music to my eyes: {Cross}-modal interactions in the perception of emotions in musical performance},
	volume = {118},
	number = {2},
	journal = {Cognition},
	author = {Vines, Bradley W and Krumhansl, Carol L and Wanderley, Marcelo M and Dalca, Ioana M and Levitin, Daniel J},
	year = {2011},
	pages = {157--170},
	file = {2011-Feb 2011-Cognition.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_JOURNALS/_Cognition/2011/2011-Feb 2011-Cognition.pdf:application/pdf}
}

@article{mauss_esquisse_1902,
	title = {Esquisse d’une théorie générale de la magie},
	volume = {1903},
	journal = {Année sociologique},
	author = {Mauss, Marcel and Hubert, Henri},
	year = {1902}
}

@phdthesis{lokuge_dynamic_1995,
	type = {{PhD} {Thesis}},
	title = {Dynamic magical environments: {Engaging} interaction based on the art of illusion},
	school = {Massachusetts Institute of Technology},
	author = {Lokuge, Ishantha Joseph},
	year = {1995}
}

@article{lippe_real-time_1991,
	title = {Real-time computer music at {IRCAM}},
	volume = {6},
	url = {https://www.cortlippe.com/uploads/1/0/7/0/107065311/lippe-cmr1991-london.pdf},
	number = {1},
	journal = {Contemporary Music Review},
	author = {Lippe, Cort},
	year = {1991},
	pages = {219--224}
}

@inproceedings{kurtenbach_issues_1991,
	title = {Issues in combining marking and direct manipulation techniques},
	url = {http://byu.danrolsenjr.org/cs656/Papers/2D/MarkingMenus-kurtenbach-UIST91.pdf},
	booktitle = {Proceedings of the 4th annual {ACM} symposium on {User} interface software and technology},
	publisher = {ACM},
	author = {Kurtenbach, Gordon and Buxton, William},
	year = {1991},
	pages = {137--144}
}

@book{kurtag_gyorgy_2018,
	title = {György {Kurtág}: entretiens, textes, écrits sur son ø euvre},
	url = {https://books.openedition.org/contrechamps/1911},
	publisher = {Éditions Contrechamps},
	author = {Kurtág, György},
	year = {2018}
}

@misc{manoury_philippe_2016,
	title = {Philippe {Manoury} en entretien. 1: {Geste}, interprétation, synchronisation},
	url = {https://geste.hypotheses.org/364},
	abstract = {Le geste apparaît comme un paramètre important des processus compositionnels développés par Philippe Manoury, à la fois dans sa musique purement instrumentale, avec, par exemple, le trio à cordes Gestes et dans sa musique impliquant de l’électronique traité en temps réel (de Sonus ex machina jusqu’à Tensio et ses œuvres les plus récentes). C’est d’ailleurs dans l’interactivité avec l’électronique qu’il prend une fonction prépondérante, du rôle de déclencheur dans Pluton à la création du système de « synthèse du geste » avec la corde virtuelle de Tensio.
L’entretien inédit que nous publions ci-dessous éclaire la façon dont Manoury conceptualise et utilise le geste, aussi bien au niveau purement instrumental qu’en des sens plus abstraits. Cet entretien été réalisé par Anne-Sylvie Barthel-Calvet à Strasbourg le 10 juin 2016 et relu par le compositeur.},
	language = {fr},
	author = {Manoury, Philippe},
	collaborator = {Barthel-Calvet, Anne-Sylvie},
	month = jun,
	year = {2016}
}

@article{patel_comparing_2006,
	title = {Comparing the rhythm and melody of speech and music: {The} case of {British} {English} and {French}},
	volume = {119},
	number = {5},
	journal = {The Journal of the Acoustical Society of America},
	author = {Patel, Aniruddh D and Iversen, John R and Rosenberg, Jason C},
	year = {2006},
	pages = {3034--3047}
}

@article{fritz_listener_2017,
	title = {Listener evaluations of new and {Old} {Italian} violins},
	volume = {114},
	number = {21},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fritz, Claudia and Curtin, Joseph and Poitevineau, Jacques and Tao, Fan-Chia},
	year = {2017},
	pages = {5395--5400}
}

@phdthesis{faure_sons_2000,
	type = {{PhD} {Thesis}},
	title = {Des sons aux mots, comment parle-t-on du timbre musical?},
	url = {https://tel.archives-ouvertes.fr/tel-00140521/},
	language = {fr},
	school = {École des Hautes-Études en Sciences Sociales},
	author = {Faure, Anne},
	year = {2000},
	file = {2000.PhD.Faure.DesSonsAuxMots.pdf:/Users/vg/Documents/_BIBLIO/_SCIENCES/_MUSIC_AND_SOUND/_THESIS/2000.PhD.Faure.DesSonsAuxMots.pdf:application/pdf}
}

@book{kohler_gestalt_1929,
	address = {New York},
	title = {Gestalt {Psychology}},
	publisher = {Horace Liveright},
	author = {Köhler, Wolfgang},
	year = {1929}
}

@book{chion_audio-vision:_2013,
	edition = {3},
	title = {L'audio-vision: son et image au cinéma},
	isbn = {978-2-200-24790-4},
	publisher = {Armand Colin},
	author = {Chion, Michel},
	year = {2013},
	note = {(1ère édition : 1990)}
}

@inproceedings{chadefaux_experimental_2012,
	address = {Nantes, France},
	title = {Experimental study of the musician / instrument interaction in the case of the concert harp},
	url = {https://hal.archives-ouvertes.fr/hal-00810872},
	booktitle = {Acoustics 2012},
	author = {CHADEFAUX, Delphine and Wanderley, Marcelo and Le Carrou, Jean-Loic and Fabre, Benoît and Daudet, Laurent},
	editor = {d'Acoustique, Société Française},
	month = apr,
	year = {2012},
	keywords = {Harp, Musical gesture}
}